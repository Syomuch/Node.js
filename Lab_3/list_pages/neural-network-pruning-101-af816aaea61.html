<!doctype html><html lang="en"><head><title data-rh="true">Neural Network Pruning 101. All you need to know not to get lost | by Hugo Tessier | Towards Data Science</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2021-09-13T07:52:05.992Z"/><meta data-rh="true" name="title" content="Neural Network Pruning 101. All you need to know not to get lost | by Hugo Tessier | Towards Data Science"/><meta data-rh="true" property="og:title" content="Neural Network Pruning 101"/><meta data-rh="true" property="al:android:url" content="medium://p/af816aaea61"/><meta data-rh="true" property="al:ios:url" content="medium://p/af816aaea61"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="Whether it is in computer vision, natural language processing or image generation, deep neural networks yield the state of the art. However, their cost in terms of computational power, memory or…"/><meta data-rh="true" property="og:description" content="All you need to know not to get lost"/><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/neural-network-pruning-101-af816aaea61"/><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/neural-network-pruning-101-af816aaea61"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:1200/1*7qwYH1r-h6VOGiE6C2tpGg.png"/><meta data-rh="true" property="article:author" content="https://medium.com/@hugo.tessier"/><meta data-rh="true" name="author" content="Hugo Tessier"/><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" property="twitter:title" content="Neural Network Pruning 101"/><meta data-rh="true" name="twitter:site" content="@TDataScience"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/af816aaea61"/><meta data-rh="true" property="twitter:description" content="All you need to know not to get lost"/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:1200/1*7qwYH1r-h6VOGiE6C2tpGg.png"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" name="twitter:label1" content="Reading time"/><meta data-rh="true" name="twitter:data1" content="22 min read"/><meta data-rh="true" name="twitter:tile:template:testing" content="2"/><meta data-rh="true" name="twitter:tile:image" content="https://miro.medium.com/v2/resize:fit:1200/1*7qwYH1r-h6VOGiE6C2tpGg.png"/><meta data-rh="true" name="twitter:tile:info1:icon" content="Person"/><meta data-rh="true" name="twitter:tile:info1:text" content="Hugo Tessier"/><meta data-rh="true" name="twitter:tile:info2:icon" content="Calendar"/><meta data-rh="true" name="twitter:tile:info2:text" content="Sep 13, 2021"/><meta data-rh="true" name="twitter:cta" content="Read on Medium"/><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/resize:fill:256:256/1*VzTUkfeGymHP4Bvav-T-lA.png"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:152:152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:120:120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:76:76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:60:60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"/><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://medium.com/@hugo.tessier"/><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/neural-network-pruning-101-af816aaea61"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/af816aaea61"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:1200\u002F1*7qwYH1r-h6VOGiE6C2tpGg.png"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fneural-network-pruning-101-af816aaea61","dateCreated":"2021-09-09T06:36:56.338Z","datePublished":"2021-09-09T06:36:56.338Z","dateModified":"2022-07-29T12:31:29.365Z","headline":"Neural Network Pruning 101 - Towards Data Science","name":"Neural Network Pruning 101 - Towards Data Science","description":"Whether it is in computer vision, natural language processing or image generation, deep neural networks yield the state of the art. However, their cost in terms of computational power, memory or…","identifier":"af816aaea61","author":{"@type":"Person","name":"Hugo Tessier","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@hugo.tessier"},"creator":["Hugo Tessier"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":165,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:330\u002F1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fneural-network-pruning-101-af816aaea61"}</script><style type="text/css" data-fela-rehydration="702" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="702" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="702" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px rgba(242, 242, 242, 1)}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:rgba(117, 117, 117, 1)}.ar:disabled{fill:rgba(117, 117, 117, 1)}.au{height:25px}.av{fill:rgba(41, 41, 41, 1)}.aw{margin-left:16px}.ax{border:none}.ay{border-radius:20px}.az{width:240px}.ba{background:rgba(250, 250, 250, 1)}.bb path{fill:rgba(117, 117, 117, 1)}.bd{outline:none}.be{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bf{font-size:14px}.bg{width:100%}.bh{padding:10px 20px 10px 0}.bi{background-color:transparent}.bj{color:rgba(41, 41, 41, 1)}.bk::placeholder{color:rgba(117, 117, 117, 1)}.bl{display:inline-block}.bm{margin-left:12px}.bn{margin-right:12px}.bo{border-radius:4px}.bp{margin-left:24px}.bq{height:24px}.bw{background-color:rgba(250, 250, 250, 1)}.bx{border-radius:50%}.by{height:32px}.bz{width:32px}.ca{justify-content:center}.cg{max-width:680px}.ch{min-width:0}.ci{animation:k1 1.2s ease-in-out infinite}.cj{height:100vh}.ck{margin-bottom:16px}.cl{margin-top:48px}.cm{align-items:flex-start}.cn{flex-direction:column}.co{justify-content:space-between}.cp{margin-bottom:24px}.cv{width:80%}.cw{background-color:rgba(242, 242, 242, 1)}.dc{height:44px}.dd{width:44px}.de{margin:auto 0}.df{margin-bottom:4px}.dg{height:16px}.dh{width:120px}.di{width:80px}.do{margin-bottom:8px}.dp{width:96%}.dq{width:98%}.dr{width:81%}.ds{margin-left:8px}.dt{color:rgba(117, 117, 117, 1)}.du{font-size:13px}.dv{height:100%}.el{color:rgba(255, 255, 255, 1)}.em{fill:rgba(255, 255, 255, 1)}.eo{background:rgba(102, 138, 170, 1)}.ep{border-color:rgba(102, 138, 170, 1)}.et:disabled{cursor:inherit !important}.eu:disabled{opacity:0.3}.ev:disabled:hover{background:rgba(102, 138, 170, 1)}.ew:disabled:hover{border-color:rgba(102, 138, 170, 1)}.ex{border-radius:99em}.ey{border-width:1px}.ez{border-style:solid}.fa{box-sizing:border-box}.fb{text-decoration:none}.fe{margin-right:32px}.ff{position:relative}.fg{fill:rgba(117, 117, 117, 1)}.fj{background:transparent}.fk svg{margin-left:4px}.fl svg{fill:rgba(117, 117, 117, 1)}.fn{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fo{position:absolute}.fv{margin:0 24px}.fz{background:rgba(255, 255, 255, 1)}.ga{border:1px solid rgba(230, 230, 230, 1)}.gb{box-shadow:0 1px 4px rgba(230, 230, 230, 1)}.gc{max-height:100vh}.gd{overflow-y:auto}.ge{left:0}.gf{top:calc(100vh + 100px)}.gg{bottom:calc(100vh + 100px)}.gh{width:10px}.gi{pointer-events:none}.gj{word-break:break-word}.gk{word-wrap:break-word}.gl:after{display:block}.gm:after{content:""}.gn:after{clear:both}.go{line-height:1.23}.gp{letter-spacing:0}.gq{font-style:normal}.gr{font-weight:700}.hm{margin-bottom:-0.27em}.hn{line-height:1.394}.id{@media all and (max-width: 551.98px):8px}.ie{@media all and (min-width: 552px) and (max-width: 727.98px):8px}.if{@media all and (min-width: 728px) and (max-width: 903.98px):16px}.ig{@media all and (min-width: 904px) and (max-width: 1079.98px):16px}.ih{@media all and (min-width: 1080px):16px}.in{align-items:baseline}.io{width:48px}.ip{height:48px}.iq{border:2px solid rgba(255, 255, 255, 1)}.ir{z-index:0}.is{box-shadow:none}.it{border:1px solid rgba(0, 0, 0, 0.05)}.iv{margin-left:-12px}.iw{width:28px}.ix{height:28px}.iy{z-index:1}.iz{width:24px}.ja{margin-bottom:2px}.jb{flex-wrap:nowrap}.jc{font-size:16px}.jd{line-height:24px}.jf{margin:0 8px}.jg{display:inline}.jh{color:rgba(102, 138, 170, 1)}.ji{fill:rgba(102, 138, 170, 1)}.jl{flex:0 0 auto}.jo{flex-wrap:wrap}.jr{white-space:pre-wrap}.js{margin-right:4px}.jt{overflow:hidden}.ju{max-height:20px}.jv{text-overflow:ellipsis}.jw{display:-webkit-box}.jx{-webkit-line-clamp:1}.jy{-webkit-box-orient:vertical}.jz{word-break:break-all}.kb{padding-left:8px}.kc{padding-right:8px}.ld> *{flex-shrink:0}.le{overflow-x:scroll}.lf::-webkit-scrollbar{display:none}.lg{scrollbar-width:none}.lh{-ms-overflow-style:none}.li{width:74px}.lj{flex-direction:row}.lm{-webkit-user-select:none}.ln{border:0}.lq{outline:0}.lr{user-select:none}.ls> svg{pointer-events:none}.mb{cursor:progress}.mc{margin-top:0px}.md{opacity:1}.me{padding:4px 0}.mg{margin-left:4px}.mh{width:16px}.mi path{fill:rgba(41, 41, 41, 1)}.mj{padding:8px 2px}.mm svg path{fill:rgba(117, 117, 117, 1)}.mn svg{color:rgba(117, 117, 117, 1)}.ne{line-height:1.58}.nf{letter-spacing:-0.004em}.ng{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.nz{margin-bottom:-0.46em}.oa{line-height:1.12}.ob{letter-spacing:-0.022em}.oc{font-weight:600}.ov{margin-bottom:-0.28em}.pb{margin-left:auto}.pc{margin-right:auto}.pd{max-width:2430px}.pj{clear:both}.pl{cursor:zoom-in}.pm{z-index:auto}.po{max-width:100%}.pp{height:auto}.pq{margin-top:10px}.pr{text-align:center}.ps{max-width:728px}.pv{line-height:1.18}.qj{margin-bottom:-0.31em}.qk{font-style:italic}.ql{text-decoration:underline}.qm{max-width:2268px}.qn{max-width:2048px}.qo{max-width:2058px}.qp{margin:auto}.qq{padding-bottom:100%}.qr{height:0}.qs{margin-bottom:26px}.qt{margin-top:6px}.qu{margin-top:8px}.qv{margin-right:8px}.qw{padding:8px 16px}.qx{border-radius:100px}.qy{transition:background 300ms ease}.ra{white-space:nowrap}.rb{border-top:none}.rh{height:52px}.ri{max-height:52px}.rj{box-sizing:content-box}.rk{position:static}.rm{max-width:155px}.rs{margin-right:20px}.ry{align-items:flex-end}.rz{width:76px}.sa{height:76px}.sb{border:2px solid rgba(250, 250, 250, 1)}.sc{height:72px}.sd{width:72px}.se{margin-left:-16px}.sf{width:36px}.sg{height:36px}.sh{width:auto}.si{stroke:rgba(242, 242, 242, 1)}.sj{color:rgba(242, 242, 242, 1)}.sk{fill:rgba(242, 242, 242, 1)}.sl{background:rgba(242, 242, 242, 1)}.sm{border-color:rgba(242, 242, 242, 1)}.ss{font-weight:500}.st{font-size:24px}.su{line-height:30px}.sv{letter-spacing:-0.016em}.sw{margin-top:16px}.sx{height:0px}.sy{border-bottom:solid 1px #E5E5E5}.te{margin-top:72px}.tf{padding:24px 0}.tg{margin-bottom:0px}.th{margin-right:16px}.ti{display:inline-flex}.to{margin-bottom:32px}.tp{margin-top:40px}.tq{align-items:stretch}.va{flex-grow:0}.vg{display:grid}.vh{grid-template-columns:repeat(12, 1fr)}.vi{grid-template-rows:auto 1fr}.vt{grid-area:image}.vu{grid-area:content}.wa{border-radius:2px}.wb{aspect-ratio:2}.wc{object-fit:cover}.wd{object-position:50% 50%}.wj{height:20px}.wk{width:20px}.wl{padding-right:4px}.xg{padding-top:8px}.xh{max-height:40px}.xi{-webkit-line-clamp:2}.xy{margin-left:20px}.xz{justify-content:flex-end}.ya{flex:0 0 0}.yb{margin-top:32px}.yi{background:0}.yj{border-color:rgba(117, 117, 117, 1)}.ym:disabled:hover{color:rgba(41, 41, 41, 1)}.yn:disabled:hover{fill:rgba(41, 41, 41, 1)}.yo:disabled:hover{border-color:rgba(117, 117, 117, 1)}.zi{padding-bottom:40px}.zj{padding-top:88px}.zk{margin-bottom:40px}.zl{margin-top:4px}.zm{border-right:3px solid rgba(250, 250, 250, 1)}.zn{z-index:3}.zo{z-index:2}.zp{margin-left:-24px}.zq{margin-left:-36px}.zr{border-radius:0 3px 3px 0}.zs{width:93px}.zt{background:#292929}.zu{background:#757575}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.eq:hover{background:rgba(90, 118, 144, 1)}.er:hover{border-color:rgba(90, 118, 144, 1)}.es:hover{cursor:pointer}.fh:hover{color:rgba(41, 41, 41, 1)}.fi:hover{fill:rgba(41, 41, 41, 1)}.fm:hover svg{fill:rgba(41, 41, 41, 1)}.fp:hover{background-color:none}.iu:hover{background-color:rgba(0, 0, 0, 0.1)}.je:hover{text-decoration:underline}.jj:hover:not(:disabled){color:rgba(90, 118, 144, 1)}.jk:hover:not(:disabled){fill:rgba(90, 118, 144, 1)}.lp:hover{fill:rgba(8, 8, 8, 1)}.mf:hover p{color:rgba(8, 8, 8, 1)}.mk:hover:not(:disabled) svg path{fill:rgba(8, 8, 8, 1)}.mo:hover svg{color:rgba(8, 8, 8, 1)}.qz:hover{background-color:rgba(230, 230, 230, 1)}.sn:hover{background:rgba(242, 242, 242, 1)}.so:hover{border-color:rgba(242, 242, 242, 1)}.sp:hover{cursor:wait}.sq:hover{color:rgba(242, 242, 242, 1)}.sr:hover{fill:rgba(242, 242, 242, 1)}.yk:hover{color:rgba(8, 8, 8, 1)}.yl:hover{border-color:rgba(41, 41, 41, 1)}.bc:focus-within path{fill:rgba(41, 41, 41, 1)}.lo:focus{fill:rgba(8, 8, 8, 1)}.ml:focus svg path{fill:rgba(8, 8, 8, 1)}.mp:focus svg{color:rgba(8, 8, 8, 1)}.pn:focus{transform:scale(1.01)}.lt:active{border-style:none}</style><style type="text/css" data-fela-rehydration="702" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ee{font-size:14px}.ef{line-height:20px}.ek{padding:5px 12px}.fd{display:flex}.fu{margin-bottom:68px}.fy{max-width:680px}.hi{font-size:42px}.hj{margin-top:1.19em}.hk{line-height:52px}.hl{letter-spacing:-0.011em}.ia{font-size:22px}.ib{margin-top:0.92em}.ic{line-height:28px}.im{align-items:center}.kp{border-top:solid 1px rgba(242, 242, 242, 1)}.kq{border-bottom:solid 1px rgba(242, 242, 242, 1)}.kr{margin:32px 0 0}.ks{padding:3px 8px}.lb> *{margin-right:24px}.lc> :last-child{margin-right:0}.ma{margin-top:0px}.nv{font-size:20px}.nw{margin-top:2em}.nx{line-height:32px}.ny{letter-spacing:-0.003em}.or{font-size:24px}.os{margin-top:1.95em}.ot{line-height:30px}.ou{letter-spacing:-0.016em}.pa{margin-top:0.86em}.pi{margin-top:56px}.qg{margin-top:1.72em}.qh{line-height:24px}.qi{letter-spacing:0}.rg{margin-bottom:88px}.rr{display:inline-block}.rx{padding-top:72px}.td{margin-top:40px}.tn{margin:0}.ud{width:calc(100% + 32px)}.ue{margin-left:-16px}.uf{margin-right:-16px}.uw{padding-left:16px}.ux{padding-right:16px}.uy{flex-basis:50%}.uz{max-width:50%}.vf{padding-bottom:56px}.vr{gap:24px 0}.vs{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.vz{display:block}.wi{margin-bottom:16px}.wu{padding-bottom:16px}.wv{flex:1 0 auto}.xe{max-height:48px}.xf{-webkit-line-clamp:2}.xn{padding-top:16px}.xw{max-width:56%}.xx{flex:1 0 0}.ye{margin-bottom:24px}.yh{flex-direction:row}.yt{width:min-width}.zc{margin-left:16px}.zh{margin-top:96px}.zz{margin-top:24px}.aba{margin-bottom:56px}</style><style type="text/css" data-fela-rehydration="702" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.lz{margin-top:0px}.pt{margin-left:auto}.pu{text-align:center}.rq{display:inline-block}</style><style type="text/css" data-fela-rehydration="702" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.ly{margin-top:0px}.rp{display:inline-block}</style><style type="text/css" data-fela-rehydration="702" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.lw{margin-top:0px}.lx{margin-right:0px}.ro{display:inline-block}</style><style type="text/css" data-fela-rehydration="702" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.br{width:24px}.cb{margin:0 24px}.cq{height:40px}.cx{margin-bottom:44px}.dj{margin-bottom:32px}.dw{font-size:13px}.dx{line-height:20px}.eg{padding:0px 8px 1px}.fq{margin-bottom:4px}.gs{font-size:32px}.gt{margin-top:1.01em}.gu{line-height:38px}.gv{letter-spacing:-0.014em}.ho{font-size:18px}.hp{margin-top:0.79em}.hq{line-height:24px}.ii{align-items:flex-start}.jm{flex-direction:column}.jp{margin-bottom:2px}.kd{margin:24px -24px 0}.ke{padding:0}.kt> *{margin-right:8px}.ku> :last-child{margin-right:24px}.lk{margin-left:0px}.lu{margin-top:0px}.lv{margin-right:0px}.mq{border:1px solid rgba(230, 230, 230, 1)}.mr{border-radius:99em}.ms{padding:0px 16px 0px 12px}.mt{height:38px}.mu{align-items:center}.mw svg{margin-right:8px}.nh{margin-top:1.56em}.ni{line-height:28px}.nj{letter-spacing:-0.003em}.od{font-size:20px}.oe{margin-top:1.2em}.of{letter-spacing:0}.ow{margin-top:0.67em}.pe{margin-top:40px}.pw{font-size:16px}.px{margin-top:1.23em}.rc{margin-bottom:80px}.rn{display:inline-block}.rt{padding-top:48px}.sz{margin-top:32px}.tj{margin:0}.tr{width:calc(100% + 24px)}.ts{margin-left:-12px}.tt{margin-right:-12px}.ug{padding-left:12px}.uh{padding-right:12px}.ui{flex-basis:100%}.uj{max-width:100%}.vb{padding-bottom:32px}.vj{gap:24px 0}.vk{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.vv{display:block}.we{margin-bottom:16px}.wm{padding-bottom:16px}.wn{flex:1 0 auto}.ww{max-height:48px}.wx{-webkit-line-clamp:2}.xj{padding-top:16px}.xo{max-width:56%}.xp{flex:1 0 0}.yp{width:100%}.yu{margin-left:0}.yv{margin-top:16px}.zd{margin-top:72px}.mv:hover{border-color:rgba(204, 204, 204, 1)}</style><style type="text/css" data-fela-rehydration="702" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bu{width:64px}.ce{margin:0 64px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.ec{font-size:14px}.ed{line-height:20px}.ej{padding:5px 12px}.fc{display:flex}.ft{margin-bottom:68px}.fx{max-width:680px}.he{font-size:42px}.hf{margin-top:1.19em}.hg{line-height:52px}.hh{letter-spacing:-0.011em}.hx{font-size:22px}.hy{margin-top:0.92em}.hz{line-height:28px}.il{align-items:center}.kl{border-top:solid 1px rgba(242, 242, 242, 1)}.km{border-bottom:solid 1px rgba(242, 242, 242, 1)}.kn{margin:32px 0 0}.ko{padding:3px 8px}.kz> *{margin-right:24px}.la> :last-child{margin-right:0}.nr{font-size:20px}.ns{margin-top:2em}.nt{line-height:32px}.nu{letter-spacing:-0.003em}.on{font-size:24px}.oo{margin-top:1.95em}.op{line-height:30px}.oq{letter-spacing:-0.016em}.oz{margin-top:0.86em}.ph{margin-top:56px}.qd{margin-top:1.72em}.qe{line-height:24px}.qf{letter-spacing:0}.rf{margin-bottom:88px}.rw{padding-top:72px}.tc{margin-top:40px}.tm{margin:0}.ua{width:calc(100% + 32px)}.ub{margin-left:-16px}.uc{margin-right:-16px}.us{padding-left:16px}.ut{padding-right:16px}.uu{flex-basis:50%}.uv{max-width:50%}.ve{padding-bottom:56px}.vp{gap:24px 0}.vq{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.vy{display:block}.wh{margin-bottom:16px}.ws{padding-bottom:16px}.wt{flex:1 0 auto}.xc{max-height:48px}.xd{-webkit-line-clamp:2}.xm{padding-top:16px}.xu{max-width:56%}.xv{flex:1 0 0}.yd{margin-bottom:24px}.yg{flex-direction:row}.ys{width:min-width}.za{margin-left:16px}.zb{margin-top:0px}.zg{margin-top:96px}.zx{margin-top:24px}.zy{margin-bottom:56px}</style><style type="text/css" data-fela-rehydration="702" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:flex-end}.bt{width:64px}.cd{margin:0 48px}.cs{height:48px}.cz{margin-bottom:52px}.dl{margin-bottom:48px}.ea{font-size:13px}.eb{line-height:20px}.ei{padding:0px 8px 1px}.fs{margin-bottom:68px}.fw{max-width:680px}.ha{font-size:42px}.hb{margin-top:1.19em}.hc{line-height:52px}.hd{letter-spacing:-0.011em}.hu{font-size:22px}.hv{margin-top:0.92em}.hw{line-height:28px}.ik{align-items:center}.kh{border-top:solid 1px rgba(242, 242, 242, 1)}.ki{border-bottom:solid 1px rgba(242, 242, 242, 1)}.kj{margin:32px 0 0}.kk{padding:3px 8px}.kx> *{margin-right:24px}.ky> :last-child{margin-right:0}.nn{font-size:20px}.no{margin-top:2em}.np{line-height:32px}.nq{letter-spacing:-0.003em}.oj{font-size:24px}.ok{margin-top:1.95em}.ol{line-height:30px}.om{letter-spacing:-0.016em}.oy{margin-top:0.86em}.pg{margin-top:56px}.qa{margin-top:1.72em}.qb{line-height:24px}.qc{letter-spacing:0}.re{margin-bottom:88px}.rv{padding-top:72px}.tb{margin-top:40px}.tl{margin:0}.tx{width:calc(100% + 28px)}.ty{margin-left:-14px}.tz{margin-right:-14px}.uo{padding-left:14px}.up{padding-right:14px}.uq{flex-basis:50%}.ur{max-width:50%}.vd{padding-bottom:56px}.vn{gap:24px 0}.vo{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.vx{display:block}.wg{margin-bottom:16px}.wq{padding-bottom:16px}.wr{flex:1 0 auto}.xa{max-height:48px}.xb{-webkit-line-clamp:2}.xl{padding-top:16px}.xs{max-width:56%}.xt{flex:1 0 0}.yc{margin-bottom:24px}.yf{flex-direction:row}.yr{width:min-width}.yy{margin-left:16px}.yz{margin-top:0px}.zf{margin-top:96px}.zv{margin-top:24px}.zw{margin-bottom:56px}</style><style type="text/css" data-fela-rehydration="702" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dy{font-size:13px}.dz{line-height:20px}.eh{padding:0px 8px 1px}.fr{margin-bottom:4px}.gw{font-size:32px}.gx{margin-top:1.01em}.gy{line-height:38px}.gz{letter-spacing:-0.014em}.hr{font-size:18px}.hs{margin-top:0.79em}.ht{line-height:24px}.ij{align-items:flex-start}.jn{flex-direction:column}.jq{margin-bottom:2px}.kf{margin:24px 0 0}.kg{padding:0}.kv> *{margin-right:8px}.kw> :last-child{margin-right:8px}.ll{margin-left:0px}.mx{border:1px solid rgba(230, 230, 230, 1)}.my{border-radius:99em}.mz{padding:0px 16px 0px 12px}.na{height:38px}.nb{align-items:center}.nd svg{margin-right:8px}.nk{margin-top:1.56em}.nl{line-height:28px}.nm{letter-spacing:-0.003em}.og{font-size:20px}.oh{margin-top:1.2em}.oi{letter-spacing:0}.ox{margin-top:0.67em}.pf{margin-top:40px}.py{font-size:16px}.pz{margin-top:1.23em}.rd{margin-bottom:80px}.ru{padding-top:48px}.ta{margin-top:32px}.tk{margin:0}.tu{width:calc(100% + 24px)}.tv{margin-left:-12px}.tw{margin-right:-12px}.uk{padding-left:12px}.ul{padding-right:12px}.um{flex-basis:100%}.un{max-width:100%}.vc{padding-bottom:32px}.vl{gap:24px 0}.vm{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.vw{display:block}.wf{margin-bottom:16px}.wo{padding-bottom:16px}.wp{flex:1 0 auto}.wy{max-height:48px}.wz{-webkit-line-clamp:2}.xk{padding-top:16px}.xq{max-width:56%}.xr{flex:1 0 0}.yq{width:100%}.yw{margin-left:0}.yx{margin-top:16px}.ze{margin-top:72px}.nc:hover{border-color:rgba(204, 204, 204, 1)}</style><style type="text/css" data-fela-rehydration="702" data-fela-type="RULE" media="print">.rl{display:none}</style><style type="text/css" data-fela-rehydration="702" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.ka{max-height:none}</style><style type="text/css" data-fela-rehydration="702" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.pk{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div class="l c"><div class="l m n o c"><div class="p q r s t u v w x i d y z"><a class="dt ag du be ak b am an ao ap aq ar as at s u j i d q dv z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Faf816aaea61&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;source=---two_column_layout_nav----------------------------------" rel="noopener follow">Open in app<svg width="10" height="10" viewBox="0 0 10 10" fill="none" class="ds"><path d="M.98 8.48a.37.37 0 1 0 .54.54l-.54-.54zm7.77-7.23h.38c0-.2-.17-.38-.38-.38v.38zM8.37 6.5a.37.37 0 1 0 .76 0h-.76zM3.5.87a.37.37 0 1 0 0 .76V.88zM1.52 9.03l7.5-7.5-.54-.54-7.5 7.5.54.54zm6.86-7.77V6.5h.74V1.25h-.74zm-4.88.38h5.25V.88H3.5v.74z" fill="currentColor"></path></svg></a><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="be b dw dx eg dy dz eh ea eb ei ec ed ej ee ef ek el em eo ep eq er es et eu ev ew ex ey ez fa bl fb" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign In</a></span></p></div></div></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" href="https://medium.com/?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><svg viewBox="0 0 1043.63 592.71" class="au av"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a><div class="aw h"><div class="ab ax ay az ba q bb bc"><div class="bl" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bm bn ab"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" tabindex="0" class="ax bd be bf z bg bh bi bj bk" placeholder="Search Medium" value=""/></div></div></div><div class="h k w fc fd"><div class="fe ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---two_column_layout_nav-----------------------new_post_topnav-----------" rel="noopener follow"><div class="be b bf z dt ff fg ab q fh fi"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Write"><path d="M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z" fill="currentColor"></path><path d="M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2" stroke="currentColor"></path></svg><div class="ds l">Write</div></div></a></span></div></div><div class="k j i d"><div class="fe ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/search?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><div class="be b bf z dt ff fg ab q fh fi"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Search"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div></a></div></div><div class="fe h k j"><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="be b dw dx eg dy dz eh ea eb ei ec ed ej ee ef ek el em eo ep eq er es et eu ev ew ex ey ez fa bl fb" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign In</a></span></p></div></div></div><div class="l" aria-hidden="false"><button class="ax fj am ab q ao fk fl fm" aria-label="user options menu"><div class="l ff"><img alt="" class="l fa bx by bz cw" src="https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"/><div class="fn bx l by bz fo n ax fp"></div></div><svg width="12px" height="12px" viewBox="0 0 15 15"><path d="M3.85 5.15a.5.5 0 0 0-.7.7l4.35 4.36 4.35-4.36a.5.5 0 1 0-.7-.7L7.5 8.79 3.85 5.15z" fill-rule="evenodd"></path></svg></button></div></div></div><div class="l"><div class="fq fr fs ft fu l"><div class="ab ca"><div class="ch bg fv fw fx fy"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="fo ge gf gg gh gi"></div><div class="gj gk gl gm gn"><div class="ab ca"><div class="ch bg fv fw fx fy"><div class=""><h1 id="06b7" class="pw-post-title go gp gq be gr gs gt gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm bj">Neural Network Pruning 101</h1></div><div class=""><h2 id="c2f6" class="pw-subtitle-paragraph hn gp gq be b ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic cp dt">All you need to know not to get lost</h2><div class="id ie if ig ih"><div class="speechify-ignore ab co"><div class="speechify-ignore bg l"><div class="ii ij ik il im ab"><div><div class="ab in"><a href="https://medium.com/@hugo.tessier?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="l io ip bx iq ir"><div class="l ff"><img alt="Hugo Tessier" class="l fa bx dc dd cw" src="https://miro.medium.com/v2/resize:fill:88:88/1*PAy1sna3YNoKY4jQl9znVw.jpeg" width="44" height="44" loading="lazy"/><div class="is bx l dc dd fo n it iu"></div></div></div></div></div></a><a href="https://towardsdatascience.com/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><div class="iv ab ff"><div><div class="bl" aria-hidden="false"><div class="l iw ix bx iq iy"><div class="l ff"><img alt="Towards Data Science" class="l fa bx bq iz cw" src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg" width="24" height="24" loading="lazy"/><div class="is bx l bq iz fo n it iu"></div></div></div></div></div></div></a></div></div><div class="bm bg l"><div class="ab"><div style="flex:1"><span class="be b bf z bj"><div class="ja ab q"><div class="ab q jb"><div class="ab q"><div><div class="bl" aria-hidden="false"><p class="be b jc jd bj"><a class="af ag ah ai aj ak al am an ao ap aq ar je" href="https://medium.com/@hugo.tessier?source=post_page-----af816aaea61--------------------------------" rel="noopener follow">Hugo Tessier</a></p></div></div></div><span class="jf jg" aria-hidden="true"><span class="be b bf z dt">·</span></span><p class="be b jc jd dt"><span><a class="jh ji ah ai aj ak al am an ao ap aq ar eu jj jk" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F524f24852f3c&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=post_page-524f24852f3c----af816aaea61---------------------post_header-----------" rel="noopener follow">Follow</a></span></p></div></div></span></div></div><div class="l jl"><span class="be b bf z dt"><div class="ab cm jm jn jo"><div class="jp jq ab"><div class="be b bf z dt ab jr"><span class="js l jl">Published in</span><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><p class="be b bf z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div><div class="h k"><span class="jf jg" aria-hidden="true"><span class="be b bf z dt">·</span></span></div></div><span class="be b bf z dt"><div class="ab ae">22 min read<div class="kb kc l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="be b bf z dt">·</span></span></div><span>Sep 9, 2021</span></div></span></div></span></div></div></div><div class="ab co kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks"><div class="h k w fc fd q"><div class="li l"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=-----af816aaea61---------------------clap_footer-----------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div></div><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class="mc"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">2</span></p></button></div></div></div><div class="ab q kt ku kv kw kx ky kz la lb lc ld le lf lg lh"><div class="mh k j i d"></div><div class="h k"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=-----af816aaea61---------------------bookmark_footer-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af fg ah ai aj ak al mj an ao ap eu mk ml mm"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div></div><div class="fa ti cm"><div class="l ae"><div class="ab ca"><div class="tj tk tl tm tn po ch bg"><div class="ab"><div class="bl bg" aria-hidden="false"><div><div class="bl" aria-hidden="false"><button class="af fg ah ai aj ak al mj an ao ap eu mn mo mf mp mq mr ms mt s mu mv mw mx my mz na u nb nc nd"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0zm9-10a10 10 0 1 0 0 20 10 10 0 0 0 0-20zm3.38 10.42l-4.6 3.06a.5.5 0 0 1-.78-.41V8.93c0-.4.45-.63.78-.41l4.6 3.06c.3.2.3.64 0 .84z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dt">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button class="af fg ah ai aj ak al mj an ao ap eu mn mo mf mp mq mr ms mt s mu mv mw mx my mz na u nb nc nd"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dt">Share</p></div></button></div></div></div></div></div></div></div></div></div><p id="ca09" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">Whether it is in computer vision, natural language processing or image generation, deep neural networks yield the state of the art. However, their cost in terms of computational power, memory or energy consumption can be prohibitive, making some of them downright unaffordable for most limited hardware. Yet, many domains would benefit from neural networks, hence the need to reduce their cost while maintaining their performance.</p><p id="375f" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">That is the whole point of neural networks compression. This field counts multiple families of methods, such as quantization [11], factorization [13], distillation [32] or, and this will be the focus of this post, pruning.</p><p id="24e1" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">Neural network pruning is a method that revolves around the intuitive idea of removing superfluous parts of a network that performs well but costs a lot of resources. Indeed, even though large neural networks have proven countless times how well they could learn, it turns out that not all of their parts are still useful after the training process is over. The idea is to eliminate these parts without impacting the network’s performance.</p><p id="9a45" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">Unfortunately, the dozens, if not hundreds, of papers published each year are revealing the hidden complexity of a supposedly straight-forward idea. Indeed, a quick overview of the literature yields countless ways of identifying said useless parts or removing them before, during or after training; it even turns out that not all kinds of pruning actually allow for accelerating neural networks, which is supposed to be the whole point.</p><p id="b038" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">The goal of this post is to provide a solid foundation to tackle the intimidatingly wild literature around neural network pruning. We will review successively three questions that seem to be at the core of the whole domain: “What kind of part should I prune?”, “How to tell which parts can be pruned?” and “How to prune parts without harming the network?”. To sum it up, we will detail <strong class="ng gr">pruning structures</strong>, <strong class="ng gr">pruning criteria</strong> and <strong class="ng gr">pruning methods</strong>.</p><h1 id="1f16" class="oa ob gq be oc od oe hq of og oh ht oi oj ok ol om on oo op oq or os ot ou ov bj">1 — Pruning structures</h1><h1 id="8cb0" class="oa ob gq be oc od oe hq of og oh ht oi oj ok ol om on oo op oq or os ot ou ov bj">1.1 — Unstructured pruning</h1><p id="fdc8" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">When talking about the cost of neural networks, the count of parameters is surely one of the most widely used metrics, along with FLOPS (floating-point operations per second). It is indeed intimidating to see networks displaying astronomical amounts of weights (up to billions for some), often correlated with stellar performance. Therefore, it is quite intuitive to aim at reducing directly this count by removing parameters themselves. Actually, pruning connections is one of the most widespread paradigms in the literature, enough to be considered as the default framework when dealing with pruning. The seminal work of Han et al.[26] presented this kind of pruning and served as a basis for numerous contributions [18, 21, 25].</p><p id="462b" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">Directly pruning parameters has many advantages. First, it is simple, since replacing the value of their weight with zero, within the parameter tensors, is enough to prune a connection. Widespread deep learning frameworks, such as Pytorch, allow to easily access all the parameters of a network, making it extremely simple to implement. Still, the greatest advantage of pruning connections remains yet that they are the smallest, most fundamental elements of networks and, therefore, they are numerous enough to prune them in large quantities without impacting performance. Such a fine granularity allows pruning very subtle patterns, up to parameters within convolution kernels, for example. As pruning weights is not limited by any constraint at all and is the finest way to prune a network, such a paradigm is called <strong class="ng gr">unstructured pruning</strong>.</p><p id="67a2" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">However, this method presents a major, fatal drawback: most frameworks and hardware cannot accelerate sparse matrices’ computation, meaning that no matter how many zeros you fill the parameter tensors with, it will not impact the actual cost of the network. What does impact it, however, is pruning in a way that directly alters the very architecture of the network, which any framework can handle.</p><figure class="pe pf pg ph pi pj pb pc paragraph-image"><div role="button" tabindex="0" class="pk pl ff pm bg pn"><div class="pb pc pd"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*7qwYH1r-h6VOGiE6C2tpGg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*7qwYH1r-h6VOGiE6C2tpGg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*7qwYH1r-h6VOGiE6C2tpGg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*7qwYH1r-h6VOGiE6C2tpGg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*7qwYH1r-h6VOGiE6C2tpGg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*7qwYH1r-h6VOGiE6C2tpGg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*7qwYH1r-h6VOGiE6C2tpGg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg po pp c" width="700" height="414" loading="lazy" role="presentation"/></picture></div></div><figcaption class="pq pr ps pb pc pt pu be b bf z dt">Difference between unstructured (left) and structured (right) pruning: structured pruning removes both convolution filters and rows of kernels instead of just pruning connections. This leads to fewer feature maps within intermediate representations. (image by author)</figcaption></figure><h2 id="01ae" class="pv ob gq be oc pw px dx of py pz dz oi nn qa qb qc nr qd qe qf nv qg qh qi qj bj">1.2 — Structured pruning</h2><p id="d73b" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">This is the reason why many works have focused on pruning larger structures, such as whole neurons [36] or, for its direct equivalent within the more modern deep convolutional networks, convolution filters [40, 41, 66]. Filter pruning allows for an exploitable and yet fine enough granularity, as large networks tend to include numerous convolution layers, each counting up to hundreds or thousands of filters. Not only does removing such structures result in sparse layers that can be directly instantiated as thinner ones, but doing so also eliminates the feature maps that are the outputs of such filters.</p><p id="4a73" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">Therefore, not only are such networks lighter to store, due to fewer parameters, but also they require less computations and generate lighter intermediate representations, hence needing less memory during runtime. Actually, it is sometimes more beneficial to reduce bandwidth rather than the parameter count. Indeed, for tasks that involve large images, such as semantic segmentation or object detection, intermediate representations may be prohibitively memory-consuming, way more than the network itself. For these reasons, filter pruning is now seen as the default kind of <strong class="ng gr">structured pruning</strong>.</p><p id="b13b" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">Yet, when applying such a pruning, one should pay attention to the following aspects. Let’s consider how a convolution layer is built: for <em class="qk">Cin</em> input channels and <em class="qk">Cout</em> output ones, a convolution layer is made of <em class="qk">Cout</em> filters, each counting <em class="qk">Cin</em> kernels; each filter outputs one feature map and within each filter, one kernel is dedicated to each input channel. Considering this architecture, and acknowledging a regular convolutional network basically stacks convolution layers, when pruning whole filters, one may observe that pruning a filter, and then the feature map it outputs, actually results in pruning the corresponding kernels in the ensuing layer too. That means that, when pruning filters, one may actually prune twice the amount of parameters thought to be removed in the first place.</p><p id="920a" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">Let’s consider too that, when a whole layer happens to get pruned (which tends to happen because of layer collapse [62], but does not always break the network, depending on the architecture), the previous layer’s outputs are now totally unconnected, hence pruned too: pruning a whole layer may actually prune all its previous layers whose outputs are not somehow connected elsewhere (because of residual connections [28] or whole parallel paths [61]). Therefore, <strong class="ng gr">when pruning filters, one should consider computing the exact number of actually pruned parameters</strong>. Indeed, pruning the same amount of filters, depending on their distribution within the architecture, may not lead to the same actual amount of pruned parameters, making any result impossible to compare with.</p><p id="64ad" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">Before changing topic, let’s just mention that, albeit a minority, some works focus on pruning convolution kernels, intra-kernel structures [2,24, 46] or even <a class="af ql" href="https://developer.nvidia.com/blog/accelerating-inference-with-sparsity-using-ampere-and-tensorrt/" rel="noopener ugc nofollow" target="_blank">specific parameter-wise structures</a>. However, such structures need special implementations to lead to any kind of speedup (as for unstructured pruning). Another kind of exploitable structure, though, is to turn convolutions into “shift layers” by pruning all but one parameter in each kernel, which can then be summed up as a combination of a shifting operation and a 1 × 1 convolution [24].</p><figure class="pe pf pg ph pi pj pb pc paragraph-image"><div role="button" tabindex="0" class="pk pl ff pm bg pn"><div class="pb pc qm"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*o0Qh-ORMytWTA2xdCFbPiQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*o0Qh-ORMytWTA2xdCFbPiQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*o0Qh-ORMytWTA2xdCFbPiQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*o0Qh-ORMytWTA2xdCFbPiQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*o0Qh-ORMytWTA2xdCFbPiQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*o0Qh-ORMytWTA2xdCFbPiQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*o0Qh-ORMytWTA2xdCFbPiQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg po pp c" width="700" height="602" loading="lazy" role="presentation"/></picture></div></div><figcaption class="pq pr ps pb pc pt pu be b bf z dt">The danger of structured pruning: altering the input and output dimensions of layers can lead to some discrepancies. If on the left, both layers output the same number of feature maps, that can be summed up well afterward, their pruned counterparts on the right produce intermediate representations of different dimensions, that cannot be summed up without processing them. (image by author)</figcaption></figure><h1 id="7400" class="oa ob gq be oc od oe hq of og oh ht oi oj ok ol om on oo op oq or os ot ou ov bj">2 — Pruning criteria</h1><p id="af47" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">Once one has decided what kind of structure to prune, the next question one may ask could be: “Now, how do I figure out which ones to keep and which ones to prune?”. To answer that one needs a proper pruning criteria, that will rank the relative importance of the parameters, filters or else.</p><h2 id="a3f6" class="pv ob gq be oc pw px dx of py pz dz oi nn qa qb qc nr qd qe qf nv qg qh qi qj bj">2.1 — Weight magnitude criterion</h2><p id="ab7c" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">One criterion that is quite intuitive and surprisingly efficient is pruning weights whose absolute value (or “magnitude”) is the smallest. Indeed, under the constraint of a weight-decay, those which do not contribute significantly to the function are expected to have their magnitude shrink during training. Therefore, the superfluous weights are expected to be those of lesser magnitude [8]. Notwithstanding its simplicity, the magnitude criterion is still widely used in modern works [21, 26, 58], making it a staple of the domain.</p><p id="b739" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">However, although this criterion seems trivial to implement in the case of unstructured pruning, one may wonder how to adapt it to structured pruning. One straightforward way is to order filters depending on their norm (L 1 or L 2 for example) [40, 70]. If this method is quite straightforward one may desire to encapsulate multiple sets of parameters within one measure: for example, a convolutional filter, its bias and its batch-normalization parameters together, or even corresponding filters within parallel layers whose outputs are then fused and whose channels we would like to reduce.</p><p id="44f2" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">One way to do that, without having to compute the combined norm of these parameters, involves inserting a learnable multiplicative parameter for each feature map after each set of layers you want to prune. This gate, when reduced to zero, effectively prunes the whole set of parameters responsible for this channel and the magnitude of this gate accounts for the importance of all of them. The method hence consists in pruning the gates of lesser magnitude [36, 41].</p><h2 id="a4d6" class="pv ob gq be oc pw px dx of py pz dz oi nn qa qb qc nr qd qe qf nv qg qh qi qj bj">2.2 — Gradient magnitude pruning</h2><p id="e034" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">Magnitude of the weight is not the only popular criterion (or family of criteria) that exists. Actually, the other main criterion to have lasted up to now is the magnitude of the gradient. Indeed, back in the 80&#x27;s some fundamental works [37, 53] theorized, through a Taylor decomposition of the impact of removing a parameter on the loss, that some metrics, derived from the back-propagated gradient, may provide a good way to determine which parameters could be pruned without damaging the network.</p><p id="50c3" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">More modern implementations of this criterion [4, 50] actually accumulate gradients over a minibatch of training data and prune on the basis of the product between this gradient and the corresponding weight of each parameter. This criterion can be applied to the aforementioned gates too [49].</p><h2 id="f74e" class="pv ob gq be oc pw px dx of py pz dz oi nn qa qb qc nr qd qe qf nv qg qh qi qj bj">2.3 — Global or local pruning</h2><p id="7f2b" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">One final aspect to take into consideration is whether the chosen criterion is applied globally to all parameters or filters of the network, or if it is computed independently for each layer. While global pruning has proven many times to yield better results, it can lead to layer collapse [62]. A simple way to avoid this problem is to resort to layer-wise local pruning, namely pruning the same rate at each layer, when the used method cannot prevent layer collapse.</p><figure class="pe pf pg ph pi pj pb pc paragraph-image"><div role="button" tabindex="0" class="pk pl ff pm bg pn"><div class="pb pc qn"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*rMLCgVa380ZBcgM0Iqg84Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*rMLCgVa380ZBcgM0Iqg84Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*rMLCgVa380ZBcgM0Iqg84Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*rMLCgVa380ZBcgM0Iqg84Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*rMLCgVa380ZBcgM0Iqg84Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*rMLCgVa380ZBcgM0Iqg84Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*rMLCgVa380ZBcgM0Iqg84Q.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg po pp c" width="700" height="301" loading="lazy" role="presentation"/></picture></div></div><figcaption class="pq pr ps pb pc pt pu be b bf z dt">Difference between local pruning (left) and global pruning (right): local pruning applies the same rate to each layer while global applies it on the whole network at once. (image by author)</figcaption></figure><h1 id="703c" class="oa ob gq be oc od oe hq of og oh ht oi oj ok ol om on oo op oq or os ot ou ov bj">3 — Pruning method</h1><p id="e967" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">Now that we have got our pruning structure and criterion, the only parameter left is which method should we use to prune a network. This is actually the topic on which the literature can be the most confusing, as each paper will bring its own quirks and gimmicks, so much that one may get lost between what is methodically relevant and what is just a specificity of a given paper.</p><p id="7b8d" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">This is why we will thematically overview some of the most popular families of method to prune neural networks, in an order that highlights the evolution of the use of sparsity during training.</p><h2 id="45d5" class="pv ob gq be oc pw px dx of py pz dz oi nn qa qb qc nr qd qe qf nv qg qh qi qj bj">3.1 — The classic framework: train, prune and fine-tune</h2><p id="f197" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">The first basic framework to know is the train, prune and fine-tune method, which obviously involves 1) training the network 2) pruning it by setting to 0 all parameters targeted by the pruning structures and criterion (these parameters cannot recover afterwhile) and 3) training the network for a few extra epochs, with the lowest learning rate, to give it a chance to recover from the loss in performance induced by pruning. Usually, these last two steps can be iterated, with each time a growing pruning rate.</p><p id="50e4" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">The method proposed by Han et al. [26] applies this method, with 5 iterations between pruning and fine-tuning, to weight magnitude pruning. Iterating has shown to improve performance, at the cost of extra computation and training time. This simple framework serves as a basis for many works [26, 40, 41, 50, 66] and can be seen as the default method over which all the others have built.</p><h2 id="62f4" class="pv ob gq be oc pw px dx of py pz dz oi nn qa qb qc nr qd qe qf nv qg qh qi qj bj">3.2 — Extending the classic framework</h2><p id="3d86" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">While not straying too far, some methods have brought significant modifications to the aforementioned classic framework by Han et al. [26]. Gale et al. [21] have pushed the principle of iterations further by removing an increasing amount of weights progressively all along the training process, which allows benefiting from the advantages of iterations and to remove the whole fine-tuning process. He et al. [29] reduce prunable filters to 0, at each epoch, while not preventing them from learning and being updated afterward, in order to let their weights grow back after pruning while enforcing sparsity during training.</p><p id="67de" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">Finally, the method of Renda et al. [58] involves fully retraining a network once it is pruned. Unlike fine-tuning, which is performed at the lowest learning-rate, retraining follows the same learning-rate schedule as training, hence its name: “Learning-Rate Rewinding”. This retraining has shown to yield better performance than mere fine-tuning, at a significantly higher cost.</p><h2 id="062d" class="pv ob gq be oc pw px dx of py pz dz oi nn qa qb qc nr qd qe qf nv qg qh qi qj bj">3.3 — Pruning at initialization</h2><p id="6ba9" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">In order to speed up training, avoid fine-tuning and prevent any alteration of the architecture during or after training, multiple works have focused on pruning before training. In the wake of SNIP [39], many works have studied the use of the work of Le Cun et al. [37] or of Mozer and Smolensky [53] to prune at initialization [12, 64], including intensive theoretical studies [27, 38, 62]. However, Optimal Brain Damage [37] relies on multiple approximations including an “extremal” approximation that “assumes that parameter deletion will be performed after training has converged” [37]; this fact is rarely mentioned, even among works that are based on it. Some works have raised reservations about the ability of such methods to generate masks whose relevance outshines random ones of similar distribution per layer [20].</p><p id="98e1" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">Another family of methods that study the relationship between pruning and initialization gravitates around the “Lottery Ticket Hypothesis” [18]. This hypothesis states that “randomly-initialized, dense neural network contains a subnet-work that is initialized such that — when trained in isolation — it can match the test accuracy of the original network after training for at most the same number of iterations”. In practice, this literature studies how well a pruning mask, defined using an already converged network, can be applied to the network back when it was just initialized. Multiple works have expanded, stabilized or studied this hypothesis [14, 19, 45, 51, 69]. However, once again multiple works tend to question the validity of the hypothesis and of the method used to study it [21, 42] and some even tend to show that its benefits rather came from the principle of fully training with the definitive mask instead of a hypothetical “Winning Ticket” [58].</p><figure class="pe pf pg ph pi pj pb pc paragraph-image"><div role="button" tabindex="0" class="pk pl ff pm bg pn"><div class="pb pc qo"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*ALVyE5U7jC692UGVKCVY8Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ALVyE5U7jC692UGVKCVY8Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ALVyE5U7jC692UGVKCVY8Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ALVyE5U7jC692UGVKCVY8Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ALVyE5U7jC692UGVKCVY8Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ALVyE5U7jC692UGVKCVY8Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*ALVyE5U7jC692UGVKCVY8Q.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg po pp c" width="700" height="286" loading="lazy" role="presentation"/></picture></div></div><figcaption class="pq pr ps pb pc pt pu be b bf z dt">Comparison between the classic “train, prune and fine-tune” framework [26], the lottery ticket experiment [18] and learning rate rewinding [58]. (image by author)</figcaption></figure><h2 id="0d30" class="pv ob gq be oc pw px dx of py pz dz oi nn qa qb qc nr qd qe qf nv qg qh qi qj bj">3.4 — Sparse training</h2><p id="fd21" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">The previous methods are linked by a seemingly shared underlying theme: training under sparsity constraints. This principle is at the core of a family of methods, called <strong class="ng gr">sparse training</strong>, which consists in enforcing a constant rate of sparsity during training while its distribution varies and is progressively adjusted. Introduced by Mocanu et al. [47], it involves: 1) initializing the network with a random mask that prunes a certain proportion of the network 2) training this pruned network during one epoch 3) pruning a certain amount of weights of lower magnitude and 4) regrowing the same amount of random weights.</p><p id="4cad" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">That way, the pruning mask, at first random, is progressively adjusted to target the least import weights while enforcing sparsity all throughout training. The sparsity level can be the same for each layer [47] or global [52]. Other methods have extended sparse training by using a certain criterion to regrow weights instead of choosing them randomly [15, 17].</p><figure class="pe pf pg ph pi pj pb pc paragraph-image"><div role="button" tabindex="0" class="pk pl ff pm bg pn"><div class="pb pc qn"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*3hP9xPMOSnsxqtLIvGrhOA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*3hP9xPMOSnsxqtLIvGrhOA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*3hP9xPMOSnsxqtLIvGrhOA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*3hP9xPMOSnsxqtLIvGrhOA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*3hP9xPMOSnsxqtLIvGrhOA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*3hP9xPMOSnsxqtLIvGrhOA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*3hP9xPMOSnsxqtLIvGrhOA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg po pp c" width="700" height="416" loading="lazy" role="presentation"/></picture></div></div><figcaption class="pq pr ps pb pc pt pu be b bf z dt">Sparse training cuts and grows different weights periodically during training, which leads to an adjusted mask that should target only relevant parameters. (image by author)</figcaption></figure><h2 id="f9f3" class="pv ob gq be oc pw px dx of py pz dz oi nn qa qb qc nr qd qe qf nv qg qh qi qj bj">3.5 — Mask learning</h2><p id="88ec" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">Instead of relying on arbitrary criteria to prune or regrow weights, multiple methods focus on learning a pruning mask during training. Two types of methods seem to prevail in this domain: 1) mask learning through separate networks or layers and 2) mask learning through auxiliary parameters. Multiple kinds of strategies can fit in the methods of the first type: training separate agents to prune as many filters of a layer as possible while maximizing the accuracy [33], inserting attention-based layers [68] or using reinforcement learning [30]. The second kind of methods aims at considering pruning as an optimization problem that tends to minimize both the L0 norm of the network and its supervised loss.</p><p id="1475" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">Since the L0 is non-differentiable, the various methods mainly involve circumventing this problem through the use of penalized auxiliary parameters that are multiplied with their corresponding parameter during the forward pass [59, 23]. Many methods [44, 60, 67] rely on a method analogous to that of “Binary Connect” [11], namely: applying stochastic gates over parameters whose values are each randomly drawn from their own Bernoulli distribution of parameter <em class="qk">p</em> that is learned using a “Straight Through Estimator” [3] or other means [44].</p><h2 id="7a36" class="pv ob gq be oc pw px dx of py pz dz oi nn qa qb qc nr qd qe qf nv qg qh qi qj bj">3.6 — Penalty-based methods</h2><p id="b905" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">Many methods, instead of pruning connections manually or penalizing auxiliary parameters, rather apply various kinds of penalties to weights themselves to make them progressively shrink toward 0. This notion is actually pretty ancient [57], as weight-decay is already an essential element to the weight magnitude criterion. Beyond using a mere weight-decay, even back then multiple works focused on elaborating penalties specifically designed to enforce sparsity [55, 65]. Today, various methods apply different regularizations, on top of the weight decay, to increase further the sparsity (typically, using L 1 norm [41]).</p><p id="ba3b" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">Among modern works, multiple methods rely on the LASSO (Least Absolute Shrinkage and Selection Operator) [22, 31, 66] to prune weights or groups. Other methods develop penalties that target weak connections to increase the gap between the parameters to keep and those to prune, so that their removal has less impact [7, 16]. Some methods show that targeting a subset of weights with a penalization that grows all throughout training can progressively prune them and make their removal seamless [6, 9, 63]. The literature also counts a whole range of methods built around the principle of “Variational Dropout” [34], a method based on variational inference [5] applied to deep learning [35]. As a pruning method [48], it birthed multiple works that adapt its principle to structured pruning [43, 54].</p><h1 id="344e" class="oa ob gq be oc od oe hq of og oh ht oi oj ok ol om on oo op oq or os ot ou ov bj">4 — Available frameworks</h1><p id="d420" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">If most of these methods have to be implemented from scratch (or can be reused from the provided sources of each paper, if they do provide them), some frameworks exist to apply basic methods or make the aforementioned implementation easier.</p><h2 id="1145" class="pv ob gq be oc pw px dx of py pz dz oi nn qa qb qc nr qd qe qf nv qg qh qi qj bj">4.1 — Pytorch</h2><p id="9c63" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj"><em class="qk">Pytorch</em> [56] provide multiple quality-of-life features to help pruning networks. The provided tools allow to easily apply a mask to a network and maintain this mask during training, as well as it allows to easily revert that mask if needed. Pytorch also provide some basic pruning methods, such as global or local pruning, whether it is structured or not. Structured pruning can be applied on any dimension of the weights tensors, which lets pruning filters, rows of kernels or even some rows and columns inside kernels. Those in-built basic methods also allow pruning randomly or depending on various norms.</p><h2 id="3f1c" class="pv ob gq be oc pw px dx of py pz dz oi nn qa qb qc nr qd qe qf nv qg qh qi qj bj">4.2 — Tensorflow</h2><p id="db73" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">The <em class="qk">Keras</em> [10] library from <em class="qk">Tensorflow</em> [1] provide some basic tools to prune weights of lower magnitudes. Such as in the work of Han et al [25], the efficiency of pruning is measured in terms of how much does the redundancy, introduced by all the inserted zeros, allows to compress the model better (which combines well with quantization).</p><h2 id="c61c" class="pv ob gq be oc pw px dx of py pz dz oi nn qa qb qc nr qd qe qf nv qg qh qi qj bj">4.3 — ShrinkBench</h2><p id="29c2" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">Blalock et al. [4] provide in their work a custom library in an effort to help the community normalize how pruning algorithm are compared. Based on <em class="qk">Pytorch</em>, <em class="qk">ShrinkBench</em> aims at making the implementation of pruning methods easier while normalizing the conditions under which they are trained and tested. It provides different baselines, such as random pruning, global or layerwise and weight magnitude or gradient magnitude pruning.</p><h1 id="0db7" class="oa ob gq be oc od oe hq of og oh ht oi oj ok ol om on oo op oq or os ot ou ov bj">5 — Brief recap of reviewed methods</h1><p id="4f0a" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">In this article, many papers have been cited. Here is a simple table to roughly summarize what they do and what differentiates them (provided dates are those of first publication):</p><figure class="pe pf pg ph pi pj"><div class="qp jt l ff"><div class="qq qr l"></div></div></figure><h1 id="5fc5" class="oa ob gq be oc od oe hq of og oh ht oi oj ok ol om on oo op oq or os ot ou ov bj">6 — Conclusion</h1><p id="dbd7" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">In our quick overview of the literature, we saw that 1) pruning structures define which kind of gain to expect from pruning 2) pruning criteria are based on various theoretical or practical justifications and 3) pruning methods tend to revolve around introducing sparsity during training to reconcile performance and cost. We also saw that, even though its founding works date back from the late 80’s, neural network pruning is a very dynamic field that still experiences fundamental discoveries and new basic concepts today.</p><p id="8cda" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">Despite the daily contributions in the domain, there seems to be still plenty of room for exploration and innovation. If each subfamily of method can be seen as an attempt to answer a question (“How to regrow pruned weights ?”, “How to learn pruning masks through optimization ?”, “How to relax the weight removal by a softer mean ?”…), then the evolution of the literature seems to point out a certain direction: that of sparsity throughout training. This direction raises itself many questions, such as: “do pruning criteria work well on networks that haven’t converged yet?” or “how to tell the benefit of the choice of the weights to prune from that of training with any kind of sparsity from the start?”</p><h1 id="b0a7" class="oa ob gq be oc od oe hq of og oh ht oi oj ok ol om on oo op oq or os ot ou ov bj">References</h1><p id="333c" class="pw-post-body-paragraph ne nf gq ng b ho ow ni nj hr ox nl nm nn oy np nq nr oz nt nu nv pa nx ny nz gj bj">[1] Martı́n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from tensorflow.org.</p><p id="1fba" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[2] Sajid Anwar, Kyuyeon Hwang, and Wonyong Sung. Structured pruning of deep convolutional neural networks. ACM Journal on Emerging Technologies in Computing Systems (JETC), 13(3):1–18, 2017.</p><p id="9ab6" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[3] Yoshua Bengio, Nicholas Léonard, and Aaron Courville. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013.</p><p id="4225" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[4] Davis Blalock, Jose Javier Gonzalez Ortiz, Jonathan Frankle, and John Guttag. What is the state of neural network pruning? arXiv preprint arXiv:2003.03033, 2020.</p><p id="1893" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[5] David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: A review for statisticians. Journal of the American statistical Association, 112(518):859–877, 2017.</p><p id="4edf" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[6] Miguel A Carreira-Perpinán and Yerlan Idelbayev. “learning-compression” algorithms for neural net pruning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8532–8541, 2018.</p><p id="5a92" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[7] Jing Chang and Jin Sha. Prune deep neural networks with the modified L1/2 penalty. IEEE Access, 7:2273–2280, 2018.</p><p id="7d74" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[8] Yves Chauvin. A back-propagation algorithm with optimal use of hidden units. In NIPS, volume 1, pages 519–526, 1988.</p><p id="2b0e" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[9] Yoojin Choi, Mostafa El-Khamy, and Jungwon Lee. Compression of deep convolutional neural networks under joint sparsity constraints. arXiv preprint arXiv:1805.08303, 2018.</p><p id="5860" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[10] Francois Chollet et al. Keras, 2015.</p><p id="a78f" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[11] Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. Binaryconnect: Training deep neural networks with binary weights during propagations. In NIPS, 2015.</p><p id="f314" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[12] Pau de Jorge, Amartya Sanyal, Harkirat S Behl, Philip HS Torr, Gregory Rogez, and Puneet K Dokania. Progressive skeletonization: Trimming more fat from a network at initialization. arXiv preprint arXiv:2006.09081, 2020.</p><p id="5849" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[13] Emily Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus. Exploiting linear structure within convolutional networks for efficient evaluation. In 28th Annual Conference on Neural Information Processing Systems 2014, NIPS 2014, pages 1269–1277. Neural information processing systems foundation, 2014.</p><p id="2aed" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[14] Shrey Desai, Hongyuan Zhan, and Ahmed Aly. Evaluating lottery tickets under distributional shifts. In Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019), pages 153–162, 2019.</p><p id="eb74" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[15] Tim Dettmers and Luke Zettlemoyer. Sparse networks from scratch: Faster training without losing performance. arXiv preprint arXiv:1907.04840, 2019.</p><p id="b415" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[16] Xiaohan Ding, Guiguang Ding, Xiangxin Zhou, Yuchen Guo, Jungong Han, and Ji Liu. Global sparse momentum sgd for pruning very deep neural networks. arXiv preprint arXiv:1909.12778, 2019.</p><p id="f184" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[17] Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, and Erich Elsen. Rigging the lottery: Making all tickets winners. In International Conference on Machine Learning, pages 2943–2952. PMLR, 2020.</p><p id="bf6f" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[18] Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635, 2018.</p><p id="3617" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[19] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Stabilizing the lottery ticket hypothesis. arXiv preprint arXiv:1903.01611, 2019.</p><p id="58c0" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[20] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Pruning neural networks at initialization: Why are we missing the mark? arXiv preprint arXiv:2009.08576, 2020.</p><p id="4f5f" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[21] Trevor Gale, Erich Elsen, and Sara Hooker. The state of sparsity in deep neural networks. arXiv preprint arXiv:1902.09574, 2019.</p><p id="74d8" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[22] Susan Gao, Xin Liu, Lung-Sheng Chien, William Zhang, and Jose M Alvarez. Vacl: Variance-aware cross-layer regularization for pruning deep residual networks. In Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops, pages 0–0, 2019.</p><p id="a37e" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[23] Yiwen Guo, Anbang Yao, and Yurong Chen. Dynamic network surgery for efficient dnns. In NIPS, 2016.</p><p id="771a" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[24] Ghouthi Boukli Hacene, Carlos Lassance, Vincent Gripon, Matthieu Courbariaux, and Yoshua Bengio. Attention based pruning for shift networks. In 2020 25th International Conference on Pattern Recognition (ICPR), pages 4054–4061. IEEE, 2021.</p><p id="c933" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[25] Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015.</p><p id="a6e9" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[26] Song Han, Jeff Pool, John Tran, and William J Dally. Learning both weights and connections for efficient neural network. In NIPS, 2015.</p><p id="3b8d" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[27] Soufiane Hayou, Jean-Francois Ton, Arnaud Doucet, and Yee Whye Teh. Robust pruning at initialization.</p><p id="ff92" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[28] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.</p><p id="9f85" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[29] Yang He, Guoliang Kang, Xuanyi Dong, Yanwei Fu, and Yi Yang. Soft filter pruning for accelerating deep convolutional neural networks. arXiv preprint arXiv:1808.06866, 2018.</p><p id="14d2" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[30] Yihui He, Ji Lin, Zhijian Liu, Hanrui Wang, Li-Jia Li, and Song Han. Amc: Automl for model compression and acceleration on mobile devices. In Proceedings of the European Conference on Computer Vision (ECCV), pages 784–800, 2018.</p><p id="af2f" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[31] Yihui He, Xiangyu Zhang, and Jian Sun. Channel pruning for accelerating very deep neural networks. In Proceedings of the IEEE International Conference on Computer Vision, pages 1389–1397, 2017.</p><p id="7371" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[32] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. stat, 1050:9, 2015.</p><p id="55ce" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[33] Qiangui Huang, Kevin Zhou, Suya You, and Ulrich Neumann. Learning to prune filters in convolutional neural networks. In 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), pages 709–718. IEEE, 2018.</p><p id="3f8f" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[34] Diederik P Kingma, Tim Salimans, and Max Welling. Variational dropout and the local reparameterization trick. stat, 1050:8, 2015.</p><p id="93d7" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[35] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. stat, 1050:1, 2014.</p><p id="38d1" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[36] John K Kruschke and Javier R Movellan. Benefits of gain: Speeded learning and minimal hidden layers in back-propagation networks. IEEE Transactions on systems, Man, and Cybernetics, 21(1):273–280, 1991.</p><p id="1b89" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[37] Yann LeCun, John S Denker, and Sara A Solla. Optimal brain damage. In Advances in neural information processing systems, pages 598–605, 1990.</p><p id="b9d6" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[38] Namhoon Lee, Thalaiyasingam Ajanthan, Stephen Gould, and Philip HS Torr. A signal propagation perspective for pruning neural networks at initialization. In International Conference on Learning Representations, 2019.</p><p id="c8c3" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[39] Namhoon Lee, Thalaiyasingam Ajanthan, and Philip HS Torr. Snip: Single-shot network pruning based on connection sensitivity. International Conference on Learning Representations, ICLR, 2019.</p><p id="fa53" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[40] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning filters for efficient convnets. arXiv preprint arXiv:1608.08710, 2016.</p><p id="5975" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[41] Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan, and Changshui Zhang. Learning efficient convolutional networks through network slimming. In Proceedings of the IEEE International Conference on Computer Vision, pages 2736–2744, 2017.</p><p id="3879" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[42] Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, and Trevor Darrell. Rethinking the value of network pruning. In International Conference on Learning Representations, 2018.</p><p id="8d02" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[43] C Louizos, K Ullrich, and M Welling. Bayesian compression for deep learning. In 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA., 2017.</p><p id="eb44" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[44] Christos Louizos, Max Welling, and Diederik P Kingma. Learning sparse neural networks through l 0 regularization. arXiv preprint arXiv:1712.01312, 2017.</p><p id="4866" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[45] Eran Malach, Gilad Yehudai, Shai Shalev-Schwartz, and Ohad Shamir. Proving the lottery ticket hypothesis: Pruning is all you need. In International Conference on Machine Learning, pages 6682–6691. PMLR, 2020.</p><p id="235f" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[46] Huizi Mao, Song Han, Jeff Pool, Wenshuo Li, Xingyu Liu, Yu Wang, and William J Dally. Exploring the regularity of sparse structure in convolutional neural networks. arXiv preprint arXiv:1705.08922, 2017.</p><p id="6721" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[47] Decebal Constantin Mocanu, Elena Mocanu, Peter Stone, Phuong H Nguyen, Madeleine Gibescu, and Antonio Liotta. Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science. Nature communications, 9(1):1–12, 2018.</p><p id="2a85" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[48] Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Variational dropout sparsifies deep neural networks. In International Conference on Machine Learning, pages 2498–2507. PMLR, 2017.</p><p id="9f44" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[49] Pavlo Molchanov, Arun Mallya, Stephen Tyree, Iuri Frosio, and Jan Kautz. Importance estimation for neural network pruning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11264–11272, 2019.</p><p id="1ef1" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[50] Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila, and Jan Kautz. Pruning convolutional neural networks for resource efficient inference. arXiv preprint arXiv:1611.06440, 2016.</p><p id="aa9b" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[51] Ari S Morcos, Haonan Yu, Michela Paganini, and Yuandong Tian. One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers. stat, 1050:6, 2019.</p><p id="79eb" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[52] Hesham Mostafa and Xin Wang. Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization. In International Conference on Machine Learning, pages 4646–4655. PMLR, 2019.</p><p id="ce0a" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[53] Michael C Mozer and Paul Smolensky. Skeletonization: A technique for trimming the fat from a network via relevance assessment. In Advances in neural information processing systems, pages 107–115, 1989.</p><p id="d3f1" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[54] Kirill Neklyudov, Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Structured bayesian pruning via log-normal multiplicative noise. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pages 6778–6787, 2017.</p><p id="bc88" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[55] Steven J Nowlan and Geoffrey E Hinton. Simplifying neural networks by soft weight-sharing. Neural Computation, 4(4):473–493, 1992.</p><p id="b046" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[56] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.</p><p id="d7b3" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[57] Russell Reed. Pruning algorithms-a survey. IEEE transactions on Neural Networks, 4(5):740–747, 1993.</p><p id="3bf3" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[58] Alex Renda, Jonathan Frankle, and Michael Carbin. Comparing rewinding and fine-tuning in neural network pruning. arXiv preprint arXiv:2003.02389, 2020.</p><p id="3d25" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[59] Pedro Savarese, Hugo Silva, and Michael Maire. Winning the lottery with continuous sparsification. Advances in Neural Information Processing Systems, 33, 2020.</p><p id="5eb0" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[60] Suraj Srinivas, Akshayvarun Subramanya, and R Venkatesh Babu. Training sparse neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pages 138–145, 2017.</p><p id="5fd8" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[61] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1–9, 2015.</p><p id="1d5f" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[62] Hidenori Tanaka, Daniel Kunin, Daniel L Yamins, and Surya Ganguli. Pruning neural networks without any data by iteratively conserving synaptic flow. Advances in Neural Information Processing Systems, 33, 2020.</p><p id="44d2" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[63] Hugo Tessier, Vincent Gripon, Mathieu Léonardon, Matthieu Arzel, Thomas Hannagan, and David Bertrand. Rethinking weight decay for efficient neural network pruning. 2021.</p><p id="1727" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[64] Chaoqi Wang, Guodong Zhang, and Roger Grosse. Picking winning tickets before training by preserving gradient flow. In International Conference on Learning Representations, 2019.</p><p id="c94b" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[65] Andreas S Weigend, David E Rumelhart, and Bernardo A Huberman. Generalization by weight-elimination with application to forecasting. In Advances in neural information processing systems, pages 875–882, 1991.</p><p id="ce36" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[66] Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Learning structured sparsity in deep neural networks. In NIPS, 2016.</p><p id="45b5" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[67] Xia Xiao, Zigeng Wang, and Sanguthevar Rajasekaran. Autoprune: Automatic network pruning by regularizing auxiliary parameters. Advances in neural information processing systems, 32, 2019.</p><p id="8e2b" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[68] Kohei Yamamoto and Kurato Maeno. Pcas: Pruning channels with attention statistics for deep network compression. arXiv preprint arXiv:1806.05382, 2018.</p><p id="7479" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[69] Hattie Zhou, Janice Lan, Rosanne Liu, and Jason Yosinski. Deconstructing lottery tickets: Zeros, signs, and the supermask. arXiv preprint arXiv:1905.01067, 2019.</p><p id="726f" class="pw-post-body-paragraph ne nf gq ng b ho nh ni nj hr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz gj bj">[70] Zhuangwei Zhuang, Mingkui Tan, Bohan Zhuang, Jing Liu, Yong Guo, Qingyao Wu, Junzhou Huang, and Jin-Hui Zhu. Discrimination-aware channel pruning for deep neural networks. In NeurIPS, 2018.</p></div></div></div></div></section></div></div></article><div class="ab ca"><div class="ch bg fv fw fx fy"></div></div></div><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="qs qt ab jo"><div class="qu ab"><a class="qv ax am ao" href="https://medium.com/tag/neural-networks?source=post_page-----af816aaea61---------------neural_networks-----------------" rel="noopener follow"><div class="qw ff cw qx ax qy qz be b bf z bj ra">Neural Networks</div></a></div><div class="qu ab"><a class="qv ax am ao" href="https://medium.com/tag/pruning?source=post_page-----af816aaea61---------------pruning-----------------" rel="noopener follow"><div class="qw ff cw qx ax qy qz be b bf z bj ra">Pruning</div></a></div><div class="qu ab"><a class="qv ax am ao" href="https://medium.com/tag/compression?source=post_page-----af816aaea61---------------compression-----------------" rel="noopener follow"><div class="qw ff cw qx ax qy qz be b bf z bj ra">Compression</div></a></div><div class="qu ab"><a class="qv ax am ao" href="https://medium.com/tag/deep-learning?source=post_page-----af816aaea61---------------deep_learning-----------------" rel="noopener follow"><div class="qw ff cw qx ax qy qz be b bf z bj ra">Deep Learning</div></a></div><div class="qu ab"><a class="qv ax am ao" href="https://medium.com/tag/deep-dives?source=post_page-----af816aaea61---------------deep_dives-----------------" rel="noopener follow"><div class="qw ff cw qx ax qy qz be b bf z bj ra">Deep Dives</div></a></div></div></div></div><div class="l"></div><footer class="rb rc rd re rf rg rh ri rj ab q rk iy c"><div class="l ae"><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="ab co rl"><div class="ab q lj"><div class="rm l"><span class="l rn ro rp e d"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=-----af816aaea61---------------------clap_footer-----------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div></span><span class="l h g f rq rr"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=-----af816aaea61---------------------clap_footer-----------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div></span></div><div class="bp ab"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class="mc"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b bf z dt"><span class="pw-responses-count mg mc">2</span></p></button></div></div></div></div><div class="ab q"><div class="rs l jl"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=--------------------------bookmark_footer-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af fg ah ai aj ak al mj an ao ap eu mk ml mm"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div></div><div class="rs l jl"><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button class="af fg ah ai aj ak al mj an ao ap eu mn mo mf mp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="rt ru rv rw rx l bw"><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="ck ab ry co"><div class="ab in"><a href="https://medium.com/@hugo.tessier?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><div class="l rz sa bx sb ir"><div class="l ff"><img alt="Hugo Tessier" class="l fa bx sc sd cw" src="https://miro.medium.com/v2/resize:fill:144:144/1*PAy1sna3YNoKY4jQl9znVw.jpeg" width="72" height="72" loading="lazy"/><div class="is bx l sc sd fo n it iu"></div></div></div></a><a href="https://towardsdatascience.com/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><div class="se ab ff"><div><div class="bl" aria-hidden="false"><div class="l sf sg bx sb iy"><div class="l ff"><img alt="Towards Data Science" class="l fa bx by bz cw" src="https://miro.medium.com/v2/resize:fill:64:64/1*CJe3891yB1A1mzMdqemkdg.jpeg" width="32" height="32" loading="lazy"/><div class="is bx l by bz fo n it iu"></div></div></div></div></div></div></a></div><div class="j i d"><div class="ab"><span><a class="be b bf z el qw em eo ep eq er es et eu ev ew ex sh ey ez fa bl fb" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F524f24852f3c&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=post_page-524f24852f3c----af816aaea61---------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="ds l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F71cc63d0ec07&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;newsletterV3=524f24852f3c&amp;newsletterV3Id=71cc63d0ec07&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=-----af816aaea61---------------------subscribe_user-----------" rel="noopener follow"><button class="be b bf z sj am sk sl sm sn so sp sq sr et eu ev ew ex ey ez fa bl fb" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="si sg sf"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="ab cm co"><div class="l"><div class="ab q"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab q" href="https://medium.com/@hugo.tessier?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><h2 class="pw-author-name be ss st su sv bj"><span class="gj">Written by <!-- -->Hugo Tessier</span></h2></a></div><div class="qu ab"><div class="l jl"><span class="pw-follower-count be b bf z bj"><a class="af ag ah ai aj ak al am an ao ap aq ar je" href="https://medium.com/@hugo.tessier/followers?source=post_page-----af816aaea61--------------------------------" rel="noopener follow">53 Followers</a></span></div><div class="be b bf z jt ju jv ab jx jy jz ka dt jr"><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span class="l jl">Writer for </span><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><p class="be b bf z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="sw l"><p class="be b bf z bj"><span class="gj">PHD student in deep learning, working on neural network compression and, especially, pruning.</span></p></div></div><div class="h k"><div class="ab"><span><a class="be b bf z el qw em eo ep eq er es et eu ev ew ex sh ey ez fa bl fb" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F524f24852f3c&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=post_page-524f24852f3c----af816aaea61---------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="ds l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F71cc63d0ec07&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;newsletterV3=524f24852f3c&amp;newsletterV3Id=71cc63d0ec07&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=-----af816aaea61---------------------subscribe_user-----------" rel="noopener follow"><button class="be b bf z sj am sk sl sm sn so sp sq sr et eu ev ew ex ey ez fa bl fb" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="si sg sf"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="sx bg sy sz ta tb tc td"></div></div></div><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="to tp l"><h2 class="be ss jc z gp bj">More from <!-- -->Hugo Tessier<!-- --> and Towards Data Science</h2></div><div class="tq ab lj jo tr ts tt tu tv tw tx ty tz ua ub uc ud ue uf"><div class="ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va"><div class="vb vc vd ve vf dv l"><article class="dv"><div class="dv rj l"><div class="bg dv"><div class="dv l"><div class="dv vg vh vi vj vk vl vm vn vo vp vq vr vs"><div class="vt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" rel="noopener follow" href="/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----af816aaea61----0---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------"><div class="vv vw vx vy vz"><img alt="" class="bg wa wb wc wd" src="https://miro.medium.com/v2/resize:fit:1358/1*rsp22rKwFDjiwwCcUly56Q.jpeg" loading="lazy" role="presentation"/></div></a></div><div class="vu ab ca cn"><div class="we wf wg wh wi ab"><div class="qv l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@jacob_marks?source=author_recirc-----af816aaea61----0---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><div class="l ff"><img alt="Jacob Marks, Ph.D." class="l fa bx wj wk cw" src="https://miro.medium.com/v2/resize:fill:40:40/0*YukZswf8UB1bQdTV" width="20" height="20" loading="lazy"/><div class="fn bx l wj wk fo n ax iu"></div></div></a></div></div></div><div class="wl l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/@jacob_marks?source=author_recirc-----af816aaea61----0---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Jacob Marks, Ph.D.</p></a></div></div></div><div class="wl l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=author_recirc-----af816aaea61----0---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="wm wn wo wp wq wr ws wt wu wv l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" rel="noopener follow" href="/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----af816aaea61----0---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------"><div title=""><h2 class="be gr od hq ww wx of og ht wy wz oi nn qb xa xb qc nr qe xc xd qf nv qh xe xf qi jt jv jw jy ka bj">How I Turned My Company’s Docs into a Searchable Database with OpenAI</h2></div><div class="xg l"><h3 class="be b jc z jt xh jv jw xi jy ka dt">And how you can do the same with your docs</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" rel="noopener follow" href="/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----af816aaea61----0---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------"><span class="be b du z dt"><div class="ab q"><span>15 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Apr 25</span></div></span></a><div class="xj xk xl xm xn l"><div class="ab co"><div class="am xo xp xq xr xs xt xu xv xw xx ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&amp;user=Jacob+Marks%2C+Ph.D.&amp;userId=f7dc0c0eae92&amp;source=-----4f2d34bd8736----0-----------------clap_footer----43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="xy l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----af816aaea61----0---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">39</span></p></button></div></div></a></div></div><div class="ab q xz ya"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&amp;source=-----af816aaea61----0-----------------bookmark_preview----43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="sx bg sy yb"></div></div></div></div></div></div></div></article></div></div><div class="ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va"><div class="vb vc vd ve vf dv l"><article class="dv"><div class="dv rj l"><div class="bg dv"><div class="dv l"><div class="dv vg vh vi vj vk vl vm vn vo vp vq vr vs"><div class="vt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" rel="noopener follow" href="/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c?source=author_recirc-----af816aaea61----1---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------"><div class="vv vw vx vy vz"><img alt="Two stochastic parrots sitting on a chain of large language models: LangChain" class="bg wa wb wc wd" src="https://miro.medium.com/v2/resize:fit:1358/1*4C54ZxHRM1dOlAvlvoEJZg@2x.jpeg" loading="lazy"/></div></a></div><div class="vu ab ca cn"><div class="we wf wg wh wi ab"><div class="qv l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@iamleonie?source=author_recirc-----af816aaea61----1---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><div class="l ff"><img alt="Leonie Monigatti" class="l fa bx wj wk cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*TTIl4oynrJyfIkLbC6fumA.png" width="20" height="20" loading="lazy"/><div class="fn bx l wj wk fo n ax iu"></div></div></a></div></div></div><div class="wl l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/@iamleonie?source=author_recirc-----af816aaea61----1---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Leonie Monigatti</p></a></div></div></div><div class="wl l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=author_recirc-----af816aaea61----1---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="wm wn wo wp wq wr ws wt wu wv l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" rel="noopener follow" href="/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c?source=author_recirc-----af816aaea61----1---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------"><div title="Getting Started with LangChain: A Beginner’s Guide to Building LLM-Powered Applications"><h2 class="be gr od hq ww wx of og ht wy wz oi nn qb xa xb qc nr qe xc xd qf nv qh xe xf qi jt jv jw jy ka bj">Getting Started with LangChain: A Beginner’s Guide to Building LLM-Powered Applications</h2></div><div class="xg l"><h3 class="be b jc z jt xh jv jw xi jy ka dt">A LangChain tutorial to build anything with large language models in Python</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" rel="noopener follow" href="/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c?source=author_recirc-----af816aaea61----1---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------"><span class="be b du z dt"><div class="ab q"><div class="rj ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>12 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Apr 25</span></div></span></a><div class="xj xk xl xm xn l"><div class="ab co"><div class="am xo xp xq xr xs xt xu xv xw xx ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F95fc8898732c&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c&amp;user=Leonie+Monigatti&amp;userId=3a38da70d8dc&amp;source=-----95fc8898732c----1-----------------clap_footer----43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="xy l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c?source=author_recirc-----af816aaea61----1---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">16</span></p></button></div></div></a></div></div><div class="ab q xz ya"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F95fc8898732c&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c&amp;source=-----af816aaea61----1-----------------bookmark_preview----43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="sx bg sy yb"></div></div></div></div></div></div></div></article></div></div><div class="ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va"><div class="vb vc vd ve vf dv l"><article class="dv"><div class="dv rj l"><div class="bg dv"><div class="dv l"><div class="dv vg vh vi vj vk vl vm vn vo vp vq vr vs"><div class="vt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" rel="noopener follow" href="/how-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79?source=author_recirc-----af816aaea61----2---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------"><div class="vv vw vx vy vz"><img alt="" class="bg wa wb wc wd" src="https://miro.medium.com/v2/resize:fit:1358/0*4ABoFdJClLr8QTK2" loading="lazy" role="presentation"/></div></a></div><div class="vu ab ca cn"><div class="we wf wg wh wi ab"><div class="qv l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@mattchapmanmsc?source=author_recirc-----af816aaea61----2---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><div class="l ff"><img alt="Matt Chapman" class="l fa bx wj wk cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*4EQrg_kfWhQfHyGeuIunfg.png" width="20" height="20" loading="lazy"/><div class="fn bx l wj wk fo n ax iu"></div></div></a></div></div></div><div class="wl l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/@mattchapmanmsc?source=author_recirc-----af816aaea61----2---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Matt Chapman</p></a></div></div></div><div class="wl l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=author_recirc-----af816aaea61----2---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="wm wn wo wp wq wr ws wt wu wv l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" rel="noopener follow" href="/how-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79?source=author_recirc-----af816aaea61----2---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------"><div title="How I Stay Up to Date With the Latest AI Trends as a Full-Time Data Scientist"><h2 class="be gr od hq ww wx of og ht wy wz oi nn qb xa xb qc nr qe xc xd qf nv qh xe xf qi jt jv jw jy ka bj">How I Stay Up to Date With the Latest AI Trends as a Full-Time Data Scientist</h2></div><div class="xg l"><h3 class="be b jc z jt xh jv jw xi jy ka dt">No, I don’t just ask ChatGPT to tell me</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" rel="noopener follow" href="/how-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79?source=author_recirc-----af816aaea61----2---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------"><span class="be b du z dt"><div class="ab q"><div class="rj ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>8 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>May 1</span></div></span></a><div class="xj xk xl xm xn l"><div class="ab co"><div class="am xo xp xq xr xs xt xu xv xw xx ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1e535dd0cd79&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79&amp;user=Matt+Chapman&amp;userId=bf7d13fc53db&amp;source=-----1e535dd0cd79----2-----------------clap_footer----43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="xy l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/how-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79?source=author_recirc-----af816aaea61----2---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">21</span></p></button></div></div></a></div></div><div class="ab q xz ya"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1e535dd0cd79&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79&amp;source=-----af816aaea61----2-----------------bookmark_preview----43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="sx bg sy yb"></div></div></div></div></div></div></div></article></div></div><div class="ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va"><div class="vb vc vd ve vf dv l"><article class="dv"><div class="dv rj l"><div class="bg dv"><div class="dv l"><div class="dv vg vh vi vj vk vl vm vn vo vp vq vr vs"><div class="vt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" rel="noopener follow" href="/the-best-learning-paths-for-ai-and-data-leadership-fabc3d4f8e36?source=author_recirc-----af816aaea61----3---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------"><div class="vv vw vx vy vz"><img alt="" class="bg wa wb wc wd" src="https://miro.medium.com/v2/resize:fit:1358/1*c85uL1F1VzlMtekbzObLaw.png" loading="lazy" role="presentation"/></div></a></div><div class="vu ab ca cn"><div class="we wf wg wh wi ab"><div class="qv l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://kozyrkov.medium.com/?source=author_recirc-----af816aaea61----3---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><div class="l ff"><img alt="Cassie Kozyrkov" class="l fa bx wj wk cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*IL0mnvzNcpG2ZD0JBqo7zQ.jpeg" width="20" height="20" loading="lazy"/><div class="fn bx l wj wk fo n ax iu"></div></div></a></div></div></div><div class="wl l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://kozyrkov.medium.com/?source=author_recirc-----af816aaea61----3---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Cassie Kozyrkov</p></a></div></div></div><div class="wl l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=author_recirc-----af816aaea61----3---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="wm wn wo wp wq wr ws wt wu wv l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" rel="noopener follow" href="/the-best-learning-paths-for-ai-and-data-leadership-fabc3d4f8e36?source=author_recirc-----af816aaea61----3---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------"><div title=""><h2 class="be gr od hq ww wx of og ht wy wz oi nn qb xa xb qc nr qe xc xd qf nv qh xe xf qi jt jv jw jy ka bj">The Best Learning Paths for AI and Data Leadership</h2></div><div class="xg l"><h3 class="be b jc z jt xh jv jw xi jy ka dt">How to muscle up on data-related topics quickly</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" rel="noopener follow" href="/the-best-learning-paths-for-ai-and-data-leadership-fabc3d4f8e36?source=author_recirc-----af816aaea61----3---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------"><span class="be b du z dt"><div class="ab q"><div class="rj ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>7 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Apr 30</span></div></span></a><div class="xj xk xl xm xn l"><div class="ab co"><div class="am xo xp xq xr xs xt xu xv xw xx ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffabc3d4f8e36&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-best-learning-paths-for-ai-and-data-leadership-fabc3d4f8e36&amp;user=Cassie+Kozyrkov&amp;userId=2fccb851bb5e&amp;source=-----fabc3d4f8e36----3-----------------clap_footer----43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="xy l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/the-best-learning-paths-for-ai-and-data-leadership-fabc3d4f8e36?source=author_recirc-----af816aaea61----3---------------------43c3c6ff_1671_4629_9343_8bcca9e0300c-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">8</span></p></button></div></div></a></div></div><div class="ab q xz ya"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffabc3d4f8e36&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-best-learning-paths-for-ai-and-data-leadership-fabc3d4f8e36&amp;source=-----af816aaea61----3-----------------bookmark_preview----43c3c6ff_1671_4629_9343_8bcca9e0300c-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div></div></div></div></div></div></article></div></div></div><div class="sx bg sy dj dk yc yd ye"></div><div class="ab jm jn yf yg yh"><a class="be b bf z bj qw av yi yj yk lp yl es et eu ym yn yo ex yp yq yr ys yt ey ez fa bl fb" href="https://medium.com/@hugo.tessier?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><div class="l pr">See all from <!-- -->Hugo Tessier</div></a><div class="yu yv yw yx yy yz za zb zc ma l"><a class="be b bf z bj qw av yi yj yk lp yl es et eu ym yn yo ex yp yq yr ys yt ey ez fa bl fb" href="https://towardsdatascience.com/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><div class="l pr">See all from <!-- -->Towards Data Science</div></a></div></div></div></div><div class="sx bg sy zd ze zf zg zh"></div><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="zi zj l"><h2 class="be ss od hq of og ht oi oj ol om on op oq or ot ou bj">Recommended from Medium</h2><div class="pe pf pg ph pi l"><div class="tq ab lj jo tr ts tt tu tv tw tx ty tz ua ub uc ud ue uf"><div class="ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va"><div class="vb vc vd ve vf dv l"><article class="dv"><div class="dv rj l"><div class="bg dv"><div class="dv l"><div class="dv vg vh vi vj vk vl vm vn vo vp vq vr vs"><div class="vt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" href="https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="vv vw vx vy vz"><img alt="" class="bg wa wb wc wd" src="https://miro.medium.com/v2/resize:fit:1358/1*FyaF0pPskcOtQ_MmEnBjZA.jpeg" loading="lazy" role="presentation"/></div></a></div><div class="vu ab ca cn"><div class="we wf wg wh wi ab"><div class="qv l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://alexcancode.medium.com/?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="l ff"><img alt="Alexander Nguyen" class="l fa bx wj wk cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*cwYWYCjbeXNc_pAtTeq_Zg.jpeg" width="20" height="20" loading="lazy"/><div class="fn bx l wj wk fo n ax iu"></div></div></a></div></div></div><div class="wl l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://alexcancode.medium.com/?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Alexander Nguyen</p></a></div></div></div><div class="wl l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://levelup.gitconnected.com/?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Level Up Coding</p></a></div></div></div></div><div class="wm wn wo wp wq wr ws wt wu wv l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" href="https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div title=""><h2 class="be gr od hq ww wx of og ht wy wz oi nn qb xa xb qc nr qe xc xd qf nv qh xe xf qi jt jv jw jy ka bj">Why I Keep Failing Candidates During Google Interviews…</h2></div><div class="xg l"><h3 class="be b jc z jt xh jv jw xi jy ka dt">They don’t meet the bar.</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" href="https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><span class="be b du z dt"><div class="ab q"><div class="rj ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>4 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Apr 13</span></div></span></a><div class="xj xk xl xm xn l"><div class="ab co"><div class="am xo xp xq xr xs xt xu xv xw xx ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&amp;user=Alexander+Nguyen&amp;userId=a148fd75c2e9&amp;source=-----dc8f865b2c19----0-----------------clap_footer----60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="xy l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON" rel="noopener follow"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">126</span></p></button></div></div></a></div></div><div class="ab q xz ya"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&amp;source=-----af816aaea61----0-----------------bookmark_preview----60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="sx bg sy yb"></div></div></div></div></div></div></div></article></div></div><div class="ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va"><div class="vb vc vd ve vf dv l"><article class="dv"><div class="dv rj l"><div class="bg dv"><div class="dv l"><div class="dv vg vh vi vj vk vl vm vn vo vp vq vr vs"><div class="vt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" href="https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="vv vw vx vy vz"><img alt="" class="bg wa wb wc wd" src="https://miro.medium.com/v2/resize:fit:1358/1*y2egV1SyuZiKb2LMS6TlKw.jpeg" loading="lazy" role="presentation"/></div></a></div><div class="vu ab ca cn"><div class="we wf wg wh wi ab"><div class="qv l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://rukshanpramoditha.medium.com/?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="l ff"><img alt="Rukshan Pramoditha" class="l fa bx wj wk cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*h9UiRF_7vSdeFNwFpt0oOQ.jpeg" width="20" height="20" loading="lazy"/><div class="fn bx l wj wk fo n ax iu"></div></div></a></div></div></div><div class="wl l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://rukshanpramoditha.medium.com/?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Rukshan Pramoditha</p></a></div></div></div><div class="wl l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/data-science-365?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Data Science 365</p></a></div></div></div></div><div class="wm wn wo wp wq wr ws wt wu wv l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" href="https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div title="Determining the Right Batch Size for a Neural Network to Get Better and Faster Results"><h2 class="be gr od hq ww wx of og ht wy wz oi nn qb xa xb qc nr qe xc xd qf nv qh xe xf qi jt jv jw jy ka bj">Determining the Right Batch Size for a Neural Network to Get Better and Faster Results</h2></div><div class="xg l"><h3 class="be b jc z jt xh jv jw xi jy ka dt">Guidelines for choosing the right batch size to maintain optimal training speed and accuracy while saving computer resources</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" href="https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><span class="be b du z dt"><div class="ab q"><div class="rj ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>4 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Sep 26, 2022</span></div></span></a><div class="xj xk xl xm xn l"><div class="ab co"><div class="am xo xp xq xr xs xt xu xv xw xx ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdata-science-365%2F7a8662830f15&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2Fdetermining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15&amp;user=Rukshan+Pramoditha&amp;userId=f90a3bb1d400&amp;source=-----7a8662830f15----1-----------------clap_footer----60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="xy l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON" rel="noopener follow"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg></button></div></div></a></div></div><div class="ab q xz ya"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7a8662830f15&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2Fdetermining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15&amp;source=-----af816aaea61----1-----------------bookmark_preview----60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div></div></div></div></div></div></article></div></div></div></div><div class="sx bg sy zk"></div><h2 class="be ss jc z gp bj">Lists</h2><div class="yb l"><div class="cm ab lj jo tr ts tt tu tv tw tx ty tz ua ub uc ud ue uf"><div class="ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@MediumStaff/list/stories-to-help-you-grow-as-a-software-developer-b1d913188c20?source=read_next_recirc-----af816aaea61--------------------------------" rel="noopener follow"><div class="zr zs jt ab jl ff"><div class="ff wa zm bw zn"><div class="wa ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*yr2O5U-a0-rfY34C6yOXMw.jpeg" width="48" height="48" loading="lazy" role="presentation"/></div></div><div class="ff wa zm bw zo zp"><div class="wa ip jt l"><div class="ip io l zt"><div class="bx dv bg l zu"></div></div></div></div><div class="ff wa bw iy zq"><div class="wa ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*_3WdkzQRqIq8tt3Wh-WhbA.jpeg" width="48" height="48" loading="lazy" role="presentation"/></div></div></div><div class="aw l"><h2 class="be ss jc z jt xh jv jw xi jy ka gp bj">Stories to Help You Grow as a Software Developer</h2><div class="be b du z dt ab zl">19 stories<span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span>59<!-- --> <!-- -->saves</div></div></a></div><div class="ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@MediumStaff/list/stories-to-help-you-levelup-at-work-faca18b0622f?source=read_next_recirc-----af816aaea61--------------------------------" rel="noopener follow"><div class="zr zs jt ab jl ff"><div class="ff wa zm bw zn"><div class="wa ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*4zC5ohNcmVDb1NXmzCvmNA.jpeg" width="48" height="48" loading="lazy" role="presentation"/></div></div><div class="ff wa zm bw zo zp"><div class="wa ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*0dul7hn9LeV7U2XLVPvYYw.jpeg" width="48" height="48" loading="lazy" role="presentation"/></div></div><div class="ff wa bw iy zq"><div class="wa ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*oO7uwYs0NMWV7B4mUCuoIw.png" width="48" height="48" loading="lazy" role="presentation"/></div></div></div><div class="aw l"><h2 class="be ss jc z jt xh jv jw xi jy ka gp bj">Stories to Help You Level-Up at Work</h2><div class="be b du z dt ab zl">19 stories<span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span>46<!-- --> <!-- -->saves</div></div></a></div><div class="ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@MediumStaff/list/staff-picks-c7bc6e1ee00f?source=read_next_recirc-----af816aaea61--------------------------------" rel="noopener follow"><div class="zr zs jt ab jl ff"><div class="ff wa zm bw zn"><div class="wa ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*vXL3FFkiYmBAfLVbPRkXng.png" width="48" height="48" loading="lazy" role="presentation"/></div></div><div class="ff wa zm bw zo zp"><div class="wa ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*mV_rDLGaL3SW2eLjauVrmg.png" width="48" height="48" loading="lazy" role="presentation"/></div></div><div class="ff wa bw iy zq"><div class="wa ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*WsyTOM_sP90daUsK2NhTHg.jpeg" width="48" height="48" loading="lazy" role="presentation"/></div></div></div><div class="aw l"><h2 class="be ss jc z jt xh jv jw xi jy ka gp bj">Staff Picks</h2><div class="be b du z dt ab zl">323 stories<span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span>81<!-- --> <!-- -->saves</div></div></a></div></div></div><div class="sx bg sy yv dj yx dk zv zw zx zy zz aba"></div><div class="tq ab lj jo tr ts tt tu tv tw tx ty tz ua ub uc ud ue uf"><div class="ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va"><div class="vb vc vd ve vf dv l"><article class="dv"><div class="dv rj l"><div class="bg dv"><div class="dv l"><div class="dv vg vh vi vj vk vl vm vn vo vp vq vr vs"><div class="vt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" href="https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="vv vw vx vy vz"><img alt="" class="bg wa wb wc wd" src="https://miro.medium.com/v2/resize:fit:1358/1*y0vJwEfN45barnQO9jiYew.jpeg" loading="lazy" role="presentation"/></div></a></div><div class="vu ab ca cn"><div class="we wf wg wh wi ab"><div class="qv l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://thepycoach.com/?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="l ff"><img alt="The PyCoach" class="l fa bx wj wk cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*veEX4-CiLz5jqUjwWfQo_Q.jpeg" width="20" height="20" loading="lazy"/><div class="fn bx l wj wk fo n ax iu"></div></div></a></div></div></div><div class="wl l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://thepycoach.com/?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">The PyCoach</p></a></div></div></div><div class="wl l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://artificialcorner.com/?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Artificial Corner</p></a></div></div></div></div><div class="wm wn wo wp wq wr ws wt wu wv l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" href="https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div title="You’re Using ChatGPT Wrong! Here’s How to Be Ahead of 99% of ChatGPT Users"><h2 class="be gr od hq ww wx of og ht wy wz oi nn qb xa xb qc nr qe xc xd qf nv qh xe xf qi jt jv jw jy ka bj">You’re Using ChatGPT Wrong! Here’s How to Be Ahead of 99% of ChatGPT Users</h2></div><div class="xg l"><h3 class="be b jc z jt xh jv jw xi jy ka dt">Master ChatGPT by learning prompt engineering.</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" href="https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><span class="be b du z dt"><div class="ab q"><div class="rj ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>7 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Mar 17</span></div></span></a><div class="xj xk xl xm xn l"><div class="ab co"><div class="am xo xp xq xr xs xt xu xv xw xx ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&amp;operation=register&amp;redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&amp;user=The+PyCoach&amp;userId=fb44e21903f3&amp;source=-----886a50dabc54----0-----------------clap_footer----60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="xy l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----af816aaea61----0---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON" rel="noopener follow"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">372</span></p></button></div></div></a></div></div><div class="ab q xz ya"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&amp;operation=register&amp;redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&amp;source=-----af816aaea61----0-----------------bookmark_preview----60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="sx bg sy yb"></div></div></div></div></div></div></div></article></div></div><div class="ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va"><div class="vb vc vd ve vf dv l"><article class="dv"><div class="dv rj l"><div class="bg dv"><div class="dv l"><div class="dv vg vh vi vj vk vl vm vn vo vp vq vr vs"><div class="vt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" href="https://medium.com/mlearning-ai/optimizing-deep-learning-models-with-pruning-a-practical-guide-163e990c02af?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="vv vw vx vy vz"><img alt="" class="bg wa wb wc wd" src="https://miro.medium.com/v2/resize:fit:1358/1*6skjudfW25iAbd8uryVH6A.png" loading="lazy" role="presentation"/></div></a></div><div class="vu ab ca cn"><div class="we wf wg wh wi ab"><div class="qv l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@jan_marcel_kezmann?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="l ff"><img alt="Jan Marcel Kezmann" class="l fa bx wj wk cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*XdvgrCXUG5ox05Aa9zQIdA.jpeg" width="20" height="20" loading="lazy"/><div class="fn bx l wj wk fo n ax iu"></div></div></a></div></div></div><div class="wl l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/@jan_marcel_kezmann?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Jan Marcel Kezmann</p></a></div></div></div><div class="wl l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/mlearning-ai?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">MLearning.ai</p></a></div></div></div></div><div class="wm wn wo wp wq wr ws wt wu wv l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" href="https://medium.com/mlearning-ai/optimizing-deep-learning-models-with-pruning-a-practical-guide-163e990c02af?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div title=""><h2 class="be gr od hq ww wx of og ht wy wz oi nn qb xa xb qc nr qe xc xd qf nv qh xe xf qi jt jv jw jy ka bj">Optimizing Deep Learning Models with Pruning: A Practical Guide</h2></div><div class="xg l"><h3 class="be b jc z jt xh jv jw xi jy ka dt">Exploring and Implementing Pruning Methods with TensorFlow and PyTorch</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" href="https://medium.com/mlearning-ai/optimizing-deep-learning-models-with-pruning-a-practical-guide-163e990c02af?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><span class="be b du z dt"><div class="ab q"><div class="rj ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>13 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Dec 30, 2022</span></div></span></a><div class="xj xk xl xm xn l"><div class="ab co"><div class="am xo xp xq xr xs xt xu xv xw xx ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2F163e990c02af&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Foptimizing-deep-learning-models-with-pruning-a-practical-guide-163e990c02af&amp;user=Jan+Marcel+Kezmann&amp;userId=8a345d2c6a20&amp;source=-----163e990c02af----1-----------------clap_footer----60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="xy l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/mlearning-ai/optimizing-deep-learning-models-with-pruning-a-practical-guide-163e990c02af?source=read_next_recirc-----af816aaea61----1---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON" rel="noopener follow"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">1</span></p></button></div></div></a></div></div><div class="ab q xz ya"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F163e990c02af&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Foptimizing-deep-learning-models-with-pruning-a-practical-guide-163e990c02af&amp;source=-----af816aaea61----1-----------------bookmark_preview----60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="sx bg sy yb"></div></div></div></div></div></div></div></article></div></div><div class="ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va"><div class="vb vc vd ve vf dv l"><article class="dv"><div class="dv rj l"><div class="bg dv"><div class="dv l"><div class="dv vg vh vi vj vk vl vm vn vo vp vq vr vs"><div class="vt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" href="https://medium.com/artificialis/maximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a?source=read_next_recirc-----af816aaea61----2---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="vv vw vx vy vz"><img alt="" class="bg wa wb wc wd" src="https://miro.medium.com/v2/resize:fit:1358/1*lgWYSQWDdrkR4atgNVInJA.png" loading="lazy" role="presentation"/></div></a></div><div class="vu ab ca cn"><div class="we wf wg wh wi ab"><div class="qv l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://alessandroai.medium.com/?source=read_next_recirc-----af816aaea61----2---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="l ff"><img alt="Alessandro Lamberti" class="l fa bx wj wk cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*hqKHflotuIpkmXQ4DX4rAQ.jpeg" width="20" height="20" loading="lazy"/><div class="fn bx l wj wk fo n ax iu"></div></div></a></div></div></div><div class="wl l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://alessandroai.medium.com/?source=read_next_recirc-----af816aaea61----2---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Alessandro Lamberti</p></a></div></div></div><div class="wl l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/artificialis?source=read_next_recirc-----af816aaea61----2---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Artificialis</p></a></div></div></div></div><div class="wm wn wo wp wq wr ws wt wu wv l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" href="https://medium.com/artificialis/maximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a?source=read_next_recirc-----af816aaea61----2---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div title=""><h2 class="be gr od hq ww wx of og ht wy wz oi nn qb xa xb qc nr qe xc xd qf nv qh xe xf qi jt jv jw jy ka bj">Maximizing Model Performance with Knowledge Distillation in PyTorch</h2></div><div class="xg l"><h3 class="be b jc z jt xh jv jw xi jy ka dt">Boost your model’s accuracy and save on resources with knowledge distillation in PyTorch</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" href="https://medium.com/artificialis/maximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a?source=read_next_recirc-----af816aaea61----2---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><span class="be b du z dt"><div class="ab q"><div class="rj ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>5 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Dec 8, 2022</span></div></span></a><div class="xj xk xl xm xn l"><div class="ab co"><div class="am xo xp xq xr xs xt xu xv xw xx ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificialis%2F12b3960a486a&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fartificialis%2Fmaximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a&amp;user=Alessandro+Lamberti&amp;userId=7fc4b5ed0ad1&amp;source=-----12b3960a486a----2-----------------clap_footer----60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="xy l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/artificialis/maximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a?source=read_next_recirc-----af816aaea61----2---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON" rel="noopener follow"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg></button></div></div></a></div></div><div class="ab q xz ya"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F12b3960a486a&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fartificialis%2Fmaximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a&amp;source=-----af816aaea61----2-----------------bookmark_preview----60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="sx bg sy yb"></div></div></div></div></div></div></div></article></div></div><div class="ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va"><div class="vb vc vd ve vf dv l"><article class="dv"><div class="dv rj l"><div class="bg dv"><div class="dv l"><div class="dv vg vh vi vj vk vl vm vn vo vp vq vr vs"><div class="vt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" rel="noopener follow" href="/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863?source=read_next_recirc-----af816aaea61----3---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------"><div class="vv vw vx vy vz"><img alt="Guide to Learning Rate Schedulers in PyTorch" class="bg wa wb wc wd" src="https://miro.medium.com/v2/resize:fit:1358/1*qe6nYlH8zsmUdScyHMhRCQ.png" loading="lazy"/></div></a></div><div class="vu ab ca cn"><div class="we wf wg wh wi ab"><div class="qv l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@iamleonie?source=read_next_recirc-----af816aaea61----3---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="l ff"><img alt="Leonie Monigatti" class="l fa bx wj wk cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*TTIl4oynrJyfIkLbC6fumA.png" width="20" height="20" loading="lazy"/><div class="fn bx l wj wk fo n ax iu"></div></div></a></div></div></div><div class="wl l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/@iamleonie?source=read_next_recirc-----af816aaea61----3---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Leonie Monigatti</p></a></div></div></div><div class="wl l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=read_next_recirc-----af816aaea61----3---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="wm wn wo wp wq wr ws wt wu wv l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" rel="noopener follow" href="/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863?source=read_next_recirc-----af816aaea61----3---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------"><div title=""><h2 class="be gr od hq ww wx of og ht wy wz oi nn qb xa xb qc nr qe xc xd qf nv qh xe xf qi jt jv jw jy ka bj">A Visual Guide to Learning Rate Schedulers in PyTorch</h2></div><div class="xg l"><h3 class="be b jc z jt xh jv jw xi jy ka dt">LR decay and annealing strategies for Deep Learning in Python</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" rel="noopener follow" href="/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863?source=read_next_recirc-----af816aaea61----3---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------"><span class="be b du z dt"><div class="ab q"><div class="rj ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>9 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Dec 6, 2022</span></div></span></a><div class="xj xk xl xm xn l"><div class="ab co"><div class="am xo xp xq xr xs xt xu xv xw xx ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F24bbb262c863&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863&amp;user=Leonie+Monigatti&amp;userId=3a38da70d8dc&amp;source=-----24bbb262c863----3-----------------clap_footer----60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="xy l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863?source=read_next_recirc-----af816aaea61----3---------------------60c52122_9416_4865_a71a_e79bb9ce6bbd-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">6</span></p></button></div></div></a></div></div><div class="ab q xz ya"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F24bbb262c863&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863&amp;source=-----af816aaea61----3-----------------bookmark_preview----60c52122_9416_4865_a71a_e79bb9ce6bbd-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div></div></div></div></div></div></article></div></div></div><div class="sx bg sy dj dk yc yd ye"></div><a class="be b bf z bj qw av yi yj yk lp yl es et eu ym yn yo ex yp yq yr ys yt ey ez fa bl fb" href="https://medium.com/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><div class="l pr">See more recommendations</div></a></div></div></div><div class="h k j"><div class="sx bg sy te"></div><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="tf ab lj jo"><div class="tg th l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><p class="be b du z dt">Help</p></a></div><div class="tg th l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><p class="be b du z dt">Status</p></a></div><div class="tg th l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://about.medium.com/creators/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><p class="be b du z dt">Writers</p></a></div><div class="tg th l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><p class="be b du z dt">Blog</p></a></div><div class="tg th l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><p class="be b du z dt">Careers</p></a></div><div class="tg th l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><p class="be b du z dt">Privacy</p></a></div><div class="tg th l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><p class="be b du z dt">Terms</p></a></div><div class="tg th l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/about?autoplay=1&amp;source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><p class="be b du z dt">About</p></a></div><div class="tg l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><p class="be b du z dt">Text to speech</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20230527-011135-8f3fe75710"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"auroraPage":{"isAuroraPageEnabled":false},"cache":{"experimentGroupSet":true,"reason":"This request is not using the cache middleware worker","group":"disabled","tags":["group-edgeCachePosts","post-af816aaea61","user-524f24852f3c","collection-7f60cf5620c9"],"serverVariantState":"","middlewareEnabled":false,"cacheStatus":"DYNAMIC","shouldUseCache":false,"vary":[],"inDisabledExperiment":false,"topicPortalsEnabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"COLLECTION","id":"7f60cf5620c9","explicit":true},"viewerIsBot":false},"debug":{"requestId":"0197b7f3-1192-44fc-bc96-29553414b8b7","hybridDevServices":[],"originalSpanCarrier":{"ot-tracer-spanid":"5178edad71437166","ot-tracer-traceid":"37b2eabce3c696c3","ot-tracer-sampled":"true"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fneural-network-pruning-101-af816aaea61","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false},"config":{"nodeEnv":"production","version":"main-20230527-021229-8f3fe75710","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20230527-021229-8f3fe75710","commit":"8f3fe75710df1a1cce703b068227d3b71edb871b"}},"datacenter":"us"},"googleAnalyticsCode":"UA-24232453-2","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyWithTrial":"d5ee3dbe3db8","yearly":"a40ad4a43185","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","variantFlags":[{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_newsletter_lo_flow_custom_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_aspiriational","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_send_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_programming","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_legacy_feed_in_iceland","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_dashboard_referred_earnings","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"web_enable_syntax_highlighting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_edge_cache","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_avatar_upload","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"redefined_top_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"sanity_check_aa_experiment_3","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"textshots_userid","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"author_fair_distribution_non_qp3","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"price_smoke_test_yearly","valueType":{"__typename":"VariantFlagString","value":"50"}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"enable_speechify_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"reader_fair_distribution_non_qp","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_lists_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_new_user_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"disable_partner_program_enrollment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_new_push_notification_endpoint","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"price_smoke_test_monthly","valueType":{"__typename":"VariantFlagString","value":"7"}},{"__typename":"VariantFlag","name":"ios_social_share_sheet","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_auto_follow_on_subscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_b2b_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_apple_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_home_post_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_seamless_social_sharing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_signup_friction","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"onboarding_tags_from_top_views","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_dynamic_programming_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_aggregator_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_continue_this_thread","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"enable_author_cards","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"can_receive_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cache_less_following_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_annual_renewal_reminder_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_import","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"explicit_signals_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_in_app_free_trial","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_user_follows","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_two_hour_refresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tag_recs","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_iceland_nux","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_trial_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_verified_book_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pill_based_home_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_twitter_auth_suggestions","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_generation_pipeline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_iceland_forced_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"enable_aspirational_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_autorefresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_remove_twitter_onboarding_step","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards_byline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_google_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_display_paywall_after_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"sanity_check_aa_experiment_2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_editor_new_publishing_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_group_gifting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_sign_in_captcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_recirc_model","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_dynamic_aspirational_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_incognito_regwall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_simplified_digest_v2_b","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"bevy_rds_double_write","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_client","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"skip_sign_in_recaptcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_boosted_notification","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_response_markup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_verified_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_automod","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_verifications_service","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"sanity_check_aa_experiment_4","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"enable_creator_welcome_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sprig","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_tagline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_reading_history","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"covid_19_cdc_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_medium2_kbfd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_members_only_audio","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_widget","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_miro_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_triton_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_follower_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound-source-serif-pro"}},{"__typename":"VariantFlag","name":"skip_fs_cache_user_vals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_syntax_highlight","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_deprecate_custom_profile","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_pub_follower_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_featurestore_parallel_queries","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_entities_to_follow_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members_username_selection","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"viewer":null,"collectionByDomainOrSlug({\"domainOrSlug\":\"towardsdatascience.com\"})":{"__ref":"Collection:7f60cf5620c9"},"postResult({\"id\":\"af816aaea61\"})":{"__ref":"Post:af816aaea61"},"post({\"id\":\"af816aaea61\"})":{"__ref":"Post:af816aaea61"},"authorCollectionRecircFeed({\"input\":{\"authorId\":\"524f24852f3c\",\"collectionId\":\"7f60cf5620c9\",\"paging\":{\"limit\":4},\"postId\":\"af816aaea61\"}})":{"__typename":"AuthorCollectionRecircFeedResult","items":[{"__typename":"HomeFeedItem","post":{"__ref":"Post:4f2d34bd8736"},"feedId":"43c3c6ff-1671-4629-9343-8bcca9e0300c"},{"__typename":"HomeFeedItem","post":{"__ref":"Post:95fc8898732c"},"feedId":"43c3c6ff-1671-4629-9343-8bcca9e0300c"},{"__typename":"HomeFeedItem","post":{"__ref":"Post:1e535dd0cd79"},"feedId":"43c3c6ff-1671-4629-9343-8bcca9e0300c"},{"__typename":"HomeFeedItem","post":{"__ref":"Post:fabc3d4f8e36"},"feedId":"43c3c6ff-1671-4629-9343-8bcca9e0300c"}]},"recirc({\"paging\":{\"limit\":6},\"postId\":\"af816aaea61\"})":{"__typename":"RexRecircResult","items":[{"__typename":"RexRecircItem","feedId":"60c52122-9416-4865-a71a-e79bb9ce6bbd","post":{"__ref":"Post:dc8f865b2c19"}},{"__typename":"RexRecircItem","feedId":"60c52122-9416-4865-a71a-e79bb9ce6bbd","post":{"__ref":"Post:7a8662830f15"}},{"__typename":"RexRecircItem","feedId":"60c52122-9416-4865-a71a-e79bb9ce6bbd","post":{"__ref":"Post:886a50dabc54"}},{"__typename":"RexRecircItem","feedId":"60c52122-9416-4865-a71a-e79bb9ce6bbd","post":{"__ref":"Post:163e990c02af"}},{"__typename":"RexRecircItem","feedId":"60c52122-9416-4865-a71a-e79bb9ce6bbd","post":{"__ref":"Post:12b3960a486a"}},{"__typename":"RexRecircItem","feedId":"60c52122-9416-4865-a71a-e79bb9ce6bbd","post":{"__ref":"Post:24bbb262c863"}}]},"postCatalogRecirc({\"pagingOptions\":{\"limit\":4},\"postId\":\"af816aaea61\"})":{"__typename":"CatalogsConnection","catalogs":[{"__ref":"Catalog:b1d913188c20"},{"__ref":"Catalog:faca18b0622f"},{"__ref":"Catalog:c7bc6e1ee00f"}]}},"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png":{"__typename":"ImageMetadata","id":"1*VzTUkfeGymHP4Bvav-T-lA.png"},"Collection:7f60cf5620c9":{"__typename":"Collection","id":"7f60cf5620c9","favicon":{"__ref":"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png"},"customStyleSheet":{"__ref":"CustomStyleSheet:514038af8f2f"},"colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"googleAnalyticsId":null,"editors":[{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:7e12c71dfa81"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:e6ad8abedec9"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:2155e1f99318"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:895063a310f4"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:29c9531ee6f5"}}],"name":"Towards Data Science","avatar":{"__ref":"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg"},"domain":"towardsdatascience.com","slug":"towards-data-science","description":"Your home for data science. A Medium publication sharing concepts, ideas and codes.","subscriberCount":662535,"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_67da07359f0f"},"twitterUsername":"TDataScience","facebookPageId":null,"logo":{"__ref":"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","status":"ACTIVE","isSubdomain":false}},"creator":{"__ref":"User:7e12c71dfa81"},"ptsQualifiedAt":1616092952992},"CustomStyleSheet:514038af8f2f":{"__typename":"CustomStyleSheet","id":"514038af8f2f","global":{"__typename":"GlobalStyles","colorPalette":{"__typename":"StyleSheetColorPalette","primary":{"__typename":"ColorValue","colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}}},"background":null},"fonts":{"__typename":"StyleSheetFonts","font1":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font2":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font3":{"__typename":"StyleSheetFont","name":"SERIF_2"}}}},"User:7e12c71dfa81":{"__typename":"User","id":"7e12c71dfa81","atsQualifiedAt":1612205680542},"User:e6ad8abedec9":{"__typename":"User","id":"e6ad8abedec9"},"User:2155e1f99318":{"__typename":"User","id":"2155e1f99318"},"User:895063a310f4":{"__typename":"User","id":"895063a310f4"},"User:29c9531ee6f5":{"__typename":"User","id":"29c9531ee6f5"},"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg":{"__typename":"ImageMetadata","id":"1*CJe3891yB1A1mzMdqemkdg.jpeg"},"LinkedAccounts:524f24852f3c":{"__typename":"LinkedAccounts","mastodon":null,"id":"524f24852f3c"},"UserViewerEdge:userId:524f24852f3c-viewerId:lo_67da07359f0f":{"__typename":"UserViewerEdge","id":"userId:524f24852f3c-viewerId:lo_67da07359f0f","isFollowing":false,"isUser":false},"NewsletterV3:71cc63d0ec07":{"__typename":"NewsletterV3","id":"71cc63d0ec07","type":"NEWSLETTER_TYPE_AUTHOR","slug":"524f24852f3c","name":"524f24852f3c","collection":null,"user":{"__ref":"User:524f24852f3c"}},"User:524f24852f3c":{"__typename":"User","id":"524f24852f3c","name":"Hugo Tessier","username":"hugo.tessier","newsletterV3":{"__ref":"NewsletterV3:71cc63d0ec07"},"linkedAccounts":{"__ref":"LinkedAccounts:524f24852f3c"},"isSuspended":false,"imageId":"1*PAy1sna3YNoKY4jQl9znVw.jpeg","mediumMemberAt":0,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":53},"customDomainState":null,"hasSubdomain":false,"bio":"PHD student in deep learning, working on neural network compression and, especially, pruning.","isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:524f24852f3c-viewerId:lo_67da07359f0f"},"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"allowNotes":true,"twitterScreenName":"","atsQualifiedAt":1631610169172},"Topic:ae5d4995e225":{"__typename":"Topic","slug":"data-science","id":"ae5d4995e225","name":"Data Science"},"Paragraph:58956a883341_0":{"__typename":"Paragraph","id":"58956a883341_0","name":"06b7","type":"H3","href":null,"layout":null,"metadata":null,"text":"Neural Network Pruning 101","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_1":{"__typename":"Paragraph","id":"58956a883341_1","name":"c2f6","type":"H4","href":null,"layout":null,"metadata":null,"text":"All you need to know not to get lost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_2":{"__typename":"Paragraph","id":"58956a883341_2","name":"ca09","type":"P","href":null,"layout":null,"metadata":null,"text":"Whether it is in computer vision, natural language processing or image generation, deep neural networks yield the state of the art. However, their cost in terms of computational power, memory or energy consumption can be prohibitive, making some of them downright unaffordable for most limited hardware. Yet, many domains would benefit from neural networks, hence the need to reduce their cost while maintaining their performance.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_3":{"__typename":"Paragraph","id":"58956a883341_3","name":"375f","type":"P","href":null,"layout":null,"metadata":null,"text":"That is the whole point of neural networks compression. This field counts multiple families of methods, such as quantization [11], factorization [13], distillation [32] or, and this will be the focus of this post, pruning.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_4":{"__typename":"Paragraph","id":"58956a883341_4","name":"24e1","type":"P","href":null,"layout":null,"metadata":null,"text":"Neural network pruning is a method that revolves around the intuitive idea of removing superfluous parts of a network that performs well but costs a lot of resources. Indeed, even though large neural networks have proven countless times how well they could learn, it turns out that not all of their parts are still useful after the training process is over. The idea is to eliminate these parts without impacting the network’s performance.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_5":{"__typename":"Paragraph","id":"58956a883341_5","name":"9a45","type":"P","href":null,"layout":null,"metadata":null,"text":"Unfortunately, the dozens, if not hundreds, of papers published each year are revealing the hidden complexity of a supposedly straight-forward idea. Indeed, a quick overview of the literature yields countless ways of identifying said useless parts or removing them before, during or after training; it even turns out that not all kinds of pruning actually allow for accelerating neural networks, which is supposed to be the whole point.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_6":{"__typename":"Paragraph","id":"58956a883341_6","name":"b038","type":"P","href":null,"layout":null,"metadata":null,"text":"The goal of this post is to provide a solid foundation to tackle the intimidatingly wild literature around neural network pruning. We will review successively three questions that seem to be at the core of the whole domain: “What kind of part should I prune?”, “How to tell which parts can be pruned?” and “How to prune parts without harming the network?”. To sum it up, we will detail pruning structures, pruning criteria and pruning methods.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":386,"end":404,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":406,"end":422,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":427,"end":442,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_7":{"__typename":"Paragraph","id":"58956a883341_7","name":"1f16","type":"H3","href":null,"layout":null,"metadata":null,"text":"1 — Pruning structures","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_8":{"__typename":"Paragraph","id":"58956a883341_8","name":"8cb0","type":"H3","href":null,"layout":null,"metadata":null,"text":"1.1 — Unstructured pruning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_9":{"__typename":"Paragraph","id":"58956a883341_9","name":"fdc8","type":"P","href":null,"layout":null,"metadata":null,"text":"When talking about the cost of neural networks, the count of parameters is surely one of the most widely used metrics, along with FLOPS (floating-point operations per second). It is indeed intimidating to see networks displaying astronomical amounts of weights (up to billions for some), often correlated with stellar performance. Therefore, it is quite intuitive to aim at reducing directly this count by removing parameters themselves. Actually, pruning connections is one of the most widespread paradigms in the literature, enough to be considered as the default framework when dealing with pruning. The seminal work of Han et al.[26] presented this kind of pruning and served as a basis for numerous contributions [18, 21, 25].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_10":{"__typename":"Paragraph","id":"58956a883341_10","name":"462b","type":"P","href":null,"layout":null,"metadata":null,"text":"Directly pruning parameters has many advantages. First, it is simple, since replacing the value of their weight with zero, within the parameter tensors, is enough to prune a connection. Widespread deep learning frameworks, such as Pytorch, allow to easily access all the parameters of a network, making it extremely simple to implement. Still, the greatest advantage of pruning connections remains yet that they are the smallest, most fundamental elements of networks and, therefore, they are numerous enough to prune them in large quantities without impacting performance. Such a fine granularity allows pruning very subtle patterns, up to parameters within convolution kernels, for example. As pruning weights is not limited by any constraint at all and is the finest way to prune a network, such a paradigm is called unstructured pruning.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":820,"end":840,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_11":{"__typename":"Paragraph","id":"58956a883341_11","name":"67a2","type":"P","href":null,"layout":null,"metadata":null,"text":"However, this method presents a major, fatal drawback: most frameworks and hardware cannot accelerate sparse matrices’ computation, meaning that no matter how many zeros you fill the parameter tensors with, it will not impact the actual cost of the network. What does impact it, however, is pruning in a way that directly alters the very architecture of the network, which any framework can handle.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*7qwYH1r-h6VOGiE6C2tpGg.png":{"__typename":"ImageMetadata","id":"1*7qwYH1r-h6VOGiE6C2tpGg.png","originalHeight":1436,"originalWidth":2430,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:58956a883341_12":{"__typename":"Paragraph","id":"58956a883341_12","name":"a727","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*7qwYH1r-h6VOGiE6C2tpGg.png"},"text":"Difference between unstructured (left) and structured (right) pruning: structured pruning removes both convolution filters and rows of kernels instead of just pruning connections. This leads to fewer feature maps within intermediate representations. (image by author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_13":{"__typename":"Paragraph","id":"58956a883341_13","name":"01ae","type":"H4","href":null,"layout":null,"metadata":null,"text":"1.2 — Structured pruning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_14":{"__typename":"Paragraph","id":"58956a883341_14","name":"d73b","type":"P","href":null,"layout":null,"metadata":null,"text":"This is the reason why many works have focused on pruning larger structures, such as whole neurons [36] or, for its direct equivalent within the more modern deep convolutional networks, convolution filters [40, 41, 66]. Filter pruning allows for an exploitable and yet fine enough granularity, as large networks tend to include numerous convolution layers, each counting up to hundreds or thousands of filters. Not only does removing such structures result in sparse layers that can be directly instantiated as thinner ones, but doing so also eliminates the feature maps that are the outputs of such filters.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_15":{"__typename":"Paragraph","id":"58956a883341_15","name":"4a73","type":"P","href":null,"layout":null,"metadata":null,"text":"Therefore, not only are such networks lighter to store, due to fewer parameters, but also they require less computations and generate lighter intermediate representations, hence needing less memory during runtime. Actually, it is sometimes more beneficial to reduce bandwidth rather than the parameter count. Indeed, for tasks that involve large images, such as semantic segmentation or object detection, intermediate representations may be prohibitively memory-consuming, way more than the network itself. For these reasons, filter pruning is now seen as the default kind of structured pruning.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":576,"end":594,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_16":{"__typename":"Paragraph","id":"58956a883341_16","name":"b13b","type":"P","href":null,"layout":null,"metadata":null,"text":"Yet, when applying such a pruning, one should pay attention to the following aspects. Let’s consider how a convolution layer is built: for Cin input channels and Cout output ones, a convolution layer is made of Cout filters, each counting Cin kernels; each filter outputs one feature map and within each filter, one kernel is dedicated to each input channel. Considering this architecture, and acknowledging a regular convolutional network basically stacks convolution layers, when pruning whole filters, one may observe that pruning a filter, and then the feature map it outputs, actually results in pruning the corresponding kernels in the ensuing layer too. That means that, when pruning filters, one may actually prune twice the amount of parameters thought to be removed in the first place.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":139,"end":142,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":162,"end":166,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":211,"end":215,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":239,"end":242,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_17":{"__typename":"Paragraph","id":"58956a883341_17","name":"920a","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s consider too that, when a whole layer happens to get pruned (which tends to happen because of layer collapse [62], but does not always break the network, depending on the architecture), the previous layer’s outputs are now totally unconnected, hence pruned too: pruning a whole layer may actually prune all its previous layers whose outputs are not somehow connected elsewhere (because of residual connections [28] or whole parallel paths [61]). Therefore, when pruning filters, one should consider computing the exact number of actually pruned parameters. Indeed, pruning the same amount of filters, depending on their distribution within the architecture, may not lead to the same actual amount of pruned parameters, making any result impossible to compare with.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":463,"end":561,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_18":{"__typename":"Paragraph","id":"58956a883341_18","name":"64ad","type":"P","href":null,"layout":null,"metadata":null,"text":"Before changing topic, let’s just mention that, albeit a minority, some works focus on pruning convolution kernels, intra-kernel structures [2,24, 46] or even specific parameter-wise structures. However, such structures need special implementations to lead to any kind of speedup (as for unstructured pruning). Another kind of exploitable structure, though, is to turn convolutions into “shift layers” by pruning all but one parameter in each kernel, which can then be summed up as a combination of a shifting operation and a 1 × 1 convolution [24].","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":159,"end":193,"href":"https:\u002F\u002Fdeveloper.nvidia.com\u002Fblog\u002Faccelerating-inference-with-sparsity-using-ampere-and-tensorrt\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*o0Qh-ORMytWTA2xdCFbPiQ.png":{"__typename":"ImageMetadata","id":"1*o0Qh-ORMytWTA2xdCFbPiQ.png","originalHeight":1950,"originalWidth":2268,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:58956a883341_19":{"__typename":"Paragraph","id":"58956a883341_19","name":"5242","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*o0Qh-ORMytWTA2xdCFbPiQ.png"},"text":"The danger of structured pruning: altering the input and output dimensions of layers can lead to some discrepancies. If on the left, both layers output the same number of feature maps, that can be summed up well afterward, their pruned counterparts on the right produce intermediate representations of different dimensions, that cannot be summed up without processing them. (image by author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_20":{"__typename":"Paragraph","id":"58956a883341_20","name":"7400","type":"H3","href":null,"layout":null,"metadata":null,"text":"2 — Pruning criteria","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_21":{"__typename":"Paragraph","id":"58956a883341_21","name":"af47","type":"P","href":null,"layout":null,"metadata":null,"text":"Once one has decided what kind of structure to prune, the next question one may ask could be: “Now, how do I figure out which ones to keep and which ones to prune?”. To answer that one needs a proper pruning criteria, that will rank the relative importance of the parameters, filters or else.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_22":{"__typename":"Paragraph","id":"58956a883341_22","name":"a3f6","type":"H4","href":null,"layout":null,"metadata":null,"text":"2.1 — Weight magnitude criterion","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_23":{"__typename":"Paragraph","id":"58956a883341_23","name":"ab7c","type":"P","href":null,"layout":null,"metadata":null,"text":"One criterion that is quite intuitive and surprisingly efficient is pruning weights whose absolute value (or “magnitude”) is the smallest. Indeed, under the constraint of a weight-decay, those which do not contribute significantly to the function are expected to have their magnitude shrink during training. Therefore, the superfluous weights are expected to be those of lesser magnitude [8]. Notwithstanding its simplicity, the magnitude criterion is still widely used in modern works [21, 26, 58], making it a staple of the domain.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_24":{"__typename":"Paragraph","id":"58956a883341_24","name":"b739","type":"P","href":null,"layout":null,"metadata":null,"text":"However, although this criterion seems trivial to implement in the case of unstructured pruning, one may wonder how to adapt it to structured pruning. One straightforward way is to order filters depending on their norm (L 1 or L 2 for example) [40, 70]. If this method is quite straightforward one may desire to encapsulate multiple sets of parameters within one measure: for example, a convolutional filter, its bias and its batch-normalization parameters together, or even corresponding filters within parallel layers whose outputs are then fused and whose channels we would like to reduce.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_25":{"__typename":"Paragraph","id":"58956a883341_25","name":"44f2","type":"P","href":null,"layout":null,"metadata":null,"text":"One way to do that, without having to compute the combined norm of these parameters, involves inserting a learnable multiplicative parameter for each feature map after each set of layers you want to prune. This gate, when reduced to zero, effectively prunes the whole set of parameters responsible for this channel and the magnitude of this gate accounts for the importance of all of them. The method hence consists in pruning the gates of lesser magnitude [36, 41].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_26":{"__typename":"Paragraph","id":"58956a883341_26","name":"a4d6","type":"H4","href":null,"layout":null,"metadata":null,"text":"2.2 — Gradient magnitude pruning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_27":{"__typename":"Paragraph","id":"58956a883341_27","name":"e034","type":"P","href":null,"layout":null,"metadata":null,"text":"Magnitude of the weight is not the only popular criterion (or family of criteria) that exists. Actually, the other main criterion to have lasted up to now is the magnitude of the gradient. Indeed, back in the 80's some fundamental works [37, 53] theorized, through a Taylor decomposition of the impact of removing a parameter on the loss, that some metrics, derived from the back-propagated gradient, may provide a good way to determine which parameters could be pruned without damaging the network.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_28":{"__typename":"Paragraph","id":"58956a883341_28","name":"50c3","type":"P","href":null,"layout":null,"metadata":null,"text":"More modern implementations of this criterion [4, 50] actually accumulate gradients over a minibatch of training data and prune on the basis of the product between this gradient and the corresponding weight of each parameter. This criterion can be applied to the aforementioned gates too [49].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_29":{"__typename":"Paragraph","id":"58956a883341_29","name":"f74e","type":"H4","href":null,"layout":null,"metadata":null,"text":"2.3 — Global or local pruning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_30":{"__typename":"Paragraph","id":"58956a883341_30","name":"7f2b","type":"P","href":null,"layout":null,"metadata":null,"text":"One final aspect to take into consideration is whether the chosen criterion is applied globally to all parameters or filters of the network, or if it is computed independently for each layer. While global pruning has proven many times to yield better results, it can lead to layer collapse [62]. A simple way to avoid this problem is to resort to layer-wise local pruning, namely pruning the same rate at each layer, when the used method cannot prevent layer collapse.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*rMLCgVa380ZBcgM0Iqg84Q.png":{"__typename":"ImageMetadata","id":"1*rMLCgVa380ZBcgM0Iqg84Q.png","originalHeight":879,"originalWidth":2048,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:58956a883341_31":{"__typename":"Paragraph","id":"58956a883341_31","name":"89e2","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*rMLCgVa380ZBcgM0Iqg84Q.png"},"text":"Difference between local pruning (left) and global pruning (right): local pruning applies the same rate to each layer while global applies it on the whole network at once. (image by author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_32":{"__typename":"Paragraph","id":"58956a883341_32","name":"703c","type":"H3","href":null,"layout":null,"metadata":null,"text":"3 — Pruning method","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_33":{"__typename":"Paragraph","id":"58956a883341_33","name":"e967","type":"P","href":null,"layout":null,"metadata":null,"text":"Now that we have got our pruning structure and criterion, the only parameter left is which method should we use to prune a network. This is actually the topic on which the literature can be the most confusing, as each paper will bring its own quirks and gimmicks, so much that one may get lost between what is methodically relevant and what is just a specificity of a given paper.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_34":{"__typename":"Paragraph","id":"58956a883341_34","name":"7b8d","type":"P","href":null,"layout":null,"metadata":null,"text":"This is why we will thematically overview some of the most popular families of method to prune neural networks, in an order that highlights the evolution of the use of sparsity during training.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_35":{"__typename":"Paragraph","id":"58956a883341_35","name":"45d5","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.1 — The classic framework: train, prune and fine-tune","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_36":{"__typename":"Paragraph","id":"58956a883341_36","name":"f197","type":"P","href":null,"layout":null,"metadata":null,"text":"The first basic framework to know is the train, prune and fine-tune method, which obviously involves 1) training the network 2) pruning it by setting to 0 all parameters targeted by the pruning structures and criterion (these parameters cannot recover afterwhile) and 3) training the network for a few extra epochs, with the lowest learning rate, to give it a chance to recover from the loss in performance induced by pruning. Usually, these last two steps can be iterated, with each time a growing pruning rate.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_37":{"__typename":"Paragraph","id":"58956a883341_37","name":"50e4","type":"P","href":null,"layout":null,"metadata":null,"text":"The method proposed by Han et al. [26] applies this method, with 5 iterations between pruning and fine-tuning, to weight magnitude pruning. Iterating has shown to improve performance, at the cost of extra computation and training time. This simple framework serves as a basis for many works [26, 40, 41, 50, 66] and can be seen as the default method over which all the others have built.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_38":{"__typename":"Paragraph","id":"58956a883341_38","name":"62f4","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.2 — Extending the classic framework","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_39":{"__typename":"Paragraph","id":"58956a883341_39","name":"3d86","type":"P","href":null,"layout":null,"metadata":null,"text":"While not straying too far, some methods have brought significant modifications to the aforementioned classic framework by Han et al. [26]. Gale et al. [21] have pushed the principle of iterations further by removing an increasing amount of weights progressively all along the training process, which allows benefiting from the advantages of iterations and to remove the whole fine-tuning process. He et al. [29] reduce prunable filters to 0, at each epoch, while not preventing them from learning and being updated afterward, in order to let their weights grow back after pruning while enforcing sparsity during training.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_40":{"__typename":"Paragraph","id":"58956a883341_40","name":"67de","type":"P","href":null,"layout":null,"metadata":null,"text":"Finally, the method of Renda et al. [58] involves fully retraining a network once it is pruned. Unlike fine-tuning, which is performed at the lowest learning-rate, retraining follows the same learning-rate schedule as training, hence its name: “Learning-Rate Rewinding”. This retraining has shown to yield better performance than mere fine-tuning, at a significantly higher cost.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_41":{"__typename":"Paragraph","id":"58956a883341_41","name":"062d","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.3 — Pruning at initialization","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_42":{"__typename":"Paragraph","id":"58956a883341_42","name":"6ba9","type":"P","href":null,"layout":null,"metadata":null,"text":"In order to speed up training, avoid fine-tuning and prevent any alteration of the architecture during or after training, multiple works have focused on pruning before training. In the wake of SNIP [39], many works have studied the use of the work of Le Cun et al. [37] or of Mozer and Smolensky [53] to prune at initialization [12, 64], including intensive theoretical studies [27, 38, 62]. However, Optimal Brain Damage [37] relies on multiple approximations including an “extremal” approximation that “assumes that parameter deletion will be performed after training has converged” [37]; this fact is rarely mentioned, even among works that are based on it. Some works have raised reservations about the ability of such methods to generate masks whose relevance outshines random ones of similar distribution per layer [20].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_43":{"__typename":"Paragraph","id":"58956a883341_43","name":"98e1","type":"P","href":null,"layout":null,"metadata":null,"text":"Another family of methods that study the relationship between pruning and initialization gravitates around the “Lottery Ticket Hypothesis” [18]. This hypothesis states that “randomly-initialized, dense neural network contains a subnet-work that is initialized such that — when trained in isolation — it can match the test accuracy of the original network after training for at most the same number of iterations”. In practice, this literature studies how well a pruning mask, defined using an already converged network, can be applied to the network back when it was just initialized. Multiple works have expanded, stabilized or studied this hypothesis [14, 19, 45, 51, 69]. However, once again multiple works tend to question the validity of the hypothesis and of the method used to study it [21, 42] and some even tend to show that its benefits rather came from the principle of fully training with the definitive mask instead of a hypothetical “Winning Ticket” [58].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*ALVyE5U7jC692UGVKCVY8Q.png":{"__typename":"ImageMetadata","id":"1*ALVyE5U7jC692UGVKCVY8Q.png","originalHeight":838,"originalWidth":2058,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:58956a883341_44":{"__typename":"Paragraph","id":"58956a883341_44","name":"9383","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*ALVyE5U7jC692UGVKCVY8Q.png"},"text":"Comparison between the classic “train, prune and fine-tune” framework [26], the lottery ticket experiment [18] and learning rate rewinding [58]. (image by author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_45":{"__typename":"Paragraph","id":"58956a883341_45","name":"0d30","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.4 — Sparse training","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_46":{"__typename":"Paragraph","id":"58956a883341_46","name":"fd21","type":"P","href":null,"layout":null,"metadata":null,"text":"The previous methods are linked by a seemingly shared underlying theme: training under sparsity constraints. This principle is at the core of a family of methods, called sparse training, which consists in enforcing a constant rate of sparsity during training while its distribution varies and is progressively adjusted. Introduced by Mocanu et al. [47], it involves: 1) initializing the network with a random mask that prunes a certain proportion of the network 2) training this pruned network during one epoch 3) pruning a certain amount of weights of lower magnitude and 4) regrowing the same amount of random weights.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":170,"end":185,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_47":{"__typename":"Paragraph","id":"58956a883341_47","name":"4cad","type":"P","href":null,"layout":null,"metadata":null,"text":"That way, the pruning mask, at first random, is progressively adjusted to target the least import weights while enforcing sparsity all throughout training. The sparsity level can be the same for each layer [47] or global [52]. Other methods have extended sparse training by using a certain criterion to regrow weights instead of choosing them randomly [15, 17].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*3hP9xPMOSnsxqtLIvGrhOA.png":{"__typename":"ImageMetadata","id":"1*3hP9xPMOSnsxqtLIvGrhOA.png","originalHeight":1217,"originalWidth":2048,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:58956a883341_48":{"__typename":"Paragraph","id":"58956a883341_48","name":"ecaa","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*3hP9xPMOSnsxqtLIvGrhOA.png"},"text":"Sparse training cuts and grows different weights periodically during training, which leads to an adjusted mask that should target only relevant parameters. (image by author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_49":{"__typename":"Paragraph","id":"58956a883341_49","name":"f9f3","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.5 — Mask learning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_50":{"__typename":"Paragraph","id":"58956a883341_50","name":"88ec","type":"P","href":null,"layout":null,"metadata":null,"text":"Instead of relying on arbitrary criteria to prune or regrow weights, multiple methods focus on learning a pruning mask during training. Two types of methods seem to prevail in this domain: 1) mask learning through separate networks or layers and 2) mask learning through auxiliary parameters. Multiple kinds of strategies can fit in the methods of the first type: training separate agents to prune as many filters of a layer as possible while maximizing the accuracy [33], inserting attention-based layers [68] or using reinforcement learning [30]. The second kind of methods aims at considering pruning as an optimization problem that tends to minimize both the L0 norm of the network and its supervised loss.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_51":{"__typename":"Paragraph","id":"58956a883341_51","name":"1475","type":"P","href":null,"layout":null,"metadata":null,"text":"Since the L0 is non-differentiable, the various methods mainly involve circumventing this problem through the use of penalized auxiliary parameters that are multiplied with their corresponding parameter during the forward pass [59, 23]. Many methods [44, 60, 67] rely on a method analogous to that of “Binary Connect” [11], namely: applying stochastic gates over parameters whose values are each randomly drawn from their own Bernoulli distribution of parameter p that is learned using a “Straight Through Estimator” [3] or other means [44].","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":462,"end":463,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_52":{"__typename":"Paragraph","id":"58956a883341_52","name":"7a36","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.6 — Penalty-based methods","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_53":{"__typename":"Paragraph","id":"58956a883341_53","name":"b905","type":"P","href":null,"layout":null,"metadata":null,"text":"Many methods, instead of pruning connections manually or penalizing auxiliary parameters, rather apply various kinds of penalties to weights themselves to make them progressively shrink toward 0. This notion is actually pretty ancient [57], as weight-decay is already an essential element to the weight magnitude criterion. Beyond using a mere weight-decay, even back then multiple works focused on elaborating penalties specifically designed to enforce sparsity [55, 65]. Today, various methods apply different regularizations, on top of the weight decay, to increase further the sparsity (typically, using L 1 norm [41]).","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_54":{"__typename":"Paragraph","id":"58956a883341_54","name":"ba3b","type":"P","href":null,"layout":null,"metadata":null,"text":"Among modern works, multiple methods rely on the LASSO (Least Absolute Shrinkage and Selection Operator) [22, 31, 66] to prune weights or groups. Other methods develop penalties that target weak connections to increase the gap between the parameters to keep and those to prune, so that their removal has less impact [7, 16]. Some methods show that targeting a subset of weights with a penalization that grows all throughout training can progressively prune them and make their removal seamless [6, 9, 63]. The literature also counts a whole range of methods built around the principle of “Variational Dropout” [34], a method based on variational inference [5] applied to deep learning [35]. As a pruning method [48], it birthed multiple works that adapt its principle to structured pruning [43, 54].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_55":{"__typename":"Paragraph","id":"58956a883341_55","name":"344e","type":"H3","href":null,"layout":null,"metadata":null,"text":"4 — Available frameworks","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_56":{"__typename":"Paragraph","id":"58956a883341_56","name":"d420","type":"P","href":null,"layout":null,"metadata":null,"text":"If most of these methods have to be implemented from scratch (or can be reused from the provided sources of each paper, if they do provide them), some frameworks exist to apply basic methods or make the aforementioned implementation easier.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_57":{"__typename":"Paragraph","id":"58956a883341_57","name":"1145","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.1 — Pytorch","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_58":{"__typename":"Paragraph","id":"58956a883341_58","name":"9c63","type":"P","href":null,"layout":null,"metadata":null,"text":"Pytorch [56] provide multiple quality-of-life features to help pruning networks. The provided tools allow to easily apply a mask to a network and maintain this mask during training, as well as it allows to easily revert that mask if needed. Pytorch also provide some basic pruning methods, such as global or local pruning, whether it is structured or not. Structured pruning can be applied on any dimension of the weights tensors, which lets pruning filters, rows of kernels or even some rows and columns inside kernels. Those in-built basic methods also allow pruning randomly or depending on various norms.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_59":{"__typename":"Paragraph","id":"58956a883341_59","name":"3f1c","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.2 — Tensorflow","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_60":{"__typename":"Paragraph","id":"58956a883341_60","name":"db73","type":"P","href":null,"layout":null,"metadata":null,"text":"The Keras [10] library from Tensorflow [1] provide some basic tools to prune weights of lower magnitudes. Such as in the work of Han et al [25], the efficiency of pruning is measured in terms of how much does the redundancy, introduced by all the inserted zeros, allows to compress the model better (which combines well with quantization).","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":4,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":28,"end":38,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_61":{"__typename":"Paragraph","id":"58956a883341_61","name":"c61c","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.3 — ShrinkBench","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_62":{"__typename":"Paragraph","id":"58956a883341_62","name":"29c2","type":"P","href":null,"layout":null,"metadata":null,"text":"Blalock et al. [4] provide in their work a custom library in an effort to help the community normalize how pruning algorithm are compared. Based on Pytorch, ShrinkBench aims at making the implementation of pruning methods easier while normalizing the conditions under which they are trained and tested. It provides different baselines, such as random pruning, global or layerwise and weight magnitude or gradient magnitude pruning.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":148,"end":155,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":157,"end":168,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_63":{"__typename":"Paragraph","id":"58956a883341_63","name":"0db7","type":"H3","href":null,"layout":null,"metadata":null,"text":"5 — Brief recap of reviewed methods","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_64":{"__typename":"Paragraph","id":"58956a883341_64","name":"4f0a","type":"P","href":null,"layout":null,"metadata":null,"text":"In this article, many papers have been cited. Here is a simple table to roughly summarize what they do and what differentiates them (provided dates are those of first publication):","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:5b60387af4bb2dc372bdb5cd4701b98c":{"__typename":"MediaResource","id":"5b60387af4bb2dc372bdb5cd4701b98c","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"Neural Network Pruning Methods"},"Paragraph:58956a883341_65":{"__typename":"Paragraph","id":"58956a883341_65","name":"0635","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:5b60387af4bb2dc372bdb5cd4701b98c"}},"mixtapeMetadata":null},"Paragraph:58956a883341_66":{"__typename":"Paragraph","id":"58956a883341_66","name":"5fc5","type":"H3","href":null,"layout":null,"metadata":null,"text":"6 — Conclusion","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_67":{"__typename":"Paragraph","id":"58956a883341_67","name":"dbd7","type":"P","href":null,"layout":null,"metadata":null,"text":"In our quick overview of the literature, we saw that 1) pruning structures define which kind of gain to expect from pruning 2) pruning criteria are based on various theoretical or practical justifications and 3) pruning methods tend to revolve around introducing sparsity during training to reconcile performance and cost. We also saw that, even though its founding works date back from the late 80’s, neural network pruning is a very dynamic field that still experiences fundamental discoveries and new basic concepts today.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_68":{"__typename":"Paragraph","id":"58956a883341_68","name":"8cda","type":"P","href":null,"layout":null,"metadata":null,"text":"Despite the daily contributions in the domain, there seems to be still plenty of room for exploration and innovation. If each subfamily of method can be seen as an attempt to answer a question (“How to regrow pruned weights ?”, “How to learn pruning masks through optimization ?”, “How to relax the weight removal by a softer mean ?”…), then the evolution of the literature seems to point out a certain direction: that of sparsity throughout training. This direction raises itself many questions, such as: “do pruning criteria work well on networks that haven’t converged yet?” or “how to tell the benefit of the choice of the weights to prune from that of training with any kind of sparsity from the start?”","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_69":{"__typename":"Paragraph","id":"58956a883341_69","name":"b0a7","type":"H3","href":null,"layout":null,"metadata":null,"text":"References","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_70":{"__typename":"Paragraph","id":"58956a883341_70","name":"333c","type":"P","href":null,"layout":null,"metadata":null,"text":"[1] Martı́n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from tensorflow.org.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_71":{"__typename":"Paragraph","id":"58956a883341_71","name":"1fba","type":"P","href":null,"layout":null,"metadata":null,"text":"[2] Sajid Anwar, Kyuyeon Hwang, and Wonyong Sung. Structured pruning of deep convolutional neural networks. ACM Journal on Emerging Technologies in Computing Systems (JETC), 13(3):1–18, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_72":{"__typename":"Paragraph","id":"58956a883341_72","name":"9ab6","type":"P","href":null,"layout":null,"metadata":null,"text":"[3] Yoshua Bengio, Nicholas Léonard, and Aaron Courville. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_73":{"__typename":"Paragraph","id":"58956a883341_73","name":"4225","type":"P","href":null,"layout":null,"metadata":null,"text":"[4] Davis Blalock, Jose Javier Gonzalez Ortiz, Jonathan Frankle, and John Guttag. What is the state of neural network pruning? arXiv preprint arXiv:2003.03033, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_74":{"__typename":"Paragraph","id":"58956a883341_74","name":"1893","type":"P","href":null,"layout":null,"metadata":null,"text":"[5] David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: A review for statisticians. Journal of the American statistical Association, 112(518):859–877, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_75":{"__typename":"Paragraph","id":"58956a883341_75","name":"4edf","type":"P","href":null,"layout":null,"metadata":null,"text":"[6] Miguel A Carreira-Perpinán and Yerlan Idelbayev. “learning-compression” algorithms for neural net pruning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8532–8541, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_76":{"__typename":"Paragraph","id":"58956a883341_76","name":"5a92","type":"P","href":null,"layout":null,"metadata":null,"text":"[7] Jing Chang and Jin Sha. Prune deep neural networks with the modified L1\u002F2 penalty. IEEE Access, 7:2273–2280, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_77":{"__typename":"Paragraph","id":"58956a883341_77","name":"7d74","type":"P","href":null,"layout":null,"metadata":null,"text":"[8] Yves Chauvin. A back-propagation algorithm with optimal use of hidden units. In NIPS, volume 1, pages 519–526, 1988.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_78":{"__typename":"Paragraph","id":"58956a883341_78","name":"2b0e","type":"P","href":null,"layout":null,"metadata":null,"text":"[9] Yoojin Choi, Mostafa El-Khamy, and Jungwon Lee. Compression of deep convolutional neural networks under joint sparsity constraints. arXiv preprint arXiv:1805.08303, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_79":{"__typename":"Paragraph","id":"58956a883341_79","name":"5860","type":"P","href":null,"layout":null,"metadata":null,"text":"[10] Francois Chollet et al. Keras, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_80":{"__typename":"Paragraph","id":"58956a883341_80","name":"a78f","type":"P","href":null,"layout":null,"metadata":null,"text":"[11] Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. Binaryconnect: Training deep neural networks with binary weights during propagations. In NIPS, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_81":{"__typename":"Paragraph","id":"58956a883341_81","name":"f314","type":"P","href":null,"layout":null,"metadata":null,"text":"[12] Pau de Jorge, Amartya Sanyal, Harkirat S Behl, Philip HS Torr, Gregory Rogez, and Puneet K Dokania. Progressive skeletonization: Trimming more fat from a network at initialization. arXiv preprint arXiv:2006.09081, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_82":{"__typename":"Paragraph","id":"58956a883341_82","name":"5849","type":"P","href":null,"layout":null,"metadata":null,"text":"[13] Emily Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus. Exploiting linear structure within convolutional networks for efficient evaluation. In 28th Annual Conference on Neural Information Processing Systems 2014, NIPS 2014, pages 1269–1277. Neural information processing systems foundation, 2014.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_83":{"__typename":"Paragraph","id":"58956a883341_83","name":"2aed","type":"P","href":null,"layout":null,"metadata":null,"text":"[14] Shrey Desai, Hongyuan Zhan, and Ahmed Aly. Evaluating lottery tickets under distributional shifts. In Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019), pages 153–162, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_84":{"__typename":"Paragraph","id":"58956a883341_84","name":"eb74","type":"P","href":null,"layout":null,"metadata":null,"text":"[15] Tim Dettmers and Luke Zettlemoyer. Sparse networks from scratch: Faster training without losing performance. arXiv preprint arXiv:1907.04840, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_85":{"__typename":"Paragraph","id":"58956a883341_85","name":"b415","type":"P","href":null,"layout":null,"metadata":null,"text":"[16] Xiaohan Ding, Guiguang Ding, Xiangxin Zhou, Yuchen Guo, Jungong Han, and Ji Liu. Global sparse momentum sgd for pruning very deep neural networks. arXiv preprint arXiv:1909.12778, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_86":{"__typename":"Paragraph","id":"58956a883341_86","name":"f184","type":"P","href":null,"layout":null,"metadata":null,"text":"[17] Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, and Erich Elsen. Rigging the lottery: Making all tickets winners. In International Conference on Machine Learning, pages 2943–2952. PMLR, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_87":{"__typename":"Paragraph","id":"58956a883341_87","name":"bf6f","type":"P","href":null,"layout":null,"metadata":null,"text":"[18] Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_88":{"__typename":"Paragraph","id":"58956a883341_88","name":"3617","type":"P","href":null,"layout":null,"metadata":null,"text":"[19] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Stabilizing the lottery ticket hypothesis. arXiv preprint arXiv:1903.01611, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_89":{"__typename":"Paragraph","id":"58956a883341_89","name":"58c0","type":"P","href":null,"layout":null,"metadata":null,"text":"[20] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Pruning neural networks at initialization: Why are we missing the mark? arXiv preprint arXiv:2009.08576, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_90":{"__typename":"Paragraph","id":"58956a883341_90","name":"4f5f","type":"P","href":null,"layout":null,"metadata":null,"text":"[21] Trevor Gale, Erich Elsen, and Sara Hooker. The state of sparsity in deep neural networks. arXiv preprint arXiv:1902.09574, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_91":{"__typename":"Paragraph","id":"58956a883341_91","name":"74d8","type":"P","href":null,"layout":null,"metadata":null,"text":"[22] Susan Gao, Xin Liu, Lung-Sheng Chien, William Zhang, and Jose M Alvarez. Vacl: Variance-aware cross-layer regularization for pruning deep residual networks. In Proceedings of the IEEE\u002FCVF International Conference on Computer Vision Workshops, pages 0–0, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_92":{"__typename":"Paragraph","id":"58956a883341_92","name":"a37e","type":"P","href":null,"layout":null,"metadata":null,"text":"[23] Yiwen Guo, Anbang Yao, and Yurong Chen. Dynamic network surgery for efficient dnns. In NIPS, 2016.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_93":{"__typename":"Paragraph","id":"58956a883341_93","name":"771a","type":"P","href":null,"layout":null,"metadata":null,"text":"[24] Ghouthi Boukli Hacene, Carlos Lassance, Vincent Gripon, Matthieu Courbariaux, and Yoshua Bengio. Attention based pruning for shift networks. In 2020 25th International Conference on Pattern Recognition (ICPR), pages 4054–4061. IEEE, 2021.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_94":{"__typename":"Paragraph","id":"58956a883341_94","name":"c933","type":"P","href":null,"layout":null,"metadata":null,"text":"[25] Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_95":{"__typename":"Paragraph","id":"58956a883341_95","name":"a6e9","type":"P","href":null,"layout":null,"metadata":null,"text":"[26] Song Han, Jeff Pool, John Tran, and William J Dally. Learning both weights and connections for efficient neural network. In NIPS, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_96":{"__typename":"Paragraph","id":"58956a883341_96","name":"3b8d","type":"P","href":null,"layout":null,"metadata":null,"text":"[27] Soufiane Hayou, Jean-Francois Ton, Arnaud Doucet, and Yee Whye Teh. Robust pruning at initialization.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_97":{"__typename":"Paragraph","id":"58956a883341_97","name":"ff92","type":"P","href":null,"layout":null,"metadata":null,"text":"[28] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_98":{"__typename":"Paragraph","id":"58956a883341_98","name":"9f85","type":"P","href":null,"layout":null,"metadata":null,"text":"[29] Yang He, Guoliang Kang, Xuanyi Dong, Yanwei Fu, and Yi Yang. Soft filter pruning for accelerating deep convolutional neural networks. arXiv preprint arXiv:1808.06866, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_99":{"__typename":"Paragraph","id":"58956a883341_99","name":"14d2","type":"P","href":null,"layout":null,"metadata":null,"text":"[30] Yihui He, Ji Lin, Zhijian Liu, Hanrui Wang, Li-Jia Li, and Song Han. Amc: Automl for model compression and acceleration on mobile devices. In Proceedings of the European Conference on Computer Vision (ECCV), pages 784–800, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_100":{"__typename":"Paragraph","id":"58956a883341_100","name":"af2f","type":"P","href":null,"layout":null,"metadata":null,"text":"[31] Yihui He, Xiangyu Zhang, and Jian Sun. Channel pruning for accelerating very deep neural networks. In Proceedings of the IEEE International Conference on Computer Vision, pages 1389–1397, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_101":{"__typename":"Paragraph","id":"58956a883341_101","name":"7371","type":"P","href":null,"layout":null,"metadata":null,"text":"[32] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. stat, 1050:9, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_102":{"__typename":"Paragraph","id":"58956a883341_102","name":"55ce","type":"P","href":null,"layout":null,"metadata":null,"text":"[33] Qiangui Huang, Kevin Zhou, Suya You, and Ulrich Neumann. Learning to prune filters in convolutional neural networks. In 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), pages 709–718. IEEE, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_103":{"__typename":"Paragraph","id":"58956a883341_103","name":"3f8f","type":"P","href":null,"layout":null,"metadata":null,"text":"[34] Diederik P Kingma, Tim Salimans, and Max Welling. Variational dropout and the local reparameterization trick. stat, 1050:8, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_104":{"__typename":"Paragraph","id":"58956a883341_104","name":"93d7","type":"P","href":null,"layout":null,"metadata":null,"text":"[35] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. stat, 1050:1, 2014.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_105":{"__typename":"Paragraph","id":"58956a883341_105","name":"38d1","type":"P","href":null,"layout":null,"metadata":null,"text":"[36] John K Kruschke and Javier R Movellan. Benefits of gain: Speeded learning and minimal hidden layers in back-propagation networks. IEEE Transactions on systems, Man, and Cybernetics, 21(1):273–280, 1991.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_106":{"__typename":"Paragraph","id":"58956a883341_106","name":"1b89","type":"P","href":null,"layout":null,"metadata":null,"text":"[37] Yann LeCun, John S Denker, and Sara A Solla. Optimal brain damage. In Advances in neural information processing systems, pages 598–605, 1990.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_107":{"__typename":"Paragraph","id":"58956a883341_107","name":"b9d6","type":"P","href":null,"layout":null,"metadata":null,"text":"[38] Namhoon Lee, Thalaiyasingam Ajanthan, Stephen Gould, and Philip HS Torr. A signal propagation perspective for pruning neural networks at initialization. In International Conference on Learning Representations, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_108":{"__typename":"Paragraph","id":"58956a883341_108","name":"c8c3","type":"P","href":null,"layout":null,"metadata":null,"text":"[39] Namhoon Lee, Thalaiyasingam Ajanthan, and Philip HS Torr. Snip: Single-shot network pruning based on connection sensitivity. International Conference on Learning Representations, ICLR, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_109":{"__typename":"Paragraph","id":"58956a883341_109","name":"fa53","type":"P","href":null,"layout":null,"metadata":null,"text":"[40] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning filters for efficient convnets. arXiv preprint arXiv:1608.08710, 2016.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_110":{"__typename":"Paragraph","id":"58956a883341_110","name":"5975","type":"P","href":null,"layout":null,"metadata":null,"text":"[41] Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan, and Changshui Zhang. Learning efficient convolutional networks through network slimming. In Proceedings of the IEEE International Conference on Computer Vision, pages 2736–2744, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_111":{"__typename":"Paragraph","id":"58956a883341_111","name":"3879","type":"P","href":null,"layout":null,"metadata":null,"text":"[42] Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, and Trevor Darrell. Rethinking the value of network pruning. In International Conference on Learning Representations, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_112":{"__typename":"Paragraph","id":"58956a883341_112","name":"8d02","type":"P","href":null,"layout":null,"metadata":null,"text":"[43] C Louizos, K Ullrich, and M Welling. Bayesian compression for deep learning. In 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA., 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_113":{"__typename":"Paragraph","id":"58956a883341_113","name":"eb44","type":"P","href":null,"layout":null,"metadata":null,"text":"[44] Christos Louizos, Max Welling, and Diederik P Kingma. Learning sparse neural networks through l 0 regularization. arXiv preprint arXiv:1712.01312, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_114":{"__typename":"Paragraph","id":"58956a883341_114","name":"4866","type":"P","href":null,"layout":null,"metadata":null,"text":"[45] Eran Malach, Gilad Yehudai, Shai Shalev-Schwartz, and Ohad Shamir. Proving the lottery ticket hypothesis: Pruning is all you need. In International Conference on Machine Learning, pages 6682–6691. PMLR, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_115":{"__typename":"Paragraph","id":"58956a883341_115","name":"235f","type":"P","href":null,"layout":null,"metadata":null,"text":"[46] Huizi Mao, Song Han, Jeff Pool, Wenshuo Li, Xingyu Liu, Yu Wang, and William J Dally. Exploring the regularity of sparse structure in convolutional neural networks. arXiv preprint arXiv:1705.08922, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_116":{"__typename":"Paragraph","id":"58956a883341_116","name":"6721","type":"P","href":null,"layout":null,"metadata":null,"text":"[47] Decebal Constantin Mocanu, Elena Mocanu, Peter Stone, Phuong H Nguyen, Madeleine Gibescu, and Antonio Liotta. Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science. Nature communications, 9(1):1–12, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_117":{"__typename":"Paragraph","id":"58956a883341_117","name":"2a85","type":"P","href":null,"layout":null,"metadata":null,"text":"[48] Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Variational dropout sparsifies deep neural networks. In International Conference on Machine Learning, pages 2498–2507. PMLR, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_118":{"__typename":"Paragraph","id":"58956a883341_118","name":"9f44","type":"P","href":null,"layout":null,"metadata":null,"text":"[49] Pavlo Molchanov, Arun Mallya, Stephen Tyree, Iuri Frosio, and Jan Kautz. Importance estimation for neural network pruning. In Proceedings of the IEEE\u002FCVF Conference on Computer Vision and Pattern Recognition, pages 11264–11272, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_119":{"__typename":"Paragraph","id":"58956a883341_119","name":"1ef1","type":"P","href":null,"layout":null,"metadata":null,"text":"[50] Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila, and Jan Kautz. Pruning convolutional neural networks for resource efficient inference. arXiv preprint arXiv:1611.06440, 2016.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_120":{"__typename":"Paragraph","id":"58956a883341_120","name":"aa9b","type":"P","href":null,"layout":null,"metadata":null,"text":"[51] Ari S Morcos, Haonan Yu, Michela Paganini, and Yuandong Tian. One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers. stat, 1050:6, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_121":{"__typename":"Paragraph","id":"58956a883341_121","name":"79eb","type":"P","href":null,"layout":null,"metadata":null,"text":"[52] Hesham Mostafa and Xin Wang. Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization. In International Conference on Machine Learning, pages 4646–4655. PMLR, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_122":{"__typename":"Paragraph","id":"58956a883341_122","name":"ce0a","type":"P","href":null,"layout":null,"metadata":null,"text":"[53] Michael C Mozer and Paul Smolensky. Skeletonization: A technique for trimming the fat from a network via relevance assessment. In Advances in neural information processing systems, pages 107–115, 1989.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_123":{"__typename":"Paragraph","id":"58956a883341_123","name":"d3f1","type":"P","href":null,"layout":null,"metadata":null,"text":"[54] Kirill Neklyudov, Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Structured bayesian pruning via log-normal multiplicative noise. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pages 6778–6787, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_124":{"__typename":"Paragraph","id":"58956a883341_124","name":"bc88","type":"P","href":null,"layout":null,"metadata":null,"text":"[55] Steven J Nowlan and Geoffrey E Hinton. Simplifying neural networks by soft weight-sharing. Neural Computation, 4(4):473–493, 1992.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_125":{"__typename":"Paragraph","id":"58956a883341_125","name":"b046","type":"P","href":null,"layout":null,"metadata":null,"text":"[56] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_126":{"__typename":"Paragraph","id":"58956a883341_126","name":"d7b3","type":"P","href":null,"layout":null,"metadata":null,"text":"[57] Russell Reed. Pruning algorithms-a survey. IEEE transactions on Neural Networks, 4(5):740–747, 1993.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_127":{"__typename":"Paragraph","id":"58956a883341_127","name":"3bf3","type":"P","href":null,"layout":null,"metadata":null,"text":"[58] Alex Renda, Jonathan Frankle, and Michael Carbin. Comparing rewinding and fine-tuning in neural network pruning. arXiv preprint arXiv:2003.02389, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_128":{"__typename":"Paragraph","id":"58956a883341_128","name":"3d25","type":"P","href":null,"layout":null,"metadata":null,"text":"[59] Pedro Savarese, Hugo Silva, and Michael Maire. Winning the lottery with continuous sparsification. Advances in Neural Information Processing Systems, 33, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_129":{"__typename":"Paragraph","id":"58956a883341_129","name":"5eb0","type":"P","href":null,"layout":null,"metadata":null,"text":"[60] Suraj Srinivas, Akshayvarun Subramanya, and R Venkatesh Babu. Training sparse neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pages 138–145, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_130":{"__typename":"Paragraph","id":"58956a883341_130","name":"5fd8","type":"P","href":null,"layout":null,"metadata":null,"text":"[61] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1–9, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_131":{"__typename":"Paragraph","id":"58956a883341_131","name":"1d5f","type":"P","href":null,"layout":null,"metadata":null,"text":"[62] Hidenori Tanaka, Daniel Kunin, Daniel L Yamins, and Surya Ganguli. Pruning neural networks without any data by iteratively conserving synaptic flow. Advances in Neural Information Processing Systems, 33, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_132":{"__typename":"Paragraph","id":"58956a883341_132","name":"44d2","type":"P","href":null,"layout":null,"metadata":null,"text":"[63] Hugo Tessier, Vincent Gripon, Mathieu Léonardon, Matthieu Arzel, Thomas Hannagan, and David Bertrand. Rethinking weight decay for efficient neural network pruning. 2021.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_133":{"__typename":"Paragraph","id":"58956a883341_133","name":"1727","type":"P","href":null,"layout":null,"metadata":null,"text":"[64] Chaoqi Wang, Guodong Zhang, and Roger Grosse. Picking winning tickets before training by preserving gradient flow. In International Conference on Learning Representations, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_134":{"__typename":"Paragraph","id":"58956a883341_134","name":"c94b","type":"P","href":null,"layout":null,"metadata":null,"text":"[65] Andreas S Weigend, David E Rumelhart, and Bernardo A Huberman. Generalization by weight-elimination with application to forecasting. In Advances in neural information processing systems, pages 875–882, 1991.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_135":{"__typename":"Paragraph","id":"58956a883341_135","name":"ce36","type":"P","href":null,"layout":null,"metadata":null,"text":"[66] Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Learning structured sparsity in deep neural networks. In NIPS, 2016.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_136":{"__typename":"Paragraph","id":"58956a883341_136","name":"45b5","type":"P","href":null,"layout":null,"metadata":null,"text":"[67] Xia Xiao, Zigeng Wang, and Sanguthevar Rajasekaran. Autoprune: Automatic network pruning by regularizing auxiliary parameters. Advances in neural information processing systems, 32, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_137":{"__typename":"Paragraph","id":"58956a883341_137","name":"8e2b","type":"P","href":null,"layout":null,"metadata":null,"text":"[68] Kohei Yamamoto and Kurato Maeno. Pcas: Pruning channels with attention statistics for deep network compression. arXiv preprint arXiv:1806.05382, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_138":{"__typename":"Paragraph","id":"58956a883341_138","name":"7479","type":"P","href":null,"layout":null,"metadata":null,"text":"[69] Hattie Zhou, Janice Lan, Rosanne Liu, and Jason Yosinski. Deconstructing lottery tickets: Zeros, signs, and the supermask. arXiv preprint arXiv:1905.01067, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_139":{"__typename":"Paragraph","id":"58956a883341_139","name":"726f","type":"P","href":null,"layout":null,"metadata":null,"text":"[70] Zhuangwei Zhuang, Mingkui Tan, Bohan Zhuang, Jing Liu, Yong Guo, Qingyao Wu, Junzhou Huang, and Jin-Hui Zhu. Discrimination-aware channel pruning for deep neural networks. In NeurIPS, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_67da07359f0f":{"__typename":"CollectionViewerEdge","id":"collectionId:7f60cf5620c9-viewerId:lo_67da07359f0f","isEditor":false},"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png":{"__typename":"ImageMetadata","id":"1*mG6i4Bh_LgixUYXJgQpYsg@2x.png","originalWidth":337,"originalHeight":122},"Tag:neural-networks":{"__typename":"Tag","id":"neural-networks","displayTitle":"Neural Networks","normalizedTagSlug":"neural-networks"},"Tag:pruning":{"__typename":"Tag","id":"pruning","displayTitle":"Pruning","normalizedTagSlug":"pruning"},"Tag:compression":{"__typename":"Tag","id":"compression","displayTitle":"Compression","normalizedTagSlug":"compression"},"Tag:deep-learning":{"__typename":"Tag","id":"deep-learning","displayTitle":"Deep Learning","normalizedTagSlug":"deep-learning"},"Tag:deep-dives":{"__typename":"Tag","id":"deep-dives","displayTitle":"Deep Dives","normalizedTagSlug":"deep-dives"},"Post:af816aaea61":{"__typename":"Post","id":"af816aaea61","collection":{"__ref":"Collection:7f60cf5620c9"},"content({\"postMeteringOptions\":{\"forceTruncation\":false}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"7520","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:58956a883341_0"},{"__ref":"Paragraph:58956a883341_1"},{"__ref":"Paragraph:58956a883341_2"},{"__ref":"Paragraph:58956a883341_3"},{"__ref":"Paragraph:58956a883341_4"},{"__ref":"Paragraph:58956a883341_5"},{"__ref":"Paragraph:58956a883341_6"},{"__ref":"Paragraph:58956a883341_7"},{"__ref":"Paragraph:58956a883341_8"},{"__ref":"Paragraph:58956a883341_9"},{"__ref":"Paragraph:58956a883341_10"},{"__ref":"Paragraph:58956a883341_11"},{"__ref":"Paragraph:58956a883341_12"},{"__ref":"Paragraph:58956a883341_13"},{"__ref":"Paragraph:58956a883341_14"},{"__ref":"Paragraph:58956a883341_15"},{"__ref":"Paragraph:58956a883341_16"},{"__ref":"Paragraph:58956a883341_17"},{"__ref":"Paragraph:58956a883341_18"},{"__ref":"Paragraph:58956a883341_19"},{"__ref":"Paragraph:58956a883341_20"},{"__ref":"Paragraph:58956a883341_21"},{"__ref":"Paragraph:58956a883341_22"},{"__ref":"Paragraph:58956a883341_23"},{"__ref":"Paragraph:58956a883341_24"},{"__ref":"Paragraph:58956a883341_25"},{"__ref":"Paragraph:58956a883341_26"},{"__ref":"Paragraph:58956a883341_27"},{"__ref":"Paragraph:58956a883341_28"},{"__ref":"Paragraph:58956a883341_29"},{"__ref":"Paragraph:58956a883341_30"},{"__ref":"Paragraph:58956a883341_31"},{"__ref":"Paragraph:58956a883341_32"},{"__ref":"Paragraph:58956a883341_33"},{"__ref":"Paragraph:58956a883341_34"},{"__ref":"Paragraph:58956a883341_35"},{"__ref":"Paragraph:58956a883341_36"},{"__ref":"Paragraph:58956a883341_37"},{"__ref":"Paragraph:58956a883341_38"},{"__ref":"Paragraph:58956a883341_39"},{"__ref":"Paragraph:58956a883341_40"},{"__ref":"Paragraph:58956a883341_41"},{"__ref":"Paragraph:58956a883341_42"},{"__ref":"Paragraph:58956a883341_43"},{"__ref":"Paragraph:58956a883341_44"},{"__ref":"Paragraph:58956a883341_45"},{"__ref":"Paragraph:58956a883341_46"},{"__ref":"Paragraph:58956a883341_47"},{"__ref":"Paragraph:58956a883341_48"},{"__ref":"Paragraph:58956a883341_49"},{"__ref":"Paragraph:58956a883341_50"},{"__ref":"Paragraph:58956a883341_51"},{"__ref":"Paragraph:58956a883341_52"},{"__ref":"Paragraph:58956a883341_53"},{"__ref":"Paragraph:58956a883341_54"},{"__ref":"Paragraph:58956a883341_55"},{"__ref":"Paragraph:58956a883341_56"},{"__ref":"Paragraph:58956a883341_57"},{"__ref":"Paragraph:58956a883341_58"},{"__ref":"Paragraph:58956a883341_59"},{"__ref":"Paragraph:58956a883341_60"},{"__ref":"Paragraph:58956a883341_61"},{"__ref":"Paragraph:58956a883341_62"},{"__ref":"Paragraph:58956a883341_63"},{"__ref":"Paragraph:58956a883341_64"},{"__ref":"Paragraph:58956a883341_65"},{"__ref":"Paragraph:58956a883341_66"},{"__ref":"Paragraph:58956a883341_67"},{"__ref":"Paragraph:58956a883341_68"},{"__ref":"Paragraph:58956a883341_69"},{"__ref":"Paragraph:58956a883341_70"},{"__ref":"Paragraph:58956a883341_71"},{"__ref":"Paragraph:58956a883341_72"},{"__ref":"Paragraph:58956a883341_73"},{"__ref":"Paragraph:58956a883341_74"},{"__ref":"Paragraph:58956a883341_75"},{"__ref":"Paragraph:58956a883341_76"},{"__ref":"Paragraph:58956a883341_77"},{"__ref":"Paragraph:58956a883341_78"},{"__ref":"Paragraph:58956a883341_79"},{"__ref":"Paragraph:58956a883341_80"},{"__ref":"Paragraph:58956a883341_81"},{"__ref":"Paragraph:58956a883341_82"},{"__ref":"Paragraph:58956a883341_83"},{"__ref":"Paragraph:58956a883341_84"},{"__ref":"Paragraph:58956a883341_85"},{"__ref":"Paragraph:58956a883341_86"},{"__ref":"Paragraph:58956a883341_87"},{"__ref":"Paragraph:58956a883341_88"},{"__ref":"Paragraph:58956a883341_89"},{"__ref":"Paragraph:58956a883341_90"},{"__ref":"Paragraph:58956a883341_91"},{"__ref":"Paragraph:58956a883341_92"},{"__ref":"Paragraph:58956a883341_93"},{"__ref":"Paragraph:58956a883341_94"},{"__ref":"Paragraph:58956a883341_95"},{"__ref":"Paragraph:58956a883341_96"},{"__ref":"Paragraph:58956a883341_97"},{"__ref":"Paragraph:58956a883341_98"},{"__ref":"Paragraph:58956a883341_99"},{"__ref":"Paragraph:58956a883341_100"},{"__ref":"Paragraph:58956a883341_101"},{"__ref":"Paragraph:58956a883341_102"},{"__ref":"Paragraph:58956a883341_103"},{"__ref":"Paragraph:58956a883341_104"},{"__ref":"Paragraph:58956a883341_105"},{"__ref":"Paragraph:58956a883341_106"},{"__ref":"Paragraph:58956a883341_107"},{"__ref":"Paragraph:58956a883341_108"},{"__ref":"Paragraph:58956a883341_109"},{"__ref":"Paragraph:58956a883341_110"},{"__ref":"Paragraph:58956a883341_111"},{"__ref":"Paragraph:58956a883341_112"},{"__ref":"Paragraph:58956a883341_113"},{"__ref":"Paragraph:58956a883341_114"},{"__ref":"Paragraph:58956a883341_115"},{"__ref":"Paragraph:58956a883341_116"},{"__ref":"Paragraph:58956a883341_117"},{"__ref":"Paragraph:58956a883341_118"},{"__ref":"Paragraph:58956a883341_119"},{"__ref":"Paragraph:58956a883341_120"},{"__ref":"Paragraph:58956a883341_121"},{"__ref":"Paragraph:58956a883341_122"},{"__ref":"Paragraph:58956a883341_123"},{"__ref":"Paragraph:58956a883341_124"},{"__ref":"Paragraph:58956a883341_125"},{"__ref":"Paragraph:58956a883341_126"},{"__ref":"Paragraph:58956a883341_127"},{"__ref":"Paragraph:58956a883341_128"},{"__ref":"Paragraph:58956a883341_129"},{"__ref":"Paragraph:58956a883341_130"},{"__ref":"Paragraph:58956a883341_131"},{"__ref":"Paragraph:58956a883341_132"},{"__ref":"Paragraph:58956a883341_133"},{"__ref":"Paragraph:58956a883341_134"},{"__ref":"Paragraph:58956a883341_135"},{"__ref":"Paragraph:58956a883341_136"},{"__ref":"Paragraph:58956a883341_137"},{"__ref":"Paragraph:58956a883341_138"},{"__ref":"Paragraph:58956a883341_139"}]},"validatedShareKey":""},"creator":{"__ref":"User:524f24852f3c"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fneural-network-pruning-101-af816aaea61","primaryTopic":{"__ref":"Topic:ae5d4995e225"},"topics":[{"__typename":"Topic","slug":"machine-learning"},{"__typename":"Topic","slug":"data-science"}],"isPublished":true,"latestPublishedVersion":"58956a883341","visibility":"PUBLIC","postResponses":{"__typename":"PostResponses","count":2},"allowResponses":true,"isLimitedState":false,"voterCount":90,"recommenders":[],"title":"Neural Network Pruning 101","isSeries":false,"sequence":null,"uniqueSlug":"neural-network-pruning-101-af816aaea61","clapCount":406,"socialTitle":"","socialDek":"","noIndex":null,"canonicalUrl":"","metaDescription":"","latestPublishedAt":1631519525992,"readingTime":21.278616352201258,"previewContent":{"__typename":"PreviewContent","subtitle":"All you need to know not to get lost"},"previewImage":{"__ref":"ImageMetadata:1*7qwYH1r-h6VOGiE6C2tpGg.png"},"isShortform":false,"seoTitle":"","firstPublishedAt":1631169416338,"updatedAt":1659097889365,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","curationStatus":"CURATION_STATUS_DISTRIBUTED","isIndexable":true,"isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:neural-networks"},{"__ref":"Tag:pruning"},{"__ref":"Tag:compression"},{"__ref":"Tag:deep-learning"},{"__ref":"Tag:deep-dives"}],"pendingCollection":null,"statusForCollection":"APPROVED","layerCake":3,"detectedLanguage":"en","wordCount":5418},"ImageMetadata:1*rsp22rKwFDjiwwCcUly56Q.jpeg":{"__typename":"ImageMetadata","id":"1*rsp22rKwFDjiwwCcUly56Q.jpeg","focusPercentX":null,"focusPercentY":null,"alt":null},"User:f7dc0c0eae92":{"__typename":"User","id":"f7dc0c0eae92","name":"Jacob Marks, Ph.D.","username":"jacob_marks","mediumMemberAt":0,"socialStats":{"__typename":"SocialStats","followerCount":905},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":null,"hasSubdomain":false,"bio":"ML @ Voxel51 | Stanford Theoretical Physics PhD https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fjacob-marks","imageId":"0*YukZswf8UB1bQdTV"},"Post:4f2d34bd8736":{"__typename":"Post","id":"4f2d34bd8736","title":"How I Turned My Company’s Docs into a Searchable Database with OpenAI","previewImage":{"__ref":"ImageMetadata:1*rsp22rKwFDjiwwCcUly56Q.jpeg"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"And how you can do the same with your docs","isFullContent":false},"visibility":"PUBLIC","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736","isPublished":true,"creator":{"__ref":"User:f7dc0c0eae92"},"collection":{"__ref":"Collection:7f60cf5620c9"},"clapCount":2993,"voterCount":692,"recommenders":[],"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":39},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1682620803812,"firstPublishedAt":1682406666156,"readingTime":14.189622641509434,"isLocked":false,"sequence":null,"isSeries":false,"uniqueSlug":"how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736"},"ImageMetadata:1*4C54ZxHRM1dOlAvlvoEJZg@2x.jpeg":{"__typename":"ImageMetadata","id":"1*4C54ZxHRM1dOlAvlvoEJZg@2x.jpeg","focusPercentX":null,"focusPercentY":null,"alt":"Two stochastic parrots sitting on a chain of large language models: LangChain"},"User:3a38da70d8dc":{"__typename":"User","id":"3a38da70d8dc","name":"Leonie Monigatti","username":"iamleonie","mediumMemberAt":1635398706000,"socialStats":{"__typename":"SocialStats","followerCount":3024},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":null,"hasSubdomain":false,"bio":"Professional software dev & data science hobbyist. Follow for practical data science guides - whether you're a data scientist or not. linkedin.com\u002Fin\u002F804250ab","imageId":"1*TTIl4oynrJyfIkLbC6fumA.png"},"Post:95fc8898732c":{"__typename":"Post","id":"95fc8898732c","title":"Getting Started with LangChain: A Beginner’s Guide to Building LLM-Powered Applications","previewImage":{"__ref":"ImageMetadata:1*4C54ZxHRM1dOlAvlvoEJZg@2x.jpeg"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"A LangChain tutorial to build anything with large language models in Python","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fgetting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c","isPublished":true,"creator":{"__ref":"User:3a38da70d8dc"},"collection":{"__ref":"Collection:7f60cf5620c9"},"clapCount":2048,"voterCount":595,"recommenders":[],"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":16},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1682431758625,"firstPublishedAt":1682431758625,"readingTime":11.031446540880502,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c"},"ImageMetadata:0*4ABoFdJClLr8QTK2":{"__typename":"ImageMetadata","id":"0*4ABoFdJClLr8QTK2","focusPercentX":null,"focusPercentY":null,"alt":null},"User:bf7d13fc53db":{"__typename":"User","id":"bf7d13fc53db","name":"Matt Chapman","username":"mattchapmanmsc","mediumMemberAt":1681163683000,"socialStats":{"__typename":"SocialStats","followerCount":2347},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":null,"hasSubdomain":false,"bio":"Data Scientist based in Oxford, UK. I write about DS, AI and try (& sometimes succeed) to give careers advice. Support me: medium.com\u002F@mattchapmanmsc\u002Fmembership","imageId":"1*4EQrg_kfWhQfHyGeuIunfg.png"},"Post:1e535dd0cd79":{"__typename":"Post","id":"1e535dd0cd79","title":"How I Stay Up to Date With the Latest AI Trends as a Full-Time Data Scientist","previewImage":{"__ref":"ImageMetadata:0*4ABoFdJClLr8QTK2"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"No, I don’t just ask ChatGPT to tell me","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fhow-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79","isPublished":true,"creator":{"__ref":"User:bf7d13fc53db"},"collection":{"__ref":"Collection:7f60cf5620c9"},"clapCount":1359,"voterCount":375,"recommenders":[],"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":21},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1682957864648,"firstPublishedAt":1682957864648,"readingTime":7.111635220125787,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"how-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79"},"ImageMetadata:1*c85uL1F1VzlMtekbzObLaw.png":{"__typename":"ImageMetadata","id":"1*c85uL1F1VzlMtekbzObLaw.png","focusPercentX":null,"focusPercentY":null,"alt":null},"User:2fccb851bb5e":{"__typename":"User","id":"2fccb851bb5e","name":"Cassie Kozyrkov","username":"kozyrkov","mediumMemberAt":1568389090000,"socialStats":{"__typename":"SocialStats","followerCount":149783},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"kozyrkov.medium.com"}},"hasSubdomain":true,"bio":"Chief Decision Scientist, Google. ❤️ Stats, ML\u002FAI, data, puns, art, theatre, decision science. All views are my own. twitter.com\u002Fquaesita","imageId":"1*IL0mnvzNcpG2ZD0JBqo7zQ.jpeg"},"Post:fabc3d4f8e36":{"__typename":"Post","id":"fabc3d4f8e36","title":"The Best Learning Paths for AI and Data Leadership","previewImage":{"__ref":"ImageMetadata:1*c85uL1F1VzlMtekbzObLaw.png"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"How to muscle up on data-related topics quickly","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fthe-best-learning-paths-for-ai-and-data-leadership-fabc3d4f8e36","isPublished":true,"creator":{"__ref":"User:2fccb851bb5e"},"collection":{"__ref":"Collection:7f60cf5620c9"},"clapCount":1454,"voterCount":265,"recommenders":[],"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":8},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1683465042067,"firstPublishedAt":1682870733876,"readingTime":6.1229559748427675,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"the-best-learning-paths-for-ai-and-data-leadership-fabc3d4f8e36"},"ImageMetadata:1*FyaF0pPskcOtQ_MmEnBjZA.jpeg":{"__typename":"ImageMetadata","id":"1*FyaF0pPskcOtQ_MmEnBjZA.jpeg","focusPercentX":null,"focusPercentY":null,"alt":null},"User:a148fd75c2e9":{"__typename":"User","id":"a148fd75c2e9","name":"Alexander Nguyen","username":"alexcancode","mediumMemberAt":0,"socialStats":{"__typename":"SocialStats","followerCount":9834},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"alexcancode.medium.com"}},"hasSubdomain":true,"bio":"120K Followers on LinkedIn Ideas about technology, software engineering and life https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Falxngu\u002F","imageId":"1*cwYWYCjbeXNc_pAtTeq_Zg.jpeg"},"Collection:5517fd7b58a6":{"__typename":"Collection","id":"5517fd7b58a6","slug":"gitconnected","name":"Level Up Coding","domain":"levelup.gitconnected.com","description":"Coding tutorials and news. The developer homepage gitconnected.com && skilled.dev && levelup.dev","subscriberCount":88642,"avatar":{"__ref":"ImageMetadata:1*5D9oYBd58pyjMkV_5-zXXQ.jpeg"}},"ImageMetadata:1*5D9oYBd58pyjMkV_5-zXXQ.jpeg":{"__typename":"ImageMetadata","id":"1*5D9oYBd58pyjMkV_5-zXXQ.jpeg"},"Post:dc8f865b2c19":{"__typename":"Post","id":"dc8f865b2c19","title":"Why I Keep Failing Candidates During Google Interviews…","previewImage":{"__ref":"ImageMetadata:1*FyaF0pPskcOtQ_MmEnBjZA.jpeg"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"They don’t meet the bar.","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Flevelup.gitconnected.com\u002Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19","isPublished":true,"creator":{"__ref":"User:a148fd75c2e9"},"collection":{"__ref":"Collection:5517fd7b58a6"},"clapCount":4100,"voterCount":955,"recommenders":[],"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":126},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1684821166277,"firstPublishedAt":1681362254418,"readingTime":3.7163522012578616,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19"},"ImageMetadata:1*y2egV1SyuZiKb2LMS6TlKw.jpeg":{"__typename":"ImageMetadata","id":"1*y2egV1SyuZiKb2LMS6TlKw.jpeg","focusPercentX":null,"focusPercentY":null,"alt":null},"User:f90a3bb1d400":{"__typename":"User","id":"f90a3bb1d400","name":"Rukshan Pramoditha","username":"rukshanpramoditha","mediumMemberAt":1671116352000,"socialStats":{"__typename":"SocialStats","followerCount":5419},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"rukshanpramoditha.medium.com"}},"hasSubdomain":true,"bio":"1,800,000+ Views | BSc in Stats | Top 50 Data Science\u002FAI\u002FML Writer on Medium | Sign up: https:\u002F\u002Frukshanpramoditha.medium.com\u002Fmembership","imageId":"1*h9UiRF_7vSdeFNwFpt0oOQ.jpeg"},"Collection:d85b77f1b277":{"__typename":"Collection","id":"d85b77f1b277","slug":"data-science-365","name":"Data Science 365","domain":null,"description":"Bring data into actionable insights.","subscriberCount":180,"avatar":{"__ref":"ImageMetadata:1*ZDYxcD7xtCPewOK3QXEWfA.png"}},"ImageMetadata:1*ZDYxcD7xtCPewOK3QXEWfA.png":{"__typename":"ImageMetadata","id":"1*ZDYxcD7xtCPewOK3QXEWfA.png"},"Post:7a8662830f15":{"__typename":"Post","id":"7a8662830f15","title":"Determining the Right Batch Size for a Neural Network to Get Better and Faster Results","previewImage":{"__ref":"ImageMetadata:1*y2egV1SyuZiKb2LMS6TlKw.jpeg"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"Guidelines for choosing the right batch size to maintain optimal training speed and accuracy while saving computer resources","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fdata-science-365\u002Fdetermining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15","isPublished":true,"creator":{"__ref":"User:f90a3bb1d400"},"collection":{"__ref":"Collection:d85b77f1b277"},"clapCount":32,"voterCount":10,"recommenders":[],"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":0},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1664218117185,"firstPublishedAt":1664218117185,"readingTime":3.4943396226415095,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15"},"ImageMetadata:1*y0vJwEfN45barnQO9jiYew.jpeg":{"__typename":"ImageMetadata","id":"1*y0vJwEfN45barnQO9jiYew.jpeg","focusPercentX":null,"focusPercentY":null,"alt":null},"User:fb44e21903f3":{"__typename":"User","id":"fb44e21903f3","name":"The PyCoach","username":"frank-andrade","mediumMemberAt":1676735732000,"socialStats":{"__typename":"SocialStats","followerCount":59698},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"thepycoach.com"}},"hasSubdomain":true,"bio":"10M+ Views on Medium || Make money by writing about AI, programming, data science or tech 👉 http:\u002F\u002Fbit.ly\u002F3zfbgiX","imageId":"1*veEX4-CiLz5jqUjwWfQo_Q.jpeg"},"Collection:76436a11a2b0":{"__typename":"Collection","id":"76436a11a2b0","slug":"artificial-corner","name":"Artificial Corner","domain":"artificialcorner.com","description":"A Medium publication about AI, tech, programming, data science and everything in between.","subscriberCount":2809,"avatar":{"__ref":"ImageMetadata:1*e1-WDgc0KCMKp_rHX9TyQQ.png"}},"ImageMetadata:1*e1-WDgc0KCMKp_rHX9TyQQ.png":{"__typename":"ImageMetadata","id":"1*e1-WDgc0KCMKp_rHX9TyQQ.png"},"Post:886a50dabc54":{"__typename":"Post","id":"886a50dabc54","title":"You’re Using ChatGPT Wrong! Here’s How to Be Ahead of 99% of ChatGPT Users","previewImage":{"__ref":"ImageMetadata:1*y0vJwEfN45barnQO9jiYew.jpeg"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"Master ChatGPT by learning prompt engineering.","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Fartificialcorner.com\u002Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54","isPublished":true,"creator":{"__ref":"User:fb44e21903f3"},"collection":{"__ref":"Collection:76436a11a2b0"},"clapCount":21080,"voterCount":5408,"recommenders":[],"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":372},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1681507222945,"firstPublishedAt":1679069542254,"readingTime":6.145283018867925,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54"},"ImageMetadata:1*6skjudfW25iAbd8uryVH6A.png":{"__typename":"ImageMetadata","id":"1*6skjudfW25iAbd8uryVH6A.png","focusPercentX":null,"focusPercentY":null,"alt":null},"User:8a345d2c6a20":{"__typename":"User","id":"8a345d2c6a20","name":"Jan Marcel Kezmann","username":"jan_marcel_kezmann","mediumMemberAt":1665209813000,"socialStats":{"__typename":"SocialStats","followerCount":871},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":null,"hasSubdomain":false,"bio":"AI enthusiast, practitioner and writer. I write about AI, ML and Data Science in general. Join Medium with https:\u002F\u002Fmedium.com\u002F@jan_marcel_kezmann\u002Fmembership","imageId":"1*XdvgrCXUG5ox05Aa9zQIdA.jpeg"},"Collection:f19413a43ae4":{"__typename":"Collection","id":"f19413a43ae4","slug":"mlearning-ai","name":"MLearning.ai","domain":null,"description":"Data Scientists must think like an artist when finding a solution when creating a piece of code. ⚪️ Artists enjoy working on interesting problems, even if there is no obvious answer ⚪️ linktr.ee\u002Fmlearning 🔵 Follow to join our 28K+ Unique DAILY Readers 🟠","subscriberCount":6728,"avatar":{"__ref":"ImageMetadata:1*6xCb1sNpjadaSBuVLPTFQQ.png"}},"ImageMetadata:1*6xCb1sNpjadaSBuVLPTFQQ.png":{"__typename":"ImageMetadata","id":"1*6xCb1sNpjadaSBuVLPTFQQ.png"},"Post:163e990c02af":{"__typename":"Post","id":"163e990c02af","title":"Optimizing Deep Learning Models with Pruning: A Practical Guide","previewImage":{"__ref":"ImageMetadata:1*6skjudfW25iAbd8uryVH6A.png"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"Exploring and Implementing Pruning Methods with TensorFlow and PyTorch","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fmlearning-ai\u002Foptimizing-deep-learning-models-with-pruning-a-practical-guide-163e990c02af","isPublished":true,"creator":{"__ref":"User:8a345d2c6a20"},"collection":{"__ref":"Collection:f19413a43ae4"},"clapCount":210,"voterCount":11,"recommenders":[],"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":1},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1672402223637,"firstPublishedAt":1672402223637,"readingTime":12.19811320754717,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"optimizing-deep-learning-models-with-pruning-a-practical-guide-163e990c02af"},"ImageMetadata:1*lgWYSQWDdrkR4atgNVInJA.png":{"__typename":"ImageMetadata","id":"1*lgWYSQWDdrkR4atgNVInJA.png","focusPercentX":null,"focusPercentY":null,"alt":null},"User:7fc4b5ed0ad1":{"__typename":"User","id":"7fc4b5ed0ad1","name":"Alessandro Lamberti","username":"alessandroai","mediumMemberAt":1628859412000,"socialStats":{"__typename":"SocialStats","followerCount":769},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"alessandroai.medium.com"}},"hasSubdomain":true,"bio":"Machine Learning Engineer | R&D and Intelligence | Sign up: https:\u002F\u002Falessandroai.medium.com\u002Fmembership","imageId":"1*hqKHflotuIpkmXQ4DX4rAQ.jpeg"},"Collection:a81c8d170222":{"__typename":"Collection","id":"a81c8d170222","slug":"artificialis","name":"Artificialis","domain":null,"description":"A home for Data Science and Machine Learning. Share ideas and concepts with us.","subscriberCount":280,"avatar":{"__ref":"ImageMetadata:1*vvurQWHROQZyfn05ihe4-Q.png"}},"ImageMetadata:1*vvurQWHROQZyfn05ihe4-Q.png":{"__typename":"ImageMetadata","id":"1*vvurQWHROQZyfn05ihe4-Q.png"},"Post:12b3960a486a":{"__typename":"Post","id":"12b3960a486a","title":"Maximizing Model Performance with Knowledge Distillation in PyTorch","previewImage":{"__ref":"ImageMetadata:1*lgWYSQWDdrkR4atgNVInJA.png"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"Boost your model’s accuracy and save on resources with knowledge distillation in PyTorch","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fartificialis\u002Fmaximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a","isPublished":true,"creator":{"__ref":"User:7fc4b5ed0ad1"},"collection":{"__ref":"Collection:a81c8d170222"},"clapCount":313,"voterCount":23,"recommenders":[],"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":0},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1670491379544,"firstPublishedAt":1670491379544,"readingTime":4.847169811320755,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"maximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a"},"ImageMetadata:1*qe6nYlH8zsmUdScyHMhRCQ.png":{"__typename":"ImageMetadata","id":"1*qe6nYlH8zsmUdScyHMhRCQ.png","focusPercentX":null,"focusPercentY":null,"alt":"Guide to Learning Rate Schedulers in PyTorch"},"Post:24bbb262c863":{"__typename":"Post","id":"24bbb262c863","title":"A Visual Guide to Learning Rate Schedulers in PyTorch","previewImage":{"__ref":"ImageMetadata:1*qe6nYlH8zsmUdScyHMhRCQ.png"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"LR decay and annealing strategies for Deep Learning in Python","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fa-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863","isPublished":true,"creator":{"__ref":"User:3a38da70d8dc"},"collection":{"__ref":"Collection:7f60cf5620c9"},"clapCount":1042,"voterCount":122,"recommenders":[],"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":6},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1670344548241,"firstPublishedAt":1670344548241,"readingTime":8.436792452830188,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863"},"User:a32c340ea342":{"__typename":"User","username":"MediumStaff","id":"a32c340ea342"},"CatalogViewerEdge:catalogId:b1d913188c20-viewerId:lo_67da07359f0f":{"__typename":"CatalogViewerEdge","followersCount":59,"id":"catalogId:b1d913188c20-viewerId:lo_67da07359f0f"},"ImageMetadata:1*yr2O5U-a0-rfY34C6yOXMw.jpeg":{"__typename":"ImageMetadata","id":"1*yr2O5U-a0-rfY34C6yOXMw.jpeg","alt":null},"Post:f9f7305598c2":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*yr2O5U-a0-rfY34C6yOXMw.jpeg"},"id":"f9f7305598c2"},"CatalogItemV2:{\"catalogItemId\":\"6324f363019b5c18686768b8\"}":{"__typename":"CatalogItemV2","catalogItemId":"6324f363019b5c18686768b8","entity":{"__ref":"Post:f9f7305598c2"}},"ImageMetadata:":{"__typename":"ImageMetadata","id":"","alt":null},"Post:8ed4a521b29f":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:"},"id":"8ed4a521b29f"},"CatalogItemV2:{\"catalogItemId\":\"6324b272c904fecfbd6cbd64\"}":{"__typename":"CatalogItemV2","catalogItemId":"6324b272c904fecfbd6cbd64","entity":{"__ref":"Post:8ed4a521b29f"}},"ImageMetadata:1*_3WdkzQRqIq8tt3Wh-WhbA.jpeg":{"__typename":"ImageMetadata","id":"1*_3WdkzQRqIq8tt3Wh-WhbA.jpeg","alt":null},"Post:d6145d2ad168":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*_3WdkzQRqIq8tt3Wh-WhbA.jpeg"},"id":"d6145d2ad168"},"CatalogItemV2:{\"catalogItemId\":\"6324be5d9e7fd89587888ed8\"}":{"__typename":"CatalogItemV2","catalogItemId":"6324be5d9e7fd89587888ed8","entity":{"__ref":"Post:d6145d2ad168"}},"ImageMetadata:1*VWm67Y5nT9RR0zLGr-aMVQ.jpeg":{"__typename":"ImageMetadata","id":"1*VWm67Y5nT9RR0zLGr-aMVQ.jpeg","alt":null},"Post:ac8b3e54c312":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*VWm67Y5nT9RR0zLGr-aMVQ.jpeg"},"id":"ac8b3e54c312"},"CatalogItemV2:{\"catalogItemId\":\"6324c101f70830c1fd0e1650\"}":{"__typename":"CatalogItemV2","catalogItemId":"6324c101f70830c1fd0e1650","entity":{"__ref":"Post:ac8b3e54c312"}},"ImageMetadata:0*xf2HMwF1tNFPp-zI":{"__typename":"ImageMetadata","id":"0*xf2HMwF1tNFPp-zI","alt":null},"Post:c890f16f4e4d":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:0*xf2HMwF1tNFPp-zI"},"id":"c890f16f4e4d"},"CatalogItemV2:{\"catalogItemId\":\"631261be8cc8af1fbf8a2cde\"}":{"__typename":"CatalogItemV2","catalogItemId":"631261be8cc8af1fbf8a2cde","entity":{"__ref":"Post:c890f16f4e4d"}},"Catalog:b1d913188c20":{"__typename":"Catalog","id":"b1d913188c20","name":"Stories to Help You Grow as a Software Developer","postItemsCount":19,"predefined":null,"creator":{"__ref":"User:a32c340ea342"},"viewerEdge":{"__ref":"CatalogViewerEdge:catalogId:b1d913188c20-viewerId:lo_67da07359f0f"},"itemsConnection:(limit:5)":{"__typename":"CatalogItemsConnection","items":[{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6324f363019b5c18686768b8\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6324b272c904fecfbd6cbd64\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6324be5d9e7fd89587888ed8\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6324c101f70830c1fd0e1650\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"631261be8cc8af1fbf8a2cde\"}"}]}},"CatalogViewerEdge:catalogId:faca18b0622f-viewerId:lo_67da07359f0f":{"__typename":"CatalogViewerEdge","followersCount":46,"id":"catalogId:faca18b0622f-viewerId:lo_67da07359f0f"},"ImageMetadata:1*4zC5ohNcmVDb1NXmzCvmNA.jpeg":{"__typename":"ImageMetadata","id":"1*4zC5ohNcmVDb1NXmzCvmNA.jpeg","alt":null},"Post:abf5300eba08":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*4zC5ohNcmVDb1NXmzCvmNA.jpeg"},"id":"abf5300eba08"},"CatalogItemV2:{\"catalogItemId\":\"6329132795c63d6fed0c5806\"}":{"__typename":"CatalogItemV2","catalogItemId":"6329132795c63d6fed0c5806","entity":{"__ref":"Post:abf5300eba08"}},"ImageMetadata:1*0dul7hn9LeV7U2XLVPvYYw.jpeg":{"__typename":"ImageMetadata","id":"1*0dul7hn9LeV7U2XLVPvYYw.jpeg","alt":null},"Post:b19ecc091df7":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*0dul7hn9LeV7U2XLVPvYYw.jpeg"},"id":"b19ecc091df7"},"CatalogItemV2:{\"catalogItemId\":\"6329ce901993f7dec4c0711e\"}":{"__typename":"CatalogItemV2","catalogItemId":"6329ce901993f7dec4c0711e","entity":{"__ref":"Post:b19ecc091df7"}},"ImageMetadata:1*oO7uwYs0NMWV7B4mUCuoIw.png":{"__typename":"ImageMetadata","id":"1*oO7uwYs0NMWV7B4mUCuoIw.png","alt":null},"Post:4c59524d650d":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*oO7uwYs0NMWV7B4mUCuoIw.png"},"id":"4c59524d650d"},"CatalogItemV2:{\"catalogItemId\":\"6324e4d255c5d4410e2d88e7\"}":{"__typename":"CatalogItemV2","catalogItemId":"6324e4d255c5d4410e2d88e7","entity":{"__ref":"Post:4c59524d650d"}},"ImageMetadata:1*TcsPbK3g22mU0hGe08jHPA.gif":{"__typename":"ImageMetadata","id":"1*TcsPbK3g22mU0hGe08jHPA.gif","alt":null},"Post:f1b658f93428":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*TcsPbK3g22mU0hGe08jHPA.gif"},"id":"f1b658f93428"},"CatalogItemV2:{\"catalogItemId\":\"6329d3bd03156fe100d6ff66\"}":{"__typename":"CatalogItemV2","catalogItemId":"6329d3bd03156fe100d6ff66","entity":{"__ref":"Post:f1b658f93428"}},"ImageMetadata:1*eW3FD5JXPqFxF-NgWdZXIQ.jpeg":{"__typename":"ImageMetadata","id":"1*eW3FD5JXPqFxF-NgWdZXIQ.jpeg","alt":null},"Post:9f2a0bb0547":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*eW3FD5JXPqFxF-NgWdZXIQ.jpeg"},"id":"9f2a0bb0547"},"CatalogItemV2:{\"catalogItemId\":\"6329ddae2e7f9552f54a4638\"}":{"__typename":"CatalogItemV2","catalogItemId":"6329ddae2e7f9552f54a4638","entity":{"__ref":"Post:9f2a0bb0547"}},"Catalog:faca18b0622f":{"__typename":"Catalog","id":"faca18b0622f","name":"Stories to Help You Level-Up at Work","postItemsCount":19,"predefined":null,"creator":{"__ref":"User:a32c340ea342"},"viewerEdge":{"__ref":"CatalogViewerEdge:catalogId:faca18b0622f-viewerId:lo_67da07359f0f"},"itemsConnection:(limit:5)":{"__typename":"CatalogItemsConnection","items":[{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6329132795c63d6fed0c5806\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6329ce901993f7dec4c0711e\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6324e4d255c5d4410e2d88e7\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6329d3bd03156fe100d6ff66\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6329ddae2e7f9552f54a4638\"}"}]}},"CatalogViewerEdge:catalogId:c7bc6e1ee00f-viewerId:lo_67da07359f0f":{"__typename":"CatalogViewerEdge","followersCount":81,"id":"catalogId:c7bc6e1ee00f-viewerId:lo_67da07359f0f"},"ImageMetadata:1*vXL3FFkiYmBAfLVbPRkXng.png":{"__typename":"ImageMetadata","id":"1*vXL3FFkiYmBAfLVbPRkXng.png","alt":null},"Post:ca291e15d99":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*vXL3FFkiYmBAfLVbPRkXng.png"},"id":"ca291e15d99"},"CatalogItemV2:{\"catalogItemId\":\"6470fd8f979042d074289251\"}":{"__typename":"CatalogItemV2","catalogItemId":"6470fd8f979042d074289251","entity":{"__ref":"Post:ca291e15d99"}},"ImageMetadata:1*mV_rDLGaL3SW2eLjauVrmg.png":{"__typename":"ImageMetadata","id":"1*mV_rDLGaL3SW2eLjauVrmg.png","alt":null},"Post:d6018bb9d7dc":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*mV_rDLGaL3SW2eLjauVrmg.png"},"id":"d6018bb9d7dc"},"CatalogItemV2:{\"catalogItemId\":\"6470b51472272ead6bb53596\"}":{"__typename":"CatalogItemV2","catalogItemId":"6470b51472272ead6bb53596","entity":{"__ref":"Post:d6018bb9d7dc"}},"ImageMetadata:1*WsyTOM_sP90daUsK2NhTHg.jpeg":{"__typename":"ImageMetadata","id":"1*WsyTOM_sP90daUsK2NhTHg.jpeg","alt":null},"Post:aa71e640efa2":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*WsyTOM_sP90daUsK2NhTHg.jpeg"},"id":"aa71e640efa2"},"CatalogItemV2:{\"catalogItemId\":\"646facfc8301505a1f2f12bf\"}":{"__typename":"CatalogItemV2","catalogItemId":"646facfc8301505a1f2f12bf","entity":{"__ref":"Post:aa71e640efa2"}},"ImageMetadata:1*WQ6n_bwaatvUI6rkfbZnog.jpeg":{"__typename":"ImageMetadata","id":"1*WQ6n_bwaatvUI6rkfbZnog.jpeg","alt":"Still of Michelle Yeoh as Evelyn Wang in 2022’s Everything Everywhere All At Once, creating a tailspin in the IRS office"},"Post:b9b99f1e3b6f":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*WQ6n_bwaatvUI6rkfbZnog.jpeg"},"id":"b9b99f1e3b6f"},"CatalogItemV2:{\"catalogItemId\":\"6470fb8ef67e95979e9eb223\"}":{"__typename":"CatalogItemV2","catalogItemId":"6470fb8ef67e95979e9eb223","entity":{"__ref":"Post:b9b99f1e3b6f"}},"ImageMetadata:1*AwBB71Yhq-GxxX-wtnysAQ.png":{"__typename":"ImageMetadata","id":"1*AwBB71Yhq-GxxX-wtnysAQ.png","alt":null},"Post:a79d1288a865":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*AwBB71Yhq-GxxX-wtnysAQ.png"},"id":"a79d1288a865"},"CatalogItemV2:{\"catalogItemId\":\"646e1ec1ced6614e0ac86880\"}":{"__typename":"CatalogItemV2","catalogItemId":"646e1ec1ced6614e0ac86880","entity":{"__ref":"Post:a79d1288a865"}},"Catalog:c7bc6e1ee00f":{"__typename":"Catalog","id":"c7bc6e1ee00f","name":"Staff Picks","postItemsCount":323,"predefined":null,"creator":{"__ref":"User:a32c340ea342"},"viewerEdge":{"__ref":"CatalogViewerEdge:catalogId:c7bc6e1ee00f-viewerId:lo_67da07359f0f"},"itemsConnection:(limit:5)":{"__typename":"CatalogItemsConnection","items":[{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6470fd8f979042d074289251\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6470b51472272ead6bb53596\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"646facfc8301505a1f2f12bf\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6470fb8ef67e95979e9eb223\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"646e1ec1ced6614e0ac86880\"}"}]}}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.ce8005ba.js"></script><script src="https://cdn-client.medium.com/lite/static/js/8885.0f1d613c.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.00c23067.js"></script><script src="https://cdn-client.medium.com/lite/static/js/instrumentation.c71f0248.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.bbdcaa9d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6068.97073e64.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/799.361fd2fb.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1860.abea291f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3838.7ae103cd.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5144.5af60acf.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2905.10f36975.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6081.33f7ed0a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8695.f26a0eca.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7685.3e67432a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3974.1968881e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5203.3abee3c1.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6776.d8a1b8fb.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6553.375a49f7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3635.c351368e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9174.55135b1c.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7855.3c85e9df.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5510.a35406ef.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4129.9a8d63eb.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8580.1d3cbd2a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1802.c640932a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4078.182beff5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9225.9cfbe85d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6804.f243c4a8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9408.71eea81b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2287.a89f9d21.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1743.20c1313c.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8883.3494dd2a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5563.d07ab3d3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9150.d74865ec.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2550.cd5e085a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8051.2abb7834.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2031.39efaccf.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.a14c0fd8.chunk.js"></script><script>window.main();</script><script defer src="https://static.cloudflareinsights.com/beacon.min.js/v52afc6f149f6479b8c77fa569edb01181681764108816" integrity="sha512-jGCTpDpBAYDGNYR5ztKt4BQPGef1P0giN6ZGVUi835kFF88FOmmn8jBQWNgrNd8g/Yu421NdgWhwQoaOPFflDw==" data-cf-beacon='{"rayId":"7ce1561a1feb24c1","version":"2023.4.0","b":1,"token":"0b5f665943484354a59c39c6833f7078","si":100}' crossorigin="anonymous"></script>
</body></html>